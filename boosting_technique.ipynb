{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Boosting Techniques | Assignment**"
      ],
      "metadata": {
        "id": "hw_1hJbeDzNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.**"
      ],
      "metadata": {
        "id": "kPO1KaJaD7G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting is a powerful ensemble learning technique that combines multiple 'weak' or 'base' learners to create a 'strong' learner. The core idea is to sequentially build models, where each new model attempts to correct the errors of the previous ones. It focuses on misclassified instances, giving them more weight in subsequent training steps.\n",
        "\n",
        "Here's how it improves weak learners:\n",
        "\n",
        "**Sequential Learning:** Unlike bagging (e.g., Random Forest) where models are built independently, boosting builds models sequentially. Each new model learns from the mistakes of the previous models.\n",
        "\n",
        "**Focus on Difficult Cases:** Boosting algorithms assign higher weights to data points that were misclassified by earlier weak learners. This forces subsequent learners to pay more attention to these 'hard' examples, leading to a better overall model.\n",
        "\n",
        "**Error Correction:** Each weak learner tries to correct the errors of its predecessors. By iteratively reducing the errors, the combined strong learner becomes highly accurate.\n",
        "\n",
        "**Reduced Bias:** Boosting algorithms are very effective at reducing bias. By repeatedly focusing on errors and improving the model, they can fit complex relationships in the data very well.\n",
        "\n",
        "**Weighted Voting/Prediction:** In the final prediction phase, the predictions of the individual weak learners are combined, often with weights assigned based on their accuracy, to produce the final output.\n",
        "\n",
        "Common boosting algorithms include AdaBoost, Gradient Boosting (GBM), XGBoost, LightGBM, and CatBoost."
      ],
      "metadata": {
        "id": "FvrEMSoNGNkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?**"
      ],
      "metadata": {
        "id": "5V72Kir3GsHM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1afc7057"
      },
      "source": [
        "Both AdaBoost and Gradient Boosting are ensemble learning techniques that combine multiple weak learners (typically decision trees) to create a strong learner. However, they differ significantly in how they train these weak learners and how they correct errors.\n",
        "\n",
        "### **AdaBoost (Adaptive Boosting)**\n",
        "\n",
        "**Focus:** AdaBoost primarily focuses on **misclassified samples** from the previous weak learner.\n",
        "\n",
        "**Training Process:**\n",
        "\n",
        "1.  **Initialize Weights:** Each training sample is initially assigned an equal weight.\n",
        "2.  **Sequential Training:** A weak learner (e.g., a shallow decision tree) is trained on the training data.\n",
        "3.  **Update Sample Weights:** After training, the weights of the misclassified samples are increased, and the weights of the correctly classified samples are decreased. This makes subsequent weak learners focus more on the samples that were difficult for the previous learner.\n",
        "4.  **Update Learner Weights:** The weak learner itself is assigned a weight based on its accuracy. More accurate learners get higher weights.\n",
        "5.  **Iteration:** Steps 2-4 are repeated for a predefined number of iterations or until a certain performance threshold is met.\n",
        "6.  **Final Prediction:** The predictions of all weak learners are combined using a weighted majority vote (for classification) or a weighted sum (for regression), where the weights are those assigned to the individual learners.\n",
        "\n",
        "**Key Characteristic:** AdaBoost adapts to the 'hardness' of samples by adjusting their weights.\n",
        "\n",
        "### **Gradient Boosting**\n",
        "\n",
        "**Focus:** Gradient Boosting primarily focuses on **the errors (residuals) made by the previous ensemble**.\n",
        "\n",
        "**Training Process:**\n",
        "\n",
        "1.  **Initial Prediction:** An initial model (often a simple constant value like the mean for regression or log-odds for classification) is used to make predictions.\n",
        "2.  **Calculate Residuals (Errors):** For each training sample, the 'residual' is calculated, which is the difference between the actual target value and the current ensemble's prediction.\n",
        "3.  **Train Weak Learner on Residuals:** A new weak learner is trained specifically to predict these residuals (or the negative gradient of the loss function). In essence, it tries to learn the errors of the previous ensemble.\n",
        "4.  **Add to Ensemble:** The prediction of this new weak learner is added to the previous ensemble's prediction, usually scaled by a learning rate (shrinkage parameter). This new learner essentially 'corrects' the errors of the prior models.\n",
        "5.  **Iteration:** Steps 2-4 are repeated for a predefined number of iterations.\n",
        "6.  **Final Prediction:** The final prediction is the sum of the initial prediction and the predictions of all subsequent weak learners.\n",
        "\n",
        "**Key Characteristic:** Gradient Boosting iteratively builds the model by fitting new models to the residuals of the previous steps, effectively minimizing the loss function using gradient descent principles.\n",
        "\n",
        "### **Summary of Differences:**\n",
        "\n",
        "| Feature                 | AdaBoost                                     | Gradient Boosting                                   |\n",
        "| :---------------------- | :------------------------------------------- | :-------------------------------------------------- |\n",
        "| **Error Correction**    | Adjusts **sample weights** to focus on misclassified samples. | Fits new models to **residuals (errors)** of the previous ensemble. |\n",
        "| **Model Combination**   | Uses weighted majority vote/sum of weak learners. | Sums up the predictions of all weak learners (with learning rate). |\n",
        "| **Focus**               | Adapts to difficult *data points*.           | Adapts to difficult *prediction errors*.            |\n",
        "| **Loss Function**       | Not directly optimizing a differentiable loss function for the weak learners (though the overall algorithm optimizes an exponential loss for classification). | Directly optimizes a differentiable loss function by using its negative gradient. |\n",
        "| **Sensitivity to Outliers** | More sensitive to noisy data and outliers due to sample weighting. | Less sensitive to outliers compared to AdaBoost, but still can be affected if residuals are large. |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: How does regularization help in XGBoost?**"
      ],
      "metadata": {
        "id": "inqo_eLtuJ2C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8892bfc9"
      },
      "source": [
        "Regularization is a key aspect of XGBoost that distinguishes it from many other boosting algorithms. It helps to prevent overfitting, making the model more robust and improving its generalization performance on unseen data.\n",
        "\n",
        "XGBoost incorporates several regularization techniques:\n",
        "\n",
        "### **1. L1 and L2 Regularization (Lasso and Ridge Penalties) on Weights**\n",
        "\n",
        "XGBoost adds L1 (Lasso) and L2 (Ridge) regularization terms to the objective function, which is the quantity it tries to minimize during training. These terms penalize the complexity of the model.\n",
        "\n",
        "*   **L1 Regularization (Lasso, controlled by `alpha` parameter):** This adds a penalty equal to the absolute value of the magnitude of coefficients. It can lead to sparse models, where some feature weights become exactly zero, effectively performing feature selection.\n",
        "*   **L2 Regularization (Ridge, controlled by `lambda` parameter):** This adds a penalty equal to the square of the magnitude of coefficients. It helps to shrink the feature weights towards zero, reducing their impact and preventing them from becoming too large.\n",
        "\n",
        "**How it helps:** By penalizing large weights and complex models, L1 and L2 regularization discourages individual trees from relying too heavily on specific features or making very aggressive splits. This prevents the model from fitting noise in the training data.\n",
        "\n",
        "### **2. Shrinkage (Learning Rate, controlled by `eta` parameter)**\n",
        "\n",
        "Shrinkage is a technique where the contribution of each tree to the overall model is scaled down by a factor (the learning rate). After each tree is built, its predictions are multiplied by `eta` before being added to the ensemble.\n",
        "\n",
        "**How it helps:** A small learning rate means that each new tree has less impact, requiring more trees to be built. This slower learning process makes the model more robust to the specific patterns in the training data, effectively preventing overfitting. It also helps to prevent individual trees from dominating the ensemble.\n",
        "\n",
        "### **3. Subsampling (Column and Row Subsampling)**\n",
        "\n",
        "XGBoost supports subsampling of both rows (training instances) and columns (features) before building each tree.\n",
        "\n",
        "*   **Row Subsampling (controlled by `subsample` parameter):** Similar to Random Forest, this involves training each tree on a random subset of the training data. This means that not all data points are seen by every tree.\n",
        "*   **Column Subsampling (controlled by `colsample_bytree`, `colsample_bylevel`, `colsample_bynode` parameters):** This involves randomly selecting a subset of features to consider when looking for the best split at each node (or level, or tree). This is similar to the `max_features` parameter in Random Forests.\n",
        "\n",
        "**How it helps:** Subsampling introduces randomness into the tree-building process. By training trees on different subsets of data and features, it reduces the correlation between individual trees, making the ensemble more diverse and less prone to overfitting to specific patterns in the full dataset or specific features.\n",
        "\n",
        "### **4. Max Depth of Trees (controlled by `max_depth` parameter)**\n",
        "\n",
        "Limiting the maximum depth of individual trees is a form of pre-pruning that directly controls the complexity of each weak learner.\n",
        "\n",
        "**How it helps:** Shallower trees are simpler and less likely to capture noise or highly specific patterns in the training data. By restricting the depth, XGBoost prevents individual trees from becoming too specialized and overfitting.\n",
        "\n",
        "### **5. Minimum Child Weight (controlled by `min_child_weight` parameter)**\n",
        "\n",
        "This parameter specifies the minimum sum of instance weight (Hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than `min_child_weight`, then the building process will give up further partitioning.\n",
        "\n",
        "**How it helps:** `min_child_weight` helps to prevent the creation of leaf nodes that are too small and thus prone to capturing noise. It ensures that splits only occur if there is sufficient data support, making the trees more generalized.\n",
        "\n",
        "### **In Summary:**\n",
        "\n",
        "By combining these regularization techniques, XGBoost achieves a powerful balance between model complexity and predictive accuracy. It allows the model to learn complex relationships in the data while actively preventing it from memorizing the training examples, leading to better performance on new, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: Why is CatBoost considered efficient for handling categorical data?**"
      ],
      "metadata": {
        "id": "4xBHsY1ruYHv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "969f8cdd"
      },
      "source": [
        "CatBoost (Categorical Boosting) is a powerful gradient boosting library that stands out for its robust and efficient handling of categorical features. Unlike many other boosting algorithms that require extensive preprocessing of categorical data (e.g., one-hot encoding, target encoding with potential data leakage), CatBoost automates and optimizes this process internally.\n",
        "\n",
        "Here's why CatBoost is considered efficient for handling categorical data:\n",
        "\n",
        "### **1. Ordered Target Encoding (aka. Ordered Boosting Principle)**\n",
        "\n",
        "This is perhaps the most significant innovation in CatBoost for categorical features. Traditional target encoding (or mean encoding) can suffer from target leakage, where the model uses information from the target variable to encode categorical features, leading to overfitting. CatBoost addresses this with an \"ordered\" approach:\n",
        "\n",
        "*   **Prevents Target Leakage:** For each sample, the target-based statistics (e.g., average target value) for a categorical feature are calculated *only using the training samples observed *before* the current sample in a random permutation of the dataset*. This prevents information from the current sample's target value from leaking into its feature encoding.\n",
        "*   **Dynamic Encoding:** The encoding is done on-the-fly during training. This means that for a given categorical feature, its numerical representation can vary depending on the position of the sample in the random permutation.\n",
        "*   **Equation:** For a categorical feature `C`, and a given sample `(X_i, y_i)`, the ordered target encoding might be calculated as:\n",
        "    `E(C=val) = (Sum(y_j for j < i and C_j = val) + prior * count) / (count(j < i and C_j = val) + prior)`\n",
        "    Where `prior` is a smoothing term and `count` is the number of times `val` appeared before sample `i`.\n",
        "\n",
        "**Efficiency:** This method avoids the need for manual, potentially leakage-prone preprocessing steps and handles high-cardinality categorical features gracefully.\n",
        "\n",
        "### **2. One-Hot Encoding for Low-Cardinality Features**\n",
        "\n",
        "For categorical features with a small number of unique values (low cardinality), CatBoost can automatically apply one-hot encoding. This is controlled by the `one_hot_max_size` parameter. If the number of unique categories is less than or equal to this parameter, CatBoost will use one-hot encoding.\n",
        "\n",
        "**Efficiency:** This is a sensible default as one-hot encoding works well for low-cardinality features without creating too many new columns.\n",
        "\n",
        "### **3. Combination of Categorical Features**\n",
        "\n",
        "CatBoost doesn't just treat categorical features individually; it can automatically combine multiple categorical features into new, more expressive features. For example, if you have `Color` and `Shape` as categorical features, CatBoost might create a new combined feature like `Color_Shape` (e.g., `Red_Circle`).\n",
        "\n",
        "**Efficiency:** This helps the model capture interactions between features that might otherwise be missed, leading to a more powerful model without the need for manual feature engineering of interaction terms.\n",
        "\n",
        "### **4. Ordered Boosting (Permutation-driven Training)**\n",
        "\n",
        "While not exclusively for categorical features, CatBoost's \"ordered boosting\" scheme is closely tied to its categorical feature handling. It uses a different tree-building mechanism where gradient calculations for each tree are based on a subset of the data that doesn't include the current sample being considered for a split. This technique further reduces prediction shift and improves model quality, especially with target-encoded categorical features.\n",
        "\n",
        "### **5. Handling of Missing Categories**\n",
        "\n",
        "CatBoost has built-in mechanisms to handle new or unseen categories in the test set, typically by assigning them a default value or treating them as part of a grouped 'other' category. This makes the model more robust in real-world scenarios.\n",
        "\n",
        "### **In Summary:**\n",
        "\n",
        "CatBoost's efficiency in handling categorical data stems from its intelligent, built-in strategies like ordered target encoding, automatic feature combination, and robust handling of one-hot encoding for low-cardinality features. These techniques reduce the need for extensive manual preprocessing, mitigate target leakage, and lead to more accurate and generalizable models, especially in datasets rich with categorical information."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?**"
      ],
      "metadata": {
        "id": "WdVD7AtxutPX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee4da93"
      },
      "source": [
        "Boosting techniques, due to their sequential nature and focus on reducing bias by correcting errors of previous models, are often preferred over bagging methods (like Random Forest) in scenarios where high accuracy and the ability to capture complex relationships are paramount. While bagging methods reduce variance, boosting primarily aims to reduce bias.\n",
        "\n",
        "Here are some real-world applications where boosting techniques are commonly preferred:\n",
        "\n",
        "### **1. Search Ranking / Information Retrieval**\n",
        "\n",
        "*   **Application:** Ranking web pages, documents, or search results based on relevance to a query.\n",
        "*   **Why Boosting:** Boosting algorithms (especially Gradient Boosting variants like XGBoost and LightGBM) are highly effective in learning complex ranking functions. They can model the intricate relationships between various features (e.g., query-document relevance, click-through rates, document authority) to produce highly accurate and relevant rankings. Their ability to minimize a custom loss function makes them ideal for optimizing ranking metrics like NDCG (Normalized Discounted Cumulative Gain).\n",
        "\n",
        "### **2. Fraud Detection**\n",
        "\n",
        "*   **Application:** Identifying fraudulent transactions (credit card, insurance, etc.) or activities.\n",
        "*   **Why Boosting:** Fraud detection often involves highly imbalanced datasets and subtle patterns. Boosting algorithms can iteratively learn from misclassified fraudulent cases (which are typically rare) and assign them higher weights, leading to models with higher recall and precision in identifying fraud. XGBoost, in particular, is widely used for its robust performance and regularization features that prevent overfitting to the majority class.\n",
        "\n",
        "### **3. Customer Churn Prediction**\n",
        "\n",
        "*   **Application:** Predicting which customers are likely to cancel a subscription or switch providers.\n",
        "*   **Why Boosting:** Churn prediction requires understanding complex customer behavior patterns across various features (usage history, demographics, interaction data). Boosting models can effectively capture these non-linear relationships and interactions between features, providing accurate predictions that allow businesses to intervene proactively.\n",
        "\n",
        "### **4. Ad Click-Through Rate (CTR) Prediction**\n",
        "\n",
        "*   **Application:** Predicting the probability that a user will click on a given advertisement.\n",
        "*   **Why Boosting:** CTR prediction is crucial for ad targeting and revenue generation. It involves vast datasets with many categorical features and complex interactions. CatBoost, with its efficient handling of categorical features and ordered boosting, and LightGBM, with its speed and memory efficiency, are frequently used to build highly accurate CTR prediction models.\n",
        "\n",
        "### **5. Credit Scoring and Risk Assessment**\n",
        "\n",
        "*   **Application:** Evaluating the creditworthiness of loan applicants or assessing risk in financial markets.\n",
        "*   **Why Boosting:** Accurate risk assessment is critical in finance. Boosting models can learn from historical data to identify key indicators of default or risk, offering precise probability estimates. Their robustness and ability to handle various data types make them suitable for these sensitive applications.\n",
        "\n",
        "### **6. Medical Diagnosis and Prognosis**\n",
        "\n",
        "*   **Application:** Predicting disease outcomes, diagnosing conditions, or identifying risk factors.\n",
        "*   **Why Boosting:** In medical contexts, high accuracy and the ability to combine information from diverse features (patient demographics, lab results, medical history) are vital. Boosting algorithms can create powerful predictive models, assisting clinicians in making informed decisions. However, interpretability is also key in this domain, and techniques to interpret tree-based models are often employed.\n",
        "\n",
        "### **7. Recommendation Systems**\n",
        "\n",
        "*   **Application:** Recommending products, movies, or content to users.\n",
        "*   **Why Boosting:** While collaborative filtering and matrix factorization are common, boosting can be used in combination with other techniques or directly for tasks like predicting user ratings or whether a user will interact with a recommended item. They can leverage rich feature sets about users and items to refine recommendations.\n",
        "\n",
        "In general, boosting is preferred when:\n",
        "\n",
        "*   **High Accuracy is Critical:** Boosting typically achieves higher accuracy than bagging methods, especially when the weak learners are already quite good.\n",
        "*   **Complex Relationships Exist:** Boosting can uncover complex non-linear relationships and interactions within the data.\n",
        "*   **Bias Reduction is the Main Goal:** Boosting excels at reducing the bias component of prediction error.\n",
        "\n",
        "However, it's also worth noting that boosting can be more prone to overfitting if not properly regularized, and bagging methods (like Random Forest) are generally more robust to noise and outliers and are inherently more parallelizable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: Write a Python program to: ● Train an AdaBoost Classifier on the Breast Cancer dataset ● Print the model accuracy**\n",
        "\n",
        "Use sklearn.datasets.load_breast_cancer() for classification tasks."
      ],
      "metadata": {
        "id": "lwYsfAHWvEp0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "815e0ce9",
        "outputId": "970cac56-4ffd-4e01-893d-34f3da43242a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Display the first few rows of the features and target\n",
        "print(\"Features (X) head:\")\n",
        "display(X.head())\n",
        "print(\"Target (y) head:\")\n",
        "display(y.head())\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Check the shapes of the split data\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# 3. Train an AdaBoost Classifier\n",
        "\n",
        "# AdaBoost typically uses weak learners, often shallow decision trees.\n",
        "# Here, we'll use a DecisionTreeClassifier with max_depth=1 (a decision stump) as the base estimator.\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
        "\n",
        "adaboost_model = AdaBoostClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,  # Number of weak learners to train\n",
        "    learning_rate=1.0, # Contribution of each classifier to the ensemble\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions on the test set\n",
        "y_pred = adaboost_model.predict(X_test)\n",
        "\n",
        "# 5. Print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAdaBoost Classifier Accuracy on Breast Cancer Dataset: {accuracy:.4f}\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ed52079-ca98-4434-98de-b0993d5b19cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ed52079-ca98-4434-98de-b0993d5b19cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ed52079-ca98-4434-98de-b0993d5b19cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ed52079-ca98-4434-98de-b0993d5b19cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-20e8ba92-5a60-4cf0-a294-b962a58b8ec5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20e8ba92-5a60-4cf0-a294-b962a58b8ec5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-20e8ba92-5a60-4cf0-a294-b962a58b8ec5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target (y) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (398, 30)\n",
            "X_test shape: (171, 30)\n",
            "y_train shape: (398,)\n",
            "y_test shape: (171,)\n",
            "\n",
            "AdaBoost Classifier Accuracy on Breast Cancer Dataset: 0.9532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 7: Write a Python program to: ● Train a Gradient Boosting Regressor on the California Housing dataset ● Evaluate performance using R-squared score**\n",
        "\n",
        "Use sklearn.datasets.fetch_california_housing() for regression\n",
        "tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ulVIoE-Pvqn-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "248635b2",
        "outputId": "4ebd88f7-edef-4197-ec74-71e0ff324d3d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "y = pd.Series(housing.target)\n",
        "\n",
        "# Display the first few rows of the features and target\n",
        "print(\"Features (X) head:\")\n",
        "display(X.head())\n",
        "print(\"Target (y) head:\")\n",
        "display(y.head())\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Check the shapes of the split data\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# 3. Train a Gradient Boosting Regressor\n",
        "\n",
        "gbr_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,  # Number of boosting stages\n",
        "    learning_rate=0.1, # Step size shrinkage to prevent overfitting\n",
        "    max_depth=3,       # Maximum depth of the individual regression estimators\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gbr_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions on the test set\n",
        "y_pred = gbr_model.predict(X_test)\n",
        "\n",
        "# 5. Evaluate performance using R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"\\nGradient Boosting Regressor R-squared Score on California Housing Dataset: {r2:.4f}\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
              "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
              "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
              "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
              "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
              "\n",
              "   Longitude  \n",
              "0    -122.23  \n",
              "1    -122.22  \n",
              "2    -122.24  \n",
              "3    -122.25  \n",
              "4    -122.25  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3b3b27-1d2c-447d-8da8-9f0a657c1b86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3b3b27-1d2c-447d-8da8-9f0a657c1b86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b3b3b27-1d2c-447d-8da8-9f0a657c1b86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b3b3b27-1d2c-447d-8da8-9f0a657c1b86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d602979e-f151-4e20-ac71-4dd7c47f9752\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d602979e-f151-4e20-ac71-4dd7c47f9752')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d602979e-f151-4e20-ac71-4dd7c47f9752 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"\\\\nGradient Boosting Regressor R-squared Score on California Housing Dataset: {r2:\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"MedInc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9218775476080674,\n        \"min\": 3.8462,\n        \"max\": 8.3252,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.3014,\n          3.8462,\n          7.2574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HouseAge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.501851724856113,\n        \"min\": 21.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          41.0,\n          21.0,\n          52.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AveRooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9705323807243326,\n        \"min\": 5.8173515981735155,\n        \"max\": 8.288135593220339,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.238137082601054,\n          6.281853281853282,\n          8.288135593220339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AveBedrms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04661885487529508,\n        \"min\": 0.9718804920913884,\n        \"max\": 1.0810810810810811,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9718804920913884,\n          1.0810810810810811,\n          1.073446327683616\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 862.3365352343596,\n        \"min\": 322.0,\n        \"max\": 2401.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2401.0,\n          565.0,\n          496.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AveOccup\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2881316535489867,\n        \"min\": 2.109841827768014,\n        \"max\": 2.8022598870056497,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.109841827768014,\n          2.1814671814671813,\n          2.8022598870056497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0130384048104057,\n        \"min\": 37.85,\n        \"max\": 37.88,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          37.88,\n          37.86,\n          37.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013038404810404884,\n        \"min\": -122.25,\n        \"max\": -122.22,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -122.22,\n          -122.25,\n          -122.23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target (y) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    4.526\n",
              "1    3.585\n",
              "2    3.521\n",
              "3    3.413\n",
              "4    3.422\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (14448, 8)\n",
            "X_test shape: (6192, 8)\n",
            "y_train shape: (14448,)\n",
            "y_test shape: (6192,)\n",
            "\n",
            "Gradient Boosting Regressor R-squared Score on California Housing Dataset: 0.7803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8: Write a Python program to: ● Train an XGBoost Classifier on the Breast Cancer dataset ● Tune the learning rate using GridSearchCV ● Print the best parameters and accuracy**\n",
        "\n",
        "Use sklearn.datasets.load_breast_cancer() for classification tasks."
      ],
      "metadata": {
        "id": "L5BxWbIxwYn1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "312efda5",
        "outputId": "702023dd-fac4-45ac-bdf1-0e74dbfcf31f"
      },
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Display the first few rows of the features and target\n",
        "print(\"Features (X) head:\")\n",
        "display(X.head())\n",
        "print(\"Target (y) head:\")\n",
        "display(y.head())\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Check the shapes of the split data\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# 3. Initialize XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic', # For binary classification\n",
        "    eval_metric='logloss',       # Evaluation metric for optimization\n",
        "    use_label_encoder=False,     # Suppress warning about label encoder\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 4. Define the parameter grid for GridSearchCV (tuning learning rate)\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# 5. Setup GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy', # Use accuracy as the scoring metric\n",
        "    cv=5,               # 5-fold cross-validation\n",
        "    verbose=1,          # Output progress\n",
        "    n_jobs=-1           # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# 6. Train with GridSearchCV to find the best learning rate\n",
        "print(\"\\nStarting GridSearchCV for learning_rate tuning...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Print the best parameters and best score\n",
        "print(\"\\nBest parameters found by GridSearchCV:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# 8. Evaluate the best model on the test set\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "y_pred = best_xgb_model.predict(X_test)\n",
        "\n",
        "# 9. Print the model accuracy on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nXGBoost Classifier Accuracy on Test Set with best parameters: {accuracy:.4f}\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-208f0b46-6745-4373-90a2-36a810142c05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-208f0b46-6745-4373-90a2-36a810142c05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-208f0b46-6745-4373-90a2-36a810142c05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-208f0b46-6745-4373-90a2-36a810142c05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1c8aef3-b28b-473b-977f-89d27ccf0812\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1c8aef3-b28b-473b-977f-89d27ccf0812')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1c8aef3-b28b-473b-977f-89d27ccf0812 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target (y) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (398, 30)\n",
            "X_test shape: (171, 30)\n",
            "y_train shape: (398,)\n",
            "y_test shape: (171,)\n",
            "\n",
            "Starting GridSearchCV for learning_rate tuning...\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:28:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters found by GridSearchCV: {'learning_rate': 0.05}\n",
            "Best cross-validation accuracy: 0.9650000000000001\n",
            "\n",
            "XGBoost Classifier Accuracy on Test Set with best parameters: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 9: Write a Python program to: ● Train a CatBoost Classifier ● Plot the confusion matrix using seaborn**"
      ],
      "metadata": {
        "id": "8NlsQWuuxDRi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f478f6cb",
        "outputId": "3ccb495e-78e4-4584-a02f-e55a5e5979f4"
      },
      "source": [
        "# Install CatBoost if you haven't already\n",
        "!pip install catboost -qq"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "833b6c3d",
        "outputId": "248db3f4-f137-496e-ec64-ceeb9b279750"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Display the first few rows of the features and target\n",
        "print(\"Features (X) head:\")\n",
        "display(X.head())\n",
        "print(\"Target (y) head:\")\n",
        "display(y.head())\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Check the shapes of the split data\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# 3. Train a CatBoost Classifier\n",
        "print(\"\\nTraining CatBoost Classifier...\")\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=100, # Number of boosting iterations\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    loss_function='Logloss', # For binary classification\n",
        "    eval_metric='Accuracy',\n",
        "    random_seed=42,\n",
        "    verbose=0, # Suppress verbose output during training\n",
        "    # CatBoost handles categorical features automatically if specified.\n",
        "    # For this dataset, all features are numerical, so no need to specify cat_features.\n",
        ")\n",
        "\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions on the test set\n",
        "y_pred = cat_model.predict(X_test)\n",
        "\n",
        "# 5. Print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nCatBoost Classifier Accuracy on Breast Cancer Dataset: {accuracy:.4f}\")\n",
        "\n",
        "# 6. Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.title('Confusion Matrix for CatBoost Classifier')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e48cab77-69bf-4094-9fb7-798817f1eb20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e48cab77-69bf-4094-9fb7-798817f1eb20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e48cab77-69bf-4094-9fb7-798817f1eb20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e48cab77-69bf-4094-9fb7-798817f1eb20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-22ee48b0-a402-4a6f-9a14-d03ce7771ecd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22ee48b0-a402-4a6f-9a14-d03ce7771ecd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-22ee48b0-a402-4a6f-9a14-d03ce7771ecd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target (y) head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (398, 30)\n",
            "X_test shape: (171, 30)\n",
            "y_train shape: (398,)\n",
            "y_test shape: (171,)\n",
            "\n",
            "Training CatBoost Classifier...\n",
            "\n",
            "CatBoost Classifier Accuracy on Breast Cancer Dataset: 0.9532\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features. Describe your step-by-step data science pipeline using boosting techniques: ● Data preprocessing & handling missing categorical values ● Choice between AdaBoost, XGBoost, or CatBoost ● Hyperparameter tuning strategy ● Evaluation metrics you'd choose and why ● How the business would benefit from your model**"
      ],
      "metadata": {
        "id": "qEhqEOYix3Gs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20f9942c"
      },
      "source": [
        "# Task\n",
        "- **Describe Data Science Pipeline**: Generate a markdown cell describing a step-by-step data science pipeline for predicting loan default. This will cover data preprocessing (handling missing values and categorical features), model choice among boosting techniques (AdaBoost, XGBoost, CatBoost), hyperparameter tuning strategy, chosen evaluation metrics with justifications, and the business benefits of the model. The description will specifically address the challenges of an imbalanced dataset and mixed feature types.\n",
        "- **Final Task**: Provide a comprehensive summary of the proposed data science pipeline, emphasizing key decisions and their rationale for predicting loan default in a FinTech context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9de0641a"
      },
      "source": [
        "## Describe Data Science Pipeline\n",
        "\n",
        "### Subtask:\n",
        "Generate a markdown cell describing a step-by-step data science pipeline for predicting loan default, covering data preprocessing, model choice, hyperparameter tuning, evaluation metrics, and business benefits, while addressing imbalanced datasets and mixed feature types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334d3085"
      },
      "source": [
        "## Describe Data Science Pipeline: Loan Default Prediction for FinTech\n",
        "\n",
        "This section outlines a step-by-step data science pipeline for predicting loan default, specifically tailored for a FinTech company dealing with customer demographics and transaction behavior data. The dataset is characterized by being imbalanced, containing missing values, and having both numeric and categorical features.\n",
        "\n",
        "### 1. Data Understanding and Initial Exploration\n",
        "\n",
        "Before any processing, it's crucial to thoroughly understand the dataset. This involves:\n",
        "\n",
        "*   **Schema Review:** Understanding the meaning and type of each feature (e.g., customer age, income, credit score, loan amount, transaction frequency, payment history). Identify the target variable (loan default: binary classification).\n",
        "*   **Descriptive Statistics:** Calculating basic statistics (mean, median, standard deviation) for numerical features and frequency distributions for categorical features.\n",
        "*   **Missing Value Identification:** Quantifying the extent and patterns of missing data across all features.\n",
        "*   **Outlier Detection:** Identifying extreme values in numerical features that might impact model training.\n",
        "*   **Feature Type Verification:** Confirming whether features are truly numerical or categorical, and identifying any mixed-type columns.\n",
        "*   **Imbalance Check:** Assessing the distribution of the target variable to confirm the degree of class imbalance (e.g., percentage of defaults vs. non-defaults).\n",
        "\n",
        "Initial exploration helps in identifying immediate challenges and informs subsequent preprocessing steps.\n",
        "\n",
        "### 2. Data Preprocessing and Handling Missing Values\n",
        "\n",
        "Handling missing values effectively is critical, as boosting algorithms generally do not handle `NaN` values directly (though some, like XGBoost, have native support for a few strategies):\n",
        "\n",
        "*   **Numerical Features:**\n",
        "    *   **Imputation:** Simple strategies include imputing with the `mean`, `median` (more robust to outliers), or `mode`. More sophisticated methods could involve `k-NN imputation` or using predictive models to estimate missing values.\n",
        "    *   **Indicator Variables:** Creating a binary indicator variable for each feature where missing values were imputed, signifying the presence of a missing value. This allows the model to learn if 'missingness' itself is predictive.\n",
        "*   **Categorical Features:**\n",
        "    *   **Imputation:** Impute with the `mode` or, preferably, create a new `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2a645e3"
      },
      "source": [
        "## Describe Data Science Pipeline: Loan Default Prediction for FinTech\n",
        "\n",
        "This section outlines a step-by-step data science pipeline for predicting loan default, specifically tailored for a FinTech company dealing with customer demographics and transaction behavior data. The dataset is characterized by being imbalanced, containing missing values, and having both numeric and categorical features.\n",
        "\n",
        "### 1. Data Understanding and Initial Exploration\n",
        "\n",
        "Before any processing, it's crucial to thoroughly understand the dataset. This involves:\n",
        "\n",
        "*   **Schema Review:** Understanding the meaning and type of each feature (e.g., customer age, income, credit score, loan amount, transaction frequency, payment history). Identify the target variable (loan default: binary classification).\n",
        "*   **Descriptive Statistics:** Calculating basic statistics (mean, median, standard deviation) for numerical features and frequency distributions for categorical features.\n",
        "*   **Missing Value Identification:** Quantifying the extent and patterns of missing data across all features.\n",
        "*   **Outlier Detection:** Identifying extreme values in numerical features that might impact model training.\n",
        "*   **Feature Type Verification:** Confirming whether features are truly numerical or categorical, and identifying any mixed-type columns.\n",
        "*   **Imbalance Check:** Assessing the distribution of the target variable to confirm the degree of class imbalance (e.g., percentage of defaults vs. non-defaults).\n",
        "\n",
        "Initial exploration helps in identifying immediate challenges and informs subsequent preprocessing steps.\n",
        "\n",
        "### 2. Data Preprocessing and Handling Missing Values\n",
        "\n",
        "Handling missing values effectively is critical, as boosting algorithms generally do not handle `NaN` values directly (though some, like XGBoost, have native support for a few strategies):\n",
        "\n",
        "*   **Numerical Features:**\n",
        "    *   **Imputation:** Simple strategies include imputing with the `mean`, `median` (more robust to outliers), or `mode`. More sophisticated methods could involve `k-NN imputation` or using predictive models to estimate missing values.\n",
        "    *   **Indicator Variables:** Creating a binary indicator variable for each feature where missing values were imputed, signifying the presence of a missing value. This allows the model to learn if 'missingness' itself is predictive.\n",
        "*   **Categorical Features:**\n",
        "    *   **Imputation:** Impute with the `mode` or, preferably, create a new `'Missing'` category to explicitly signal missingness to the model. This is often better than simply imputing the mode, as 'missing' can sometimes be a predictive category.\n",
        "    *   **CatBoost's Inherent Handling:** CatBoost can handle missing categorical values automatically. If a categorical feature has missing values, CatBoost can treat them as a special category, removing the need for explicit imputation for these features.\n",
        "\n",
        "*   **Outlier Treatment (if applicable):** Depending on the analysis during exploration, outliers in numerical features might be capped (winsorization) or transformed (e.g., log transformation) to reduce their disproportionate influence on the model.\n",
        "\n",
        "### 3. Handling Categorical Features\n",
        "\n",
        "Appropriate encoding of categorical features is crucial for tree-based models:\n",
        "\n",
        "*   **One-Hot Encoding:** For categorical features with **low cardinality** (a small number of unique values), One-Hot Encoding is a standard approach. It creates new binary features for each category, preventing the model from assuming any ordinal relationship.\n",
        "*   **Target Encoding / Ordered Encoding:** For features with **high cardinality** (many unique values), One-Hot Encoding can lead to a very sparse dataset and curse of dimensionality. Target encoding (e.g., replacing a category with the mean of the target variable for that category) is a more compact alternative. However, it's prone to target leakage. CatBoost's **Ordered Target Encoding** (as discussed in a previous question) is a sophisticated variant that prevents target leakage by calculating target statistics only on previously seen data points in a random permutation. This is highly beneficial for FinTech datasets with potentially many high-cardinality categorical features (e.g., transaction types, merchant IDs).\n",
        "*   **CatBoost's Automatic Handling:** A significant advantage of CatBoost is its ability to directly handle categorical features without explicit preprocessing. By declaring columns as categorical, CatBoost applies its ordered target encoding and can combine categorical features internally, reducing manual effort and preventing leakage issues. This makes it a strong candidate for this problem.\n",
        "\n",
        "### 4. Addressing Imbalanced Dataset\n",
        "\n",
        "Loan default datasets are inherently imbalanced (far fewer defaults than non-defaults). Ignoring this leads to models that are biased towards the majority class and perform poorly on the minority class (defaults), which is usually the class of interest. Strategies include:\n",
        "\n",
        "*   **Resampling Techniques:**\n",
        "    *   **Oversampling:** Increasing the number of samples in the minority class. Techniques like **SMOTE (Synthetic Minority Over-sampling Technique)** generate synthetic samples based on existing minority class instances.\n",
        "    *   **Undersampling:** Reducing the number of samples in the majority class. This can lead to loss of information but can be effective for very large datasets.\n",
        "    *   **Combined Approaches:** Using a combination of oversampling the minority and undersampling the majority class (e.g., SMOTE + ENN).\n",
        "*   **Algorithmic Approaches:**\n",
        "    *   **Class Weights:** Many boosting algorithms (XGBoost, CatBoost, AdaBoost) allow assigning higher weights to the minority class samples during training. This forces the model to pay more attention to misclassifying defaults.\n",
        "    *   **Cost-Sensitive Learning:** Adjusting the cost of misclassification errors, making misclassifying a default more expensive than misclassifying a non-default.\n",
        "*   **Ensemble Methods Designed for Imbalance:** Some specialized ensemble methods exist, but for boosting, adjusting class weights or resampling are common and effective.\n",
        "\n",
        "### 5. Model Choice (Boosting Techniques)\n",
        "\n",
        "Given the requirements for high accuracy and handling complex relationships, boosting techniques are excellent choices. Here's a comparison and justification for a FinTech loan default prediction model:\n",
        "\n",
        "*   **AdaBoost:**\n",
        "    *   **Pros:** Conceptually simple, effective as a baseline, focuses on hard-to-classify samples.\n",
        "    *   **Cons:** Highly sensitive to noisy data and outliers, may not perform as well as gradient boosting variants on complex, high-dimensional data, can be slower than GBMs on large datasets.\n",
        "    *   **Suitability for FinTech:** Could serve as a solid baseline, but likely to be outperformed by more advanced methods given the potential for noise and complex interactions in financial data.\n",
        "\n",
        "*   **XGBoost:**\n",
        "    *   **Pros:** Highly optimized for performance (speed and memory), excellent regularization capabilities (L1/L2, shrinkage, subsampling) to prevent overfitting, handles sparse data well, flexible objective functions, widely adopted and well-documented.\n",
        "    *   **Cons:** Requires careful hyperparameter tuning, still needs explicit handling of categorical features (one-hot, target encoding) before feeding to the model, although it can handle missing values.\n",
        "    *   **Suitability for FinTech:** A very strong contender. Its speed and regularization are excellent for large financial datasets, and its robustness makes it reliable. The main caveat is the need for careful categorical feature preprocessing.\n",
        "\n",
        "*   **CatBoost:**\n",
        "    *   **Pros:** State-of-the-art for handling categorical features automatically and robustly (Ordered Target Encoding prevents leakage), less prone to overfitting due to ordered boosting, good default parameters, often achieves high accuracy with less tuning effort.\n",
        "    *   **Cons:** Can be slower to train than LightGBM (though often faster than XGBoost with optimal settings), less mature community/documentation than XGBoost.\n",
        "    *   **Suitability for FinTech:** **Highly Recommended.** Given the problem statement explicitly mentioning 'customer demographics and transaction behavior' (which implies many categorical features) and missing values, CatBoost's native, robust handling of categorical features and missing data is a significant advantage. It reduces the risk of data leakage and simplifies the preprocessing pipeline, potentially leading to a more robust and accurate model with less manual feature engineering.\n",
        "\n",
        "**Final Model Choice:** CatBoost would likely be the preferred choice due to its superior and automatic handling of categorical features and robustness against target leakage, which are critical in this FinTech context. XGBoost would be a close second, especially if speed is paramount and categorical feature preprocessing can be managed effectively.\n",
        "\n",
        "### 6. Hyperparameter Tuning Strategy\n",
        "\n",
        "Optimizing model performance requires thorough hyperparameter tuning:\n",
        "\n",
        "*   **Cross-Validation:** Always use k-fold cross-validation (e.g., 5-fold or 10-fold) to ensure the robustness of the model and prevent overfitting to the validation set during tuning. Stratified K-Fold should be used for imbalanced datasets to maintain the class distribution in each fold.\n",
        "*   **Search Strategies:**\n",
        "    *   **GridSearchCV:** Exhaustively searches over a specified parameter grid. Good for exploring a small, defined range of parameters.\n",
        "    *   **RandomizedSearchCV:** Samples a fixed number of parameter settings from specified distributions. More efficient than GridSearchCV for larger search spaces.\n",
        "    *   **Bayesian Optimization (e.g., using Hyperopt, Optuna):** More advanced and efficient, it builds a probabilistic model of the objective function (e.g., accuracy/F1-score) and selects hyperparameters that are most promising to explore. This is ideal for complex models like boosting with many hyperparameters.\n",
        "*   **Key Hyperparameters for CatBoost (or XGBoost):**\n",
        "    *   `iterations`/`n_estimators`: Number of boosting rounds (trees).\n",
        "    *   `learning_rate`/`eta`: Step size shrinkage, controls the contribution of each tree.\n",
        "    *   `depth`/`max_depth`: Maximum depth of the trees.\n",
        "    *   `l2_leaf_reg`/`lambda`: L2 regularization term on weights (XGBoost) or leaf values (CatBoost).\n",
        "    *   `subsample`: Fraction of samples used for fitting the individual base learners.\n",
        "    *   `colsample_bylevel`/`colsample_bytree`: Fraction of features considered for splits.\n",
        "    *   `min_child_samples`/`min_child_weight`: Minimum number of samples (CatBoost) or sum of instance weight (XGBoost) required in a child node.\n",
        "    *   `scale_pos_weight`/`is_unbalanced`: For handling class imbalance by giving more weight to the minority class.\n",
        "\n",
        "### 7. Evaluation Metrics\n",
        "\n",
        "For an imbalanced binary classification task like loan default prediction, accuracy alone is insufficient and misleading. Instead, focus on metrics that provide insight into the model's performance on both classes, especially the minority class (defaults):\n",
        "\n",
        "*   **Confusion Matrix:** Provides a full breakdown of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "*   **Precision (Positive Predictive Value):** `TP / (TP + FP)`. What proportion of predicted defaults were actually defaults? High precision minimizes incorrectly flagging good customers as risky.\n",
        "*   **Recall (Sensitivity, True Positive Rate):** `TP / (TP + FN)`. What proportion of actual defaults did the model correctly identify? High recall minimizes missed defaults, which directly translates to reduced financial losses.\n",
        "*   **F1-Score:** The harmonic mean of Precision and Recall. `2 * (Precision * Recall) / (Precision + Recall)`. Provides a balanced measure when both precision and recall are important.\n",
        "*   **AUC-ROC (Area Under the Receiver Operating Characteristic Curve):** Measures the model's ability to distinguish between positive and negative classes across all possible classification thresholds. A high AUC-ROC indicates good overall discrimination.\n",
        "*   **PR-Curve (Precision-Recall Curve):** Particularly useful for highly imbalanced datasets. It plots Precision against Recall for various thresholds. The **Area Under the PR Curve (AUPRC)** is often a more informative metric than AUC-ROC for imbalanced data, as it focuses on the performance of the positive class.\n",
        "\n",
        "**Why Accuracy is Insufficient:** If only 5% of loans default, a model predicting 'no default' for everyone would achieve 95% accuracy, which is deceptively high but useless for the business. Precision, Recall, and F1-Score for the 'default' class, and AUPRC, are far more critical.\n",
        "\n",
        "### 8. Business Benefits of the Model\n",
        "\n",
        "A robust loan default prediction model offers significant tangible benefits for a FinTech company:\n",
        "\n",
        "*   **Reduced Financial Losses:** By accurately identifying high-risk applicants, the company can avoid granting loans that are likely to default, directly saving millions in potential write-offs.\n",
        "*   **Optimized Risk Assessment:** Provides a quantitative and data-driven basis for assessing applicant risk, leading to more consistent and objective lending decisions.\n",
        "*   **Improved Loan Approval Processes:** Streamlines and automates parts of the loan application review, allowing for faster decisions for low-risk applicants and focused human review for borderline cases.\n",
        "*   **Better Customer Segmentation and Personalization:** The insights gained from the model can help segment customers based on their risk profile, allowing for tailored loan products, interest rates, and marketing strategies.\n",
        "*   **Enhanced Regulatory Compliance:** Provides a structured, auditable approach to risk management, aiding in compliance with financial regulations.\n",
        "*   **Dynamic Portfolio Management:** Allows for proactive monitoring of existing loans and identifying early warning signs of potential default, enabling timely interventions.\n",
        "*   **Competitive Advantage:** Superior risk models can enable the company to offer more competitive rates to low-risk customers while prudently managing higher-risk segments, thus attracting a broader customer base.\n",
        "\n",
        "By carefully implementing this pipeline, the FinTech company can transform its loan approval and risk management processes, leading to significant financial gains and a more sustainable business model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3bc29da"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the proposed data science pipeline, emphasizing key decisions and their rationale for predicting loan default in a FinTech context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "741f2270"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Comprehensive Pipeline Design:** A detailed eight-step data science pipeline was formulated for predicting loan default in a FinTech context, addressing crucial aspects from data understanding to business benefits.\n",
        "*   **Robust Data Preprocessing:** The pipeline includes specific strategies for handling missing values (imputation with mean/median/mode, indicator variables, CatBoost's inherent handling) and outliers (capping, transformations).\n",
        "*   **Strategic Categorical Feature Handling:** For mixed feature types, the pipeline recommends One-Hot Encoding for low cardinality features and sophisticated Target Encoding (specifically CatBoost's Ordered Target Encoding to prevent leakage) for high cardinality features, leveraging CatBoost's automatic capabilities.\n",
        "*   **Effective Imbalance Management:** To counter the inherent class imbalance in loan default data, the pipeline proposes both resampling techniques (SMOTE, undersampling) and algorithmic approaches (class weights, cost-sensitive learning), coupled with stratified k-fold cross-validation.\n",
        "*   **Optimized Model Selection:** CatBoost was *highly recommended* as the primary model choice among boosting techniques (AdaBoost, XGBoost, CatBoost). This decision was based on its superior and automatic handling of categorical features, its robustness against target leakage via Ordered Target Encoding, and its suitability for complex FinTech datasets. XGBoost was noted as a strong alternative for its performance and regularization capabilities.\n",
        "*   **Advanced Hyperparameter Tuning:** The pipeline advocates for hyperparameter optimization using advanced methods like Bayesian Optimization, alongside traditional GridSearchCV and RandomizedSearchCV, ensuring robust model performance.\n",
        "*   **Appropriate Evaluation Metrics:** It emphasizes using metrics beyond simple accuracy, such as Precision, Recall, F1-Score, AUC-ROC, and crucially, Area Under the Precision-Recall Curve (AUPRC), highlighting their importance for imbalanced datasets where the minority class (defaults) is of paramount interest.\n",
        "*   **Clear Business Value Proposition:** The described model is projected to deliver significant business benefits, including reduced financial losses, optimized risk assessment, improved loan approval processes, better customer segmentation, and enhanced regulatory compliance.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The comprehensive pipeline provides a strong theoretical foundation for building a robust loan default prediction system; the immediate next step should involve implementing this pipeline using actual FinTech data to validate its practical effectiveness and fine-tune its components.\n",
        "*   The emphasis on CatBoost and specific encoding strategies for categorical features highlights a proactive approach to mitigating data leakage and handling complex data characteristics, which is a critical success factor in high-stakes financial modeling.\n"
      ]
    }
  ]
}