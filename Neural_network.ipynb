{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network - A Simple Perceptron Assignment**"
      ],
      "metadata": {
        "id": "VNrVzIC0Yy5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: What is Deep Learning? Briefly describe how it evolved and how it differs from traditional machine learning.**"
      ],
      "metadata": {
        "id": "p6FkSefVZCE8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41e8c89a"
      },
      "source": [
        "### **What is Deep Learning?**\n",
        "\n",
        "Deep Learning is a subfield of machine learning that uses artificial neural networks with multiple layers (hence \"deep\") to learn representations of data with multiple levels of abstraction. These networks are inspired by the structure and function of the human brain. Instead of requiring human engineers to identify features from data, deep learning models can automatically learn these features from raw data.\n",
        "\n",
        "### **How it evolved:**\n",
        "\n",
        "Deep learning's evolution can be traced through several key periods:\n",
        "\n",
        "1.  **Early Foundations (1940s-1960s):**\n",
        "    *   **Perceptron (1950s):** Frank Rosenblatt developed the Perceptron, one of the first artificial neural networks capable of learning from data. However, it had limitations, notably its inability to solve non-linearly separable problems.\n",
        "    *   **Backpropagation (1970s-1980s):** The backpropagation algorithm, crucial for training multi-layered neural networks, was rediscovered and popularized by researchers like Rumelhart, Hinton, and Williams. This allowed networks to learn complex patterns by adjusting weights based on error.\n",
        "\n",
        "2.  **\"AI Winter\" and Revival (1990s-early 2000s):**\n",
        "    *   Despite early promise, neural networks faced challenges like vanishing gradients (making it hard to train deep networks) and the lack of computational power and large datasets. This led to a period of reduced interest.\n",
        "    *   **Breakthroughs (2000s):** Researchers like Geoffrey Hinton introduced techniques such as unsupervised pre-training and Restricted Boltzmann Machines (RBMs) to initialize network weights more effectively, alleviating some training difficulties.\n",
        "\n",
        "3.  **Modern Deep Learning Boom (2010s-Present):**\n",
        "    *   **Increased Computational Power:** The advent of powerful GPUs made it feasible to train very large and deep neural networks in reasonable timeframes.\n",
        "    *   **Large Datasets:** The explosion of digital data provided the massive amounts of labeled data necessary for deep learning models to excel.\n",
        "    *   **Algorithmic Improvements:** Innovations like Rectified Linear Units (ReLU) activation functions, dropout regularization, and new optimization algorithms (e.g., Adam) further improved training efficiency and performance.\n",
        "    *   **Architectural Advances:** The development of sophisticated architectures like Convolutional Neural Networks (CNNs) for image processing and Recurrent Neural Networks (RNNs)/Transformers for sequential data (like text and speech) led to significant breakthroughs in various fields.\n",
        "\n",
        "### **How it differs from traditional machine learning:**\n",
        "\n",
        "| Feature              | Traditional Machine Learning                      | Deep Learning                                         |\n",
        "| :------------------- | :------------------------------------------------ | :---------------------------------------------------- |\n",
        "| **Feature Extraction** | Manual, hand-crafted by domain experts             | Automatic, learned hierarchical features from raw data |\n",
        "| **Data Scale**       | Performs well with smaller datasets               | Requires large amounts of data to perform optimally   |\n",
        "| **Performance**      | Performance often plateaus with more data          | Performance tends to improve with more data           |\n",
        "| **Model Complexity** | Typically shallower models (e.g., SVM, Decision Trees) | Very deep neural networks with many layers            |\n",
        "| **Computational Power** | Less computationally intensive                    | Highly computationally intensive (GPUs often required) |\n",
        "| **Interpretability** | Often more interpretable (e.g., feature importance) | Often less interpretable, considered a \"black box\"   |\n",
        "| **Problem Domains**  | Structured data (tabular), some image/text tasks  | Unstructured data (images, text, audio, video), complex structured data |\n",
        "\n",
        "In essence, deep learning automates much of the feature engineering process that is critical (and often laborious) in traditional machine learning, allowing it to discover intricate patterns in complex, high-dimensional data that might be missed by human-defined features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: Explain the basic architecture and functioning of a Perceptron. What are its limitations?**"
      ],
      "metadata": {
        "id": "0a22gl3zZe9Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75f25fb3"
      },
      "source": [
        "### **What is a Perceptron?**\n",
        "\n",
        "A Perceptron is the simplest form of an artificial neural network, inspired by the biological neuron. It's a linear classifier used for supervised learning of binary classifiers. It was developed by Frank Rosenblatt in 1957.\n",
        "\n",
        "### **Basic Architecture of a Perceptron:**\n",
        "\n",
        "A typical Perceptron consists of the following components:\n",
        "\n",
        "1.  **Input Layer:** Receives input features (e.g., `x1, x2, ..., xn`). Each input feature is a numerical value.\n",
        "2.  **Weights (`w`):** Each input `x_i` is associated with a weight `w_i`. These weights represent the strength or importance of each input feature. During training, the Perceptron learns to adjust these weights.\n",
        "3.  **Bias (`b`):** A bias term is added to the weighted sum. It allows the Perceptron to shift the activation function curve up or down, making it more flexible. It acts like an intercept in a linear equation.\n",
        "4.  **Weighted Sum:** The inputs are multiplied by their respective weights, and these products are summed together, along with the bias. This is often called the *net input* or *pre-activation value* (`z`):\n",
        "\n",
        "    `z = (x1 * w1) + (x2 * w2) + ... + (xn * wn) + b`\n",
        "\n",
        "    This can also be written in vector form as `z = W * X + b`, where `W` is the weight vector and `X` is the input vector.\n",
        "\n",
        "5.  **Activation Function:** The weighted sum `z` is then passed through an activation function. For a simple Perceptron, this is typically a **step function** (or Heaviside step function). If the net input `z` exceeds a certain threshold (often 0), the Perceptron outputs 1; otherwise, it outputs 0 (or -1).\n",
        "\n",
        "    *   `Output = 1` if `z >= threshold`\n",
        "    *   `Output = 0` if `z < threshold`\n",
        "\n",
        "    (Note: The bias term `b` can also be thought of as a negative threshold, absorbed into the weighted sum calculation.)\n",
        "\n",
        "### **Functioning of a Perceptron:**\n",
        "\n",
        "The Perceptron operates in two main phases:\n",
        "\n",
        "1.  **Forward Pass (Prediction):**\n",
        "    *   It takes a set of input features.\n",
        "    *   Calculates the weighted sum of these inputs and adds the bias.\n",
        "    *   Applies the activation function to this sum to produce an output (a classification, typically 0 or 1).\n",
        "\n",
        "2.  **Learning (Weight Update):**\n",
        "    *   During training, the Perceptron compares its predicted output with the actual (target) output.\n",
        "    *   If there's a mismatch, it adjusts its weights and bias using the **Perceptron learning rule**. This rule updates the weights in proportion to the error and the input, moving the decision boundary closer to correctly classifying the misclassified point.\n",
        "    *   The update rule for weights `w_i` and bias `b` for a misclassified example is:\n",
        "        *   `w_i = w_i + learning_rate * (target - predicted) * x_i`\n",
        "        *   `b = b + learning_rate * (target - predicted)`\n",
        "    *   This process iterates over many training examples until the Perceptron correctly classifies all (or most) training data, or until a maximum number of iterations is reached.\n",
        "\n",
        "### **Limitations of a Perceptron:**\n",
        "\n",
        "The most significant limitation of a single-layer Perceptron is its inability to solve **non-linearly separable problems**.\n",
        "\n",
        "*   **Linear Separability:** A Perceptron can only learn to distinguish between classes if those classes can be perfectly separated by a single straight line (in 2D), a plane (in 3D), or a hyperplane (in higher dimensions). These are called linearly separable problems (e.g., AND gate, OR gate).\n",
        "\n",
        "*   **XOR Problem:** The classic example demonstrating this limitation is the XOR (exclusive OR) logic gate. No single straight line can separate the `(0,1)` and `(1,0)` inputs (which output 1) from the `(0,0)` and `(1,1)` inputs (which output 0) in a 2D plane. Because the Perceptron can only form linear decision boundaries, it cannot solve the XOR problem.\n",
        "\n",
        "*   **No Hidden Layers:** The original Perceptron model lacks hidden layers, which are crucial for learning complex, non-linear relationships in data. This limitation was largely overcome with the advent of multi-layer Perceptrons (MLPs) and the backpropagation algorithm, leading to the development of deeper neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: Describe the purpose of activation function in neural networks. Compare Sigmoid, ReLU, and Tanh functions.**"
      ],
      "metadata": {
        "id": "Sdoa643zZvQG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac1010f"
      },
      "source": [
        "### **Purpose of Activation Functions in Neural Networks:**\n",
        "\n",
        "Activation functions are critical components within artificial neural networks, introduced at the output of each neuron (or layer). Their primary purpose is to introduce **non-linearity** into the network's output. Without activation functions, a neural network, regardless of its depth, would simply be performing linear transformations on its inputs. This would limit its ability to learn and model complex, non-linear relationships present in real-world data.\n",
        "\n",
        "Here's why they are important:\n",
        "\n",
        "1.  **Introduce Non-linearity:** Real-world data is often non-linear. Linear models can only learn linear decision boundaries. Activation functions allow neural networks to learn and approximate complex functions and patterns by mapping the output of a neuron to a non-linear range.\n",
        "2.  **Enable Learning of Complex Patterns:** By introducing non-linearity, activation functions enable multi-layer perceptrons to learn more complex features and representations, which is essential for tasks like image recognition, natural language processing, and speech recognition.\n",
        "3.  **Control Output Range:** Some activation functions (like Sigmoid and Tanh) map the output to a specific range (e.g., [0, 1] or [-1, 1]), which can be useful for certain types of output layers (e.g., probability prediction in classification).\n",
        "4.  **Gradient Flow:** The derivative of the activation function plays a crucial role in the backpropagation algorithm, determining how errors are propagated back through the network to update weights.\n",
        "\n",
        "### **Comparison of Sigmoid, ReLU, and Tanh Functions:**\n",
        "\n",
        "Here's a comparison of three commonly used activation functions:\n",
        "\n",
        "#### 1. Sigmoid Function (Logistic Function)\n",
        "\n",
        "*   **Formula:** `σ(x) = 1 / (1 + e^(-x))`\n",
        "*   **Output Range:** (0, 1)\n",
        "*   **Graph:** S-shaped curve.\n",
        "\n",
        "*   **Pros:**\n",
        "    *   Outputs are normalized between 0 and 1, making it suitable for binary classification tasks (e.g., as the output layer where the output can be interpreted as a probability).\n",
        "    *   Smooth gradient, preventing \"jumps\" in output values.\n",
        "\n",
        "*   **Cons:**\n",
        "    *   **Vanishing Gradient Problem:** For very large positive or negative inputs, the sigmoid function becomes saturated (its output is very close to 0 or 1), and its gradient becomes extremely small (close to 0). This makes it difficult for the network to learn, as weight updates become tiny.\n",
        "    *   **Not Zero-centered:** The output is always positive. This can lead to non-zero-centered gradient updates, which can make the optimization process (e.g., gradient descent) less efficient and cause \"zig-zagging\" during training.\n",
        "    *   **Computationally Expensive:** The `exp()` operation is more computationally intensive than simpler functions.\n",
        "\n",
        "#### 2. Tanh Function (Hyperbolic Tangent)\n",
        "\n",
        "*   **Formula:** `tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))`\n",
        "*   **Output Range:** (-1, 1)\n",
        "*   **Graph:** Also S-shaped, similar to Sigmoid but centered at zero.\n",
        "\n",
        "*   **Pros:**\n",
        "    *   **Zero-centered:** Its output is centered around 0, which generally helps in making the optimization process more stable and faster than Sigmoid, as gradients are not always positive.\n",
        "    *   Outputs are normalized between -1 and 1.\n",
        "\n",
        "*   **Cons:**\n",
        "    *   **Vanishing Gradient Problem:** Similar to Sigmoid, Tanh also suffers from the vanishing gradient problem when inputs are very large positive or negative, as the function saturates at -1 and 1.\n",
        "    *   **Computationally Expensive:** Still involves `exp()` operations, making it more expensive than ReLU.\n",
        "\n",
        "#### 3. ReLU Function (Rectified Linear Unit)\n",
        "\n",
        "*   **Formula:** `ReLU(x) = max(0, x)`\n",
        "*   **Output Range:** [0, infinity)\n",
        "*   **Graph:** A straight line that is 0 for negative inputs and `x` for positive inputs.\n",
        "\n",
        "*   **Pros:**\n",
        "    *   **Mitigates Vanishing Gradient:** For positive inputs, the gradient is always 1, which helps in preventing vanishing gradients and speeds up convergence significantly compared to Sigmoid and Tanh.\n",
        "    *   **Computationally Efficient:** Very simple to compute (just a `max` operation).\n",
        "    *   **Sparsity:** Can lead to sparse activations, as neurons output 0 for negative inputs, which can be computationally efficient.\n",
        "\n",
        "*   **Cons:**\n",
        "    *   **Dying ReLU Problem:** For negative inputs, the gradient is 0. If a large gradient flows through a ReLU neuron during training, it can output 0 for all subsequent inputs, effectively \"killing\" the neuron (it stops learning). This can sometimes be mitigated by using variants like Leaky ReLU or ELU.\n",
        "    *   **Not Zero-centered:** The output is not zero-centered, which can lead to similar issues as with Sigmoid, although its other advantages often outweigh this.\n",
        "\n",
        "**Summary Table:**\n",
        "\n",
        "| Feature           | Sigmoid                                | Tanh                                   | ReLU                                    |\n",
        "| :---------------- | :------------------------------------- | :------------------------------------- | :-------------------------------------- |\n",
        "| **Output Range**  | (0, 1)                                 | (-1, 1)                                | [0, infinity)                           |\n",
        "| **Zero-centered** | No                                     | Yes                                    | No                                      |\n",
        "| **Vanishing Grad.** | Yes, for large positive/negative inputs | Yes, for large positive/negative inputs | No, for positive inputs                 |\n",
        "| **Computational** | High                                   | High                                   | Low                                     |\n",
        "| **\"Dying\" Issue** | No                                     | No                                     | Yes (Dying ReLU)                        |\n",
        "\n",
        "In modern deep learning, ReLU and its variants (Leaky ReLU, ELU, PReLU, Swish, etc.) are generally the default choice for hidden layers due to their ability to combat vanishing gradients and their computational efficiency. Sigmoid and Tanh are still used, particularly in specific scenarios like output layers for binary classification (Sigmoid) or when a strong normalization around zero is desired."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: What is the difference between Loss function and Cost function in neural networks? Provide examples.**\n"
      ],
      "metadata": {
        "id": "OxRkYwfLaEi-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ee2e589"
      },
      "source": [
        "### **Difference between Loss Function and Cost Function in Neural Networks:**\n",
        "\n",
        "While often used interchangeably, \"loss function\" and \"cost function\" (and sometimes \"objective function\") refer to related but slightly different concepts in the context of neural networks and machine learning.\n",
        "\n",
        "*   **Loss Function (Error Function):**\n",
        "    *   **Definition:** A loss function quantifies the error or discrepancy between a *single training example's* predicted output and its actual target value.\n",
        "    *   **Purpose:** It measures how well the neural network performs on a single data point.\n",
        "    *   **Calculation:** Calculated for each individual training example.\n",
        "    *   **Usage:** Used to assess the model's performance on a micro-level.\n",
        "\n",
        "*   **Cost Function (Objective Function):**\n",
        "    *   **Definition:** A cost function is the average of the loss functions over the *entire training dataset* (or a batch of training data).\n",
        "    *   **Purpose:** It quantifies the overall error of the neural network across all (or a batch of) training examples.\n",
        "    *   **Calculation:** Calculated as an aggregate (e.g., sum or average) of the individual losses.\n",
        "    *   **Usage:** The primary function that the optimization algorithm (like gradient descent) aims to minimize during the training process to find the optimal set of weights and biases for the model.\n",
        "\n",
        "In simpler terms:\n",
        "*   **Loss Function:** \"How bad is our prediction for *one* data point?\"\n",
        "*   **Cost Function:** \"How bad is our prediction for *all* (or a batch of) data points, on average?\"\n",
        "\n",
        "An **objective function** is a more general term that encompasses both loss and cost functions. It's the function that an optimization algorithm seeks to minimize (or maximize) – in machine learning, this is typically minimization.\n",
        "\n",
        "### **Examples of Loss/Cost Functions:**\n",
        "\n",
        "The choice of loss/cost function depends heavily on the type of problem (e.g., regression, binary classification, multi-class classification).\n",
        "\n",
        "#### 1. Mean Squared Error (MSE) / L2 Loss (for Regression Problems)\n",
        "\n",
        "*   **Formula (Loss for a single example):** `L = (y_true - y_pred)^2`\n",
        "*   **Formula (Cost for 'm' examples):** `J = (1/m) * Σ (y_true_i - y_pred_i)^2`\n",
        "*   **Description:** MSE calculates the average of the squares of the differences between predicted and actual values. It penalizes larger errors more heavily. Commonly used in regression tasks where the output is a continuous value.\n",
        "\n",
        "#### 2. Mean Absolute Error (MAE) / L1 Loss (for Regression Problems)\n",
        "\n",
        "*   **Formula (Loss for a single example):** `L = |y_true - y_pred|`\n",
        "*   **Formula (Cost for 'm' examples):** `J = (1/m) * Σ |y_true_i - y_pred_i|`\n",
        "*   **Description:** MAE calculates the average of the absolute differences between predicted and actual values. It is less sensitive to outliers than MSE.\n",
        "\n",
        "#### 3. Binary Cross-Entropy (Log Loss) (for Binary Classification Problems)\n",
        "\n",
        "*   **Formula (Loss for a single example):**\n",
        "    `L = - [y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred)]`\n",
        "*   **Formula (Cost for 'm' examples):**\n",
        "    `J = -(1/m) * Σ [y_true_i * log(y_pred_i) + (1 - y_true_i) * log(1 - y_pred_i)]`\n",
        "*   **Description:** Used when predicting a binary outcome (0 or 1). It measures the performance of a classification model whose output is a probability value between 0 and 1. It heavily penalizes confident wrong predictions.\n",
        "\n",
        "#### 4. Categorical Cross-Entropy (for Multi-Class Classification Problems)\n",
        "\n",
        "*   **Formula (Loss for a single example):**\n",
        "    `L = - Σ y_true_j * log(y_pred_j)` (where `j` iterates over classes)\n",
        "*   **Formula (Cost for 'm' examples):**\n",
        "    `J = -(1/m) * Σ (Σ y_true_ij * log(y_pred_ij))`\n",
        "*   **Description:** Used when there are more than two classes, and the output is a probability distribution over those classes (usually via a softmax activation in the output layer). It compares the true one-hot encoded label with the predicted probability distribution.\n",
        "\n",
        "In summary, the loss function is for a single data point, while the cost function aggregates these losses over a dataset to provide an overall measure of the model's error that the optimizer then tries to minimize."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: What is the role of optimizers in neural networks? Compare Gradient Descent, Adam, and RMSprop.**"
      ],
      "metadata": {
        "id": "GPf00DyvaSlC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "977b5c1c"
      },
      "source": [
        "### **Role of Optimizers in Neural Networks:**\n",
        "\n",
        "Optimizers are algorithms or methods used to change the attributes of your neural network, such as weights and learning rate, in order to reduce the losses. In simpler terms, optimizers help a neural network learn from data by finding the best possible set of weights and biases that minimize the model's error (cost function).\n",
        "\n",
        "During the training process, the neural network makes predictions, and a loss function calculates how far off these predictions are from the actual values. The optimizer's job is to use this loss information to guide the adjustments of the network's parameters (weights and biases) in the right direction, effectively moving towards a state where the loss is minimal. This iterative process of adjusting parameters based on the loss is called **optimization**.\n",
        "\n",
        "Key aspects of an optimizer's role:\n",
        "\n",
        "1.  **Minimizing the Loss Function:** The primary goal is to find the global minimum (or at least a good local minimum) of the loss function. This means finding the parameter values where the model performs best.\n",
        "2.  **Guiding Parameter Updates:** Optimizers determine how the weights and biases are updated in response to the computed gradients (derivatives of the loss function with respect to the parameters).\n",
        "3.  **Controlling Learning Speed:** They often involve a `learning_rate` parameter, which dictates the size of the steps taken during each parameter update. A well-chosen learning rate is crucial for efficient and stable training.\n",
        "4.  **Improving Convergence:** Effective optimizers help the network converge faster and more reliably to a good solution, avoiding getting stuck in poor local minima or oscillating around the optimal solution.\n",
        "\n",
        "### **Comparison of Gradient Descent, Adam, and RMSprop:**\n",
        "\n",
        "#### 1. Gradient Descent (Batch Gradient Descent)\n",
        "\n",
        "*   **Concept:** This is the most basic optimization algorithm. It calculates the gradient of the loss function with respect to every parameter in the network for *all* training examples. It then updates the parameters by taking a step in the opposite direction of the gradient, scaled by the learning rate.\n",
        "*   **Update Rule:** `W = W - learning_rate * dW`\n",
        "*   **Pros:**\n",
        "    *   Conceptually simple and easy to understand.\n",
        "    *   Guaranteed to converge to a local minimum (for convex functions).\n",
        "*   **Cons:**\n",
        "    *   **Computationally Expensive:** Calculates gradients for the entire dataset in each epoch, which can be very slow for large datasets.\n",
        "    *   **Slow Convergence:** Can be very slow to converge, especially with large datasets.\n",
        "    *   **Requires Large Memory:** Needs to store the entire dataset for gradient calculation.\n",
        "    *   Can get stuck in poor local minima or saddle points in non-convex landscapes.\n",
        "\n",
        "#### 2. RMSprop (Root Mean Square Propagation)\n",
        "\n",
        "*   **Concept:** RMSprop is an adaptive learning rate optimization algorithm. It addresses the issue of vanishing/exploding gradients and tries to make learning faster in the vertical direction and slower in the horizontal direction. It does this by dividing the learning rate by an exponentially decaying average of squared gradients.\n",
        "*   **Update Rule (simplified):**\n",
        "    *   `squared_gradient_avg = decay_rate * squared_gradient_avg + (1 - decay_rate) * gradient^2`\n",
        "    *   `W = W - (learning_rate / sqrt(squared_gradient_avg + epsilon)) * dW`\n",
        "*   **Pros:**\n",
        "    *   Effectively handles non-stationary objectives (where gradients change direction frequently).\n",
        "    *   Addresses vanishing/exploding gradient problems.\n",
        "    *   Faster convergence than vanilla Gradient Descent.\n",
        "    *   Works well with recurrent neural networks.\n",
        "*   **Cons:**\n",
        "    *   Can still oscillate in the presence of strong variations in gradients.\n",
        "    *   Does not guarantee convergence to the optimal solution.\n",
        "\n",
        "#### 3. Adam (Adaptive Moment Estimation)\n",
        "\n",
        "*   **Concept:** Adam combines the advantages of two other extensions of stochastic gradient descent: Adaptive Gradient Algorithm (AdaGrad) and RMSprop. It computes adaptive learning rates for each parameter by storing an exponentially decaying average of past squared gradients (like RMSprop) and also an exponentially decaying average of past gradients (momentum).\n",
        "*   **Update Rule (simplified):**\n",
        "    *   `m = beta1 * m + (1 - beta1) * gradient` (first moment - like momentum)\n",
        "    *   `v = beta2 * v + (1 - beta2) * gradient^2` (second moment - like RMSprop)\n",
        "    *   Bias corrections are applied to `m` and `v`.\n",
        "    *   `W = W - (learning_rate / (sqrt(v_corrected) + epsilon)) * m_corrected`\n",
        "*   **Pros:**\n",
        "    *   **Generally performs very well:** Often considered the default choice for many deep learning tasks.\n",
        "    *   Combines the benefits of AdaGrad (handling sparse gradients) and RMSprop (handling non-stationary objectives).\n",
        "    *   Fast convergence and robust to hyperparameter choices.\n",
        "    *   Maintains a relatively constant learning rate for each parameter, adapting it based on the historical gradient information.\n",
        "*   **Cons:**\n",
        "    *   Can sometimes converge to a suboptimal solution compared to SGD with momentum in some specific tasks (though this is rare and often depends on hyperparameter tuning).\n",
        "    *   Can sometimes generalize worse than SGD in certain scenarios, especially towards the end of training.\n",
        "\n",
        "**Summary Table:**\n",
        "\n",
        "| Feature              | Gradient Descent (Batch)                               | RMSprop                                                | Adam                                                    |\n",
        "| :------------------- | :----------------------------------------------------- | :----------------------------------------------------- | :------------------------------------------------------ |\n",
        "| **Learning Rate**    | Fixed (or scheduled)                                   | Adaptive (per-parameter, based on squared gradients)   | Adaptive (per-parameter, based on first & second moments) |\n",
        "| **Memory Usage**     | High (for gradients of entire dataset)                 | Low (stores exponentially decaying averages)           | Low (stores exponentially decaying averages)            |\n",
        "| **Computational Cost** | High (for large datasets)                              | Moderate                                               | Moderate                                                |\n",
        "| **Convergence Speed**| Slow                                                   | Faster than GD, especially with non-stationary data    | Generally fastest                                       |\n",
        "| **Gradient Handling**| Can suffer from vanishing/exploding gradients          | Addresses vanishing/exploding gradients                | Addresses vanishing/exploding gradients, adds momentum  |\n",
        "| **Common Use**       | Theoretical understanding, small datasets              | Often used for RNNs                                    | General-purpose, widely used for deep learning          |\n",
        "\n",
        "In practice, Adam is often the go-to optimizer due to its efficiency and good performance across a wide range of tasks. However, understanding the strengths and weaknesses of each optimizer helps in making informed decisions for specific problems and architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: Write a Python program to implement a single-layer perceptron from scratch using NumPy to solve the logical AND gate.**\n"
      ],
      "metadata": {
        "id": "_i35FiucalrC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8cdf53",
        "outputId": "7f25f8fc-6622-4367-d7d2-9a11c1f79b94"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def _step_function(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize weights and bias to zeros\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                # Calculate weighted sum and apply activation function\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self._step_function(linear_output)\n",
        "\n",
        "                # Calculate error\n",
        "                error = y[idx] - y_predicted\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += self.learning_rate * error * x_i\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._step_function(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "# 1. Define the logical AND gate data\n",
        "# Input features (X): [[x1, x2]]\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "# Target outputs (y): [output]\n",
        "y = np.array([0, 0, 0, 1])\n",
        "\n",
        "print(\"Input (X):\\n\", X)\n",
        "print(\"Target Output (y):\\n\", y)\n",
        "\n",
        "# 2. Create and train the Perceptron model\n",
        "perceptron = Perceptron(learning_rate=0.1, n_iterations=10)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "print(\"\\nPerceptron trained.\")\n",
        "print(\"Learned Weights:\", perceptron.weights)\n",
        "print(\"Learned Bias:\", perceptron.bias)\n",
        "\n",
        "# 3. Test the trained Perceptron\n",
        "predictions = perceptron.predict(X)\n",
        "\n",
        "print(\"\\nPredictions for AND gate:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"Input: {X[i]}, Expected: {y[i]}, Predicted: {predictions[i]}\")\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.sum(predictions == y) / len(y)\n",
        "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (X):\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "Target Output (y):\n",
            " [0 0 0 1]\n",
            "\n",
            "Perceptron trained.\n",
            "Learned Weights: [0.2 0.1]\n",
            "Learned Bias: -0.20000000000000004\n",
            "\n",
            "Predictions for AND gate:\n",
            "Input: [0 0], Expected: 0, Predicted: 0\n",
            "Input: [0 1], Expected: 0, Predicted: 0\n",
            "Input: [1 0], Expected: 0, Predicted: 0\n",
            "Input: [1 1], Expected: 1, Predicted: 1\n",
            "\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 7: Implement and visualize Sigmoid, ReLU, and Tanh activation functions using Matplotlib.**"
      ],
      "metadata": {
        "id": "bucTMmmfcGcN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "68c383db",
        "outputId": "ffd11f9c-3789-4c91-8afb-a47978c15e69"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Generate a range of input values\n",
        "x = np.linspace(-5, 5, 100)\n",
        "\n",
        "# Calculate outputs for each activation function\n",
        "y_sigmoid = sigmoid(x)\n",
        "y_relu = relu(x)\n",
        "y_tanh = tanh(x)\n",
        "\n",
        "# Plot the activation functions\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.plot(x, y_sigmoid, label='Sigmoid', color='blue')\n",
        "plt.plot(x, y_relu, label='ReLU', color='red')\n",
        "plt.plot(x, y_tanh, label='Tanh', color='green')\n",
        "\n",
        "plt.title('Activation Functions: Sigmoid, ReLU, Tanh')\n",
        "plt.xlabel('Input (x)')\n",
        "plt.ylabel('Output')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8) # Add a vertical line at x=0\n",
        "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8) # Add a horizontal line at y=0\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAAK9CAYAAABGnB2ZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAyZ5JREFUeJzs3Xd8FHX+x/HXljRaQgk1tAQUEEEU5BQVxVOaBcSup9hFOSv2U8EG52EvYAUVPBUExFNAfyrYFQRBFFCq9J4EwiabnZnfH2OWhPSQMLO77+fdPjKZbZ8v8/G7+ezMfMZjWZaFiIiIiIiIiDjG63QAIiIiIiIiIrFOxbmIiIiIiIiIw1Sci4iIiIiIiDhMxbmIiIiIiIiIw1Sci4iIiIiIiDhMxbmIiIiIiIiIw1Sci4iIiIiIiDhMxbmIiIiIiIiIw1Sci4iIiIiIiDhMxbmISAwYOnQobdq0ceS9R44cicfjceS9I9HJJ5/MySef7HQYNWLu3Ll4PB7mzp3rdChlqug2iJTxRKuhQ4dSp04dp8MQEak2Ks5FRFzgxRdfxOPx0LNnzyq/xqZNmxg5ciQ///xz9QVWQfv27WPkyJGuK1I8Hk+Jt6ZNmzoa12+//cbIkSNZu3ato3FUF9M0efPNN+nZsycNGjSgbt26HHbYYVx22WV8//33TofnWgfmZb169ejduzcfffRRlV+zTZs2nHHGGaXeX15BW6dOHYYOHVqp9yz4kqIiNxERKZ3f6QBERAQmT55MmzZt+PHHH1m5ciXt2rWr9Gts2rSJUaNG0aZNG4466qgi973yyiuYpllN0Ra3b98+Ro0aBVBsj+O//vUv7r777hp77/KcdtppXHbZZUXWJSUlORSN7bfffmPUqFGcfPLJxY5o+OSTT5wJ6iDcdNNNvPDCC5x99tlccskl+P1+VqxYwaxZs0hPT+dvf/sbACeddBKBQID4+HiHIy7bodwGBflpWRbr1q1j3LhxnHnmmcyaNYu+ffsesjgORseOHXnrrbeKrLvnnnuoU6cO9913n0NRiYhEHhXnIiIOW7NmDd9++y3Tpk3juuuuY/LkyTz44IPV+h5xcXHV+nqV4ff78fud+7g57LDDuPTSSx17/8pye+F6oK1bt/Liiy9yzTXX8PLLLxe57+mnn2b79u3h371eL4mJiYc6xEo7lNvgwPwcMmQInTp14plnnomY4rxJkybF/hsbM2YMjRo1iqj/9kREnKbD2kVEHDZ58mTq16/PwIEDOffcc5k8eXKJj8vMzOTWW2+lTZs2JCQkkJaWxmWXXcaOHTuYO3cuPXr0AOCKK64IH0I6ceJEoOg55/n5+TRo0IArrrii2HtkZ2eTmJjIiBEjAAgGgzzwwAMcc8wxJCcnU7t2bU488US++OKL8HPWrl1LamoqAKNGjQq/98iRI4GSzzkPhUI8/PDDZGRkkJCQQJs2bbj33nvJy8sr8riCQ3S//vprjj32WBITE0lPT+fNN9+s3D9yKUo7F7+kmD0eD8OHD2fGjBl07tyZhIQEjjjiCGbPnl3s+Rs3buSqq66iefPmJCQk0LZtW4YNG0YwGGTixImcd955AJxyyinhf6+CUwJKOt9527ZtXHXVVTRp0oTExES6du3KG2+8UeQxa9euxePxMHbsWF5++eXwv22PHj2YP39+kcdu2bKFK664grS0NBISEmjWrBlnn312kcPss7KyWL58OVlZWWX+G65ZswbLsujVq1ex+zweD40bNw7/Xto52i+88ALp6ekkJSVx7LHH8tVXXxX7dyh47nvvvceoUaNo0aIFdevW5dxzzyUrK4u8vDxuueUWGjduTJ06dbjiiiuK5VNF866kbbBhwwYGDRpE7dq1ady4Mbfeemux51WHjh070qhRI1atWlVkfV5eHg8++CDt2rUjISGBli1bcuedd9ZIDDWhInMJVC6PC2zcuJFBgwZRp04dUlNTGTFiBIZhHIphiYhUK+05FxFx2OTJkznnnHOIj4/noosuYty4ccyfPz9cbAPs3buXE088kWXLlnHllVdy9NFHs2PHDmbOnMmGDRvo2LEjDz30EA888ADXXnstJ554IgDHH398sfeLi4tj8ODBTJs2jZdeeqnIXsIZM2aQl5fHhRdeCNjF+quvvspFF13ENddcw549e3jttdfo27cvP/74I0cddRSpqamMGzeOYcOGMXjwYM455xwAunTpUuqYr776at544w3OPfdcbr/9dn744QdGjx7NsmXLmD59epHHrly5knPPPZerrrqKyy+/nNdff52hQ4dyzDHHcMQRR5T775ubm8uOHTuKrKtbty4JCQnlPvdAX3/9NdOmTeOGG26gbt26PPvsswwZMoQ///yThg0bAvbpBcceeyyZmZlce+21dOjQgY0bNzJ16lT27dvHSSedxE033cSzzz7LvffeS8eOHQHCPw8UCAQ4+eSTWblyJcOHD6dt27ZMmTKFoUOHkpmZyc0331zk8W+//TZ79uzhuuuuw+Px8Pjjj3POOeewevXq8BEUQ4YM4ddff+Wf//wnbdq0Ydu2bXz66af8+eef4S8rpk+fzhVXXMGECRPKPAe5devWAEyZMoXzzjuPWrVqVerfdNy4cQwfPpwTTzyRW2+9lbVr1zJo0CDq169PWlpascePHj2apKQk7r77blauXMlzzz1HXFwcXq+X3bt3M3LkSL7//nsmTpxI27ZteeCBB8LPrUzeFRYIBDj11FP5888/uemmm2jevDlvvfUWn3/+eaXGWhFZWVns3r2bjIyM8DrTNDnrrLP4+uuvufbaa+nYsSO//PILTz31FL///jszZsyo9jiqW0XmksIqkscAhmHQt29fevbsydixY/m///s/nnjiCTIyMhg2bNghHqWIyEGyRETEMQsWLLAA69NPP7Usy7JM07TS0tKsm2++ucjjHnjgAQuwpk2bVuw1TNO0LMuy5s+fbwHWhAkTij3m8ssvt1q3bh3+fc6cORZgffjhh0UeN2DAACs9PT38eygUsvLy8oo8Zvfu3VaTJk2sK6+8Mrxu+/btFmA9+OCDxd77wQcftAp/3Pz8888WYF199dVFHjdixAgLsD7//PPwutatW1uA9eWXX4bXbdu2zUpISLBuv/32Yu91IKDEW8G/0YH/LqXFXPBa8fHx1sqVK8PrFi9ebAHWc889F1532WWXWV6v15o/f36x1y3YVlOmTLEA64svvij2mN69e1u9e/cO//70009bgDVp0qTwumAwaB133HFWnTp1rOzsbMuyLGvNmjUWYDVs2NDatWtX+LEffPBBkW29e/duC7D+85//lPKvZpswYUKp+XSgyy67zAKs+vXrW4MHD7bGjh1rLVu2rNjjvvjiiyLjzsvLsxo2bGj16NHDys/PDz9u4sSJFlDk36HguZ07d7aCwWB4/UUXXWR5PB6rf//+Rd7ruOOOK7JtK5N3pW2D9957L7wuJyfHateuXanbsSIA66qrrrK2b99ubdu2zVqwYIHVr1+/Ytvnrbfesrxer/XVV18Vef748eMtwPrmm2/C61q3bm0NHDiw1Pe8/PLLrdq1a5d6f+3ata3LL7+8SuMp7Igjjijyb1jRuaSieVwwFsB66KGHirxut27drGOOOeagxyAicqjpsHYREQdNnjyZJk2acMoppwD2YcAXXHAB77zzTpHDMt9//326du3K4MGDi71GVTog9+nTh0aNGvHuu++G1+3evZtPP/2UCy64ILzO5/OF96ybpsmuXbsIhUJ0796dhQsXVvp9AT7++GMAbrvttiLrb7/9doBinao7deoUPhIAIDU1lcMPP5zVq1dX6P3OPvtsPv300yK3qp7L+/e//73IHs0uXbpQr169cCymaTJjxgzOPPNMunfvXuz5VdlWH3/8MU2bNuWiiy4Kr4uLi+Omm25i7969zJs3r8jjL7jgAurXrx/+veDfriDGpKQk4uPjmTt3Lrt37y71fYcOHYplWRXq3D1hwgSef/552rZty/Tp0xkxYgQdO3bk1FNPZePGjaU+b8GCBezcuZNrrrmmSF+CSy65pMgYCrvsssuK7Dnt2bMnlmVx5ZVXFnlcz549Wb9+PaFQCKh83hX28ccf06xZM84999zwulq1anHttdeW+pyKeu2110hNTaVx48Z0796dzz77jDvvvLNInFOmTKFjx4506NCBHTt2hG99+vQBKHZouBtVdi4pL48Lu/7664v8fuKJJ1Z4fhARcRMV5yIiDjEMg3feeYdTTjmFNWvWsHLlSlauXEnPnj3ZunUrn332Wfixq1atonPnztX23n6/nyFDhvDBBx+Ez1mdNm0a+fn5RYpzgDfeeIMuXbqQmJhIw4YNSU1N5aOPPir3XOTSrFu3Dq/XW6wjfdOmTUlJSWHdunVF1rdq1arYa9SvX7/MwrKwtLQ0/v73vxe5NWvWrEqxlxfL9u3byc7OrtZttW7dOtq3b4/XW/Qju+Aw+PL+vQoKnIIYExIS+Pe//82sWbNo0qQJJ510Eo8//jhbtmypcoxer5cbb7yRn376iR07dvDBBx/Qv39/Pv/88/ApEqWNDSiWC36/v8ReAFB8fMnJyQC0bNmy2HrTNMN5Wtm8OzDOdu3aFfty5fDDDy/1ORVV8OXRRx99FO51sG/fviLb+48//uDXX38lNTW1yO2www4D7J4E1ammLnlWmbmkvDwukJiYGO55UfixFZ0fRETcROeci4g45PPPP2fz5s288847vPPOO8Xunzx5MqeffnqNvf+FF17ISy+9xKxZsxg0aBDvvfceHTp0oGvXruHHTJo0iaFDhzJo0CDuuOMOGjdujM/nY/To0cUaVlVWRQsAn89X4nrLsg7q/cuKobRmUjUZS3WpSIy33HILZ555JjNmzGDOnDncf//9jB49ms8//5xu3bod1Ps3bNiQs846i7POOouTTz6ZefPmsW7duvC56QertPFVdNu47VrbBV8eAQwYMIBGjRoxfPhwTjnllHD/BtM0OfLII3nyySdLfI0Dv5goS2JiInl5eViWVezfwrIscnNza6SjfmXnkopuz9IeJyISiVSci4g4ZPLkyTRu3JgXXnih2H3Tpk1j+vTpjB8/nqSkJDIyMli6dGmZr1fZouOkk06iWbNmvPvuu5xwwgl8/vnnxa5JPHXqVNLT05k2bVqR1z/wUm+Vee/WrVtjmiZ//PFHkSZoW7duJTMzs9qKuIqoX78+mZmZxdaXtRe1LKmpqdSrV69at1Xr1q1ZsmQJpmkW2Zu6fPny8P1VkZGRwe23387tt9/OH3/8wVFHHcUTTzzBpEmTqvR6JenevTvz5s1j8+bNJcZZsG7lypXhUzvA7qq+du3aMpsKVtbB5F3r1q1ZunRpsYJ2xYoV1RZfgeuuu46nnnqKf/3rXwwePBiPx0NGRgaLFy/m1FNPPegvF1q3bk0oFGLVqlXFjiJYuXIlhmHUyH+DFZ1LRERimQ5rFxFxQCAQYNq0aZxxxhmce+65xW7Dhw9nz549zJw5E7C7ay9evLjEjtIFe5Jq164NUGKxWRKv18u5557Lhx9+yFtvvUUoFCp2SHvBXqnCe6t++OEHvvvuuyKPK+jQXZH3HjBgAGBfA7uwgr2CAwcOrFD81SEjI4OsrCyWLFkSXrd58+YyO3eXxev1MmjQID788EMWLFhQ7P6qbKsBAwawZcuWIv0BQqEQzz33HHXq1KF3796VinHfvn3k5uYWWZeRkUHdunWLXJaropdS27JlC7/99lux9cFgkM8++6zEQ8kLdO/enYYNG/LKK6+Ezw0H+4ur6j4s+WDybsCAAWzatImpU6eG1+3bt6/Ydd2rg9/v5/bbb2fZsmV88MEHAJx//vls3LiRV155pdjjA4EAOTk5FX79/v37A/D8888Xu6/gi8KCx1Snis4lIiKxTHvORUQcMHPmTPbs2cNZZ51V4v1/+9vfSE1NZfLkyVxwwQXccccdTJ06lfPOO48rr7ySY445hl27djFz5kzGjx9P165dycjIICUlhfHjx1O3bl1q165Nz549adu2balxXHDBBTz33HM8+OCDHHnkkcUu53XGGWcwbdo0Bg8ezMCBA1mzZg3jx4+nU6dO7N27N/y4pKQkOnXqxLvvvsthhx1GgwYN6Ny5c4nnXnft2pXLL7+cl19+mczMTHr37s2PP/7IG2+8waBBg4rsQa1pF154IXfddReDBw/mpptuYt++fYwbN47DDjusyg3vHnvsMT755BN69+4dvuzV5s2bmTJlCl9//TUpKSkcddRR+Hw+/v3vf5OVlUVCQgJ9+vQpck3wAtdeey0vvfQSQ4cO5aeffqJNmzZMnTqVb775hqeffpq6detWKr7ff/+dU089lfPPP59OnTrh9/uZPn06W7duLXJ+eEUvpbZhwwaOPfZY+vTpw6mnnkrTpk3Ztm0b//3vf1m8eDG33HILjRo1KvG58fHxjBw5kn/+85/06dOH888/n7Vr1zJx4kQyMjKq9RD0g8m7a665hueff57LLruMn376iWbNmvHWW2+VeNm4uXPncsopp/Dggw8ycuTIKsU6dOhQHnjgAf79738zaNAg/vGPf/Dee+9x/fXX88UXX9CrVy8Mw2D58uW89957zJkzp0gDwpUrV/LII48Ue91u3boxcOBArr76ap555hn++OMPTjvtNAA+/fRTPv74Y66++uoip7YA4fP/165dW6XxQMXnEhGRWKbiXETEAZMnTyYxMTH8h/GBvF4vAwcOZPLkyezcuZOGDRvy1Vdf8eCDDzJ9+nTeeOMNGjduzKmnnhq+FnRcXBxvvPEG99xzD9dffz2hUIgJEyaUWZwff/zxtGzZkvXr1xfbaw52kbBlyxZeeukl5syZQ6dOnZg0aRJTpkxh7ty5RR776quv8s9//pNbb72VYDDIgw8+WGpjtFdffZX09HQmTpzI9OnTadq0Kffcc88hP8S1YcOGTJ8+ndtuu40777yTtm3bMnr0aP74448qF+ctWrTghx9+4P7772fy5MlkZ2fTokUL+vfvHy7mmjZtyvjx4xk9ejRXXXUVhmHwxRdflFicJyUlMXfuXO6++27eeOMNsrOzOfzww8stmkvTsmVLLrroIj777DPeeust/H4/HTp04L333mPIkCGVfr3DDz+cp59+mo8//pgXX3yRrVu3kpiYSOfOnXnllVe46qqrynz+8OHDsSyLJ554ghEjRtC1a1dmzpzJTTfdVO3nPlc172rVqsVnn33GP//5T5577jlq1arFJZdcQv/+/enXr1+RxxYUmlVtOgj2Nh8+fDgjR45k7ty5nHzyycyYMYOnnnqKN998k+nTp1OrVi3S09O5+eabw43hCqxYsYL777+/2OteddVVDBw4kJdeeokjjzyS119/nXvuuQewt+Ozzz7LjTfeWOx5OTk5pR79UFGVmUtERGKVx3JTFxsRERGJeaZpkpqayjnnnFPiodxuduedd/Lf//6XlStXkpCQ4HQ4B+23337jiCOO4H//+98hPeVERCQW6ZxzERERcUxubm6xDtxvvvkmu3bt4uSTT3YmqIPwxRdfcP/990dFYQ72eI477jgV5iIih4D2nIuIiIhj5s6dy6233sp5551Hw4YNWbhwIa+99hodO3bkp59+Ij4+3ukQRUREDgmdcy4iIiKOadOmDS1btuTZZ59l165dNGjQgMsuu4wxY8aoMBcRkZiiPeciIiIiIiIiDtM55yIiIiIiIiIOU3EuIiIiIiIi4rCYOufcNE02bdpE3bp18Xg8TocjIiIiIiIiUc6yLPbs2UPz5s3xekvfPx5TxfmmTZto2bKl02GIiIiIiIhIjFm/fj1paWml3h9TxXndunUB+x+lXr16Dkcjh1IoFGLRokV069YNvz+m0l4ihHJU3C4nJ4dnn32Wm266idq1azsdjkgxmkfF7ZSjsSs7O5uWLVuG69HSxFRWFBzKXq9ePRXnMSYUClG7dm3q1aunyVBcSTkqbufz+UhMTKRevXoqzsWVNI+K2ylHpbxTq9UQTkRERERERMRhMXWd8+zsbJKTk8nKytKe8xhjWRaGYeDz+dQMUFxJOSpuZ5omgUCApKSkMpvZiDhF86i4nXI0dlW0DtWnq8SMYDDodAgiZVKOiptZlsXOnTuJoe/0JQJpHhW3U45KWXSywwEsyyIUCmEYhtOhyAF8Ph9+v79K3zQahsGSJUvo3r27zvERV1KOitvl5uYyYcIERowYoXPOxZU0j4rbKUelPMqKQoLBIJs3b2bfvn1OhyKlqFWrFs2aNSM+Pt7pUERERERERKqNivO/mKbJmjVr8Pl8NG/enPj4eJ0L4iKWZREMBtm+fTtr1qyhffv2OudRRERERESihorzvwSDQUzTpGXLltSqVcvpcKQESUlJxMXFsW7dOoLBIImJiZV6vs/nq6HIRKqHclTcTodhittpHhW3U45KWdSt/S+5ubmsWbOGtm3bVrrok0NH20lERERERCKJurWLFGJZFpmZmeoyLK6lHBW3MwyDxYsXq2GquJbmUXE75aiUR8W5xATDMFi+fLn+qBTXUo6K2+Xm5jJjxgxyc3OdDkWkRJpHxe2Uo1IeFecxwOPxMGPGDKfDYO7cuXg8HjIzM0t9zMSJE0lJSTlkMYmIiIiIiLiBivMosH37doYNG0arVq1ISEigadOm9O3bl2+++QaAzZs3079/f4ejhOOPP57NmzeTnJzsdCgiIiIiIiKuorarUWDIkCEEg0HeeOMN0tPT2bp1K5999hk7d+4EoGnTpg5HaIuPj3csFo/HQ1JSki6PJ66lHBW383q91K1bV5exFNfSPCpupxyV8ugTthSWBTk5ztwq0yMiMzOTr776in//+9+ccsoptG7dmmOPPZZ77rmHs846Cyh+WPu3337LUUcdRWJiIt27d2fGjBl4PB5+/vlnYP/h53PmzKFbt24kJSXRp08ftm3bxqxZs+jYsSP16tXj4osvZt++feHXzcvL46abbqJx48YkJiZywgknMH/+/PD9JR3WPnHiRFq1akWtWrUYPHhw+AuF6ubz+ejatasuXyGupRwVt0tKSuK2224jKSnJ6VBESqR5VNxOOSrlUXFein37oE4dZ26F6t1y1alThzp16jBjxgzy8vLKfXx2djZnnnkmRx55JAsXLuThhx/mrrvuKvGxI0eO5Pnnn+fbb79l/fr1nH/++Tz99NO8/fbbfPTRR3zyySc899xz4cffeeedvP/++7zxxhssXLiQdu3a0bdvX3bt2lXi6//www9cddVVDB8+nJ9//plTTjmFRx55pOKDrwTTNNm2bRumadbI64scLOWouF1+fj5z584lPz/f6VBESqR5VNxOOSrlUXEe4fx+PxMnTuSNN94gJSWFXr16ce+997JkyZISH//222/j8Xh45ZVX6NSpE/379+eOO+4o8bGPPPIIvXr1olu3blx11VXMmzePcePG0a1bN0488UTOPfdcvvjiCwBycnIYN24c//nPf+jfvz+dOnXilVdeISkpiddee63E13/mmWfo168fd955J4cddhg33XQTffv2rZ5/mAOYpsnq1as1GYprKUfF7YLBIPPmzSMYDDodikiJNI+K2ylHpTwqzktRqxbs3evMrVatysU6ZMgQNm3axMyZM+nXrx9z587l6KOPZuLEicUeu2LFCrp06UJiYmJ43bHHHlvi63bp0iW83KRJE2rVqkV6enqRddu2bQNg1apV5Ofn06tXr/D9cXFxHHvssSxbtqzE11+2bBk9e/Yssu64444rf8AiIiIiIiJRRg3hSuHxQO3aTkdRcYmJiZx22mmcdtpp3H///Vx99dU8+OCDDB06tMqvGRcXF172eDxFfi9Yp2/+REREREREDp72nEepTp06kZOTU2z94Ycfzi+//FLk/PTCTduqKiMjg/j4+PDl28A+P3H+/Pl06tSpxOd07NiRH374oci677///qBjKYnH4yE5OVndMcW1lKPidl6vlyZNmqhbu7iW5lFxO+WolEefsBFu586d9OnTh0mTJrFkyRLWrFnDlClTePzxxzn77LOLPf7iiy/GNE2uvfZali1bxpw5cxg7dizAQU0UtWvXZtiwYdxxxx3Mnj2b3377jWuuuYZ9+/Zx1VVXlficm266idmzZzN27Fj++OMPnn/+eWbPnl3lGMri8/no2LGjumOKaylHxe2SkpK4/vrr1a1dXEvzqLidclTKo+I8wtWpU4eePXvy1FNPcdJJJ9G5c2fuv/9+rrnmGp5//vlij69Xrx4ffvghP//8M0cddRT33XcfDzzwAECR89CrYsyYMQwZMoR//OMfHH300axcuZI5c+ZQv379Eh//t7/9jVdeeYVnnnmGrl278sknn/Cvf/3roGIojWmabNiwQYfhi2spR8XtgsEgM2fOVEM4cS3No+J2ylEpj8eyKnNVbeeMHDmSUaNGFVl3+OGHs3z58gq/RnZ2NsnJyWRlZVGvXr0i9+Xm5rJmzRratm170EVqpJk8eTJXXHEFWVlZrt8jUtXtFAqFWLBgAd27d8fvV6sFcR/lqLhdTk4OY8eOZcSIEdSOpKYsEjM0j4rbKUdjV1l1aGERlRVHHHEE//d//xf+XUldNW+++Sbp6em0aNGCxYsXc9ddd3H++ee7vjAXERERERGJVhFV3fr9fpo2bep0GBFvy5YtPPDAA2zZsoVmzZpx3nnn8eijjzodloiIiIiISMUEAjBmDNxzD0TJkc8RVZz/8ccfNG/enMTERI477jhGjx5Nq1atSn18Xl5eka7k2dnZgH1ISSgUAuzus16vF9M0sSwrfAO7QVpJR/1Xdn1lVNd7lrX+jjvu4I477jio16mM6h6TZVnhbViw/QzDKPKcA9ebpknDhg3DTe8Ktn+BgsYchmFUaL3f78eyrCLrPR4PPp8P0zSLnEtU2vrCuVfS+vLGVDhGj8ejMUX4mApy1DRNQqFQVIwpGrdTrI8pIyMD2D+HRsOYonE7xeqYCubRsmKPtDGVtV5jiswxFXzWm6YZNWMqL/YaGVMohPeCC/B++CEsXow1fbqrx1TReipiivOePXsyceJEDj/8cDZv3syoUaM48cQTWbp0KXXr1i3xOaNHjy52njrAokWLwufLpaamkpGRwYYNGwgGg+zbtw/DMIiPjyc+Pp7c3NwiGzohIYG4uDgCgUCRDZeYmIjf72ffvn1F/vGTkpLwer3FLmtWu3ZtTNMkEAiE13k8HmrXro1hGOTm5obXe71eatWqRSgUKvJlg8/nIykpifz8/CINevx+P4mJieTl5RVJjGgYUzAYJBgMsnTpUgDS0tJIS0vj999/JysrK/z49PR0GjduzNKlS4vEk5qaSkpKCosWLSryb9ClSxfi4+NZsGBBkTF1796dYDDIkiVLisTYo0cPsrKyivQ8SEpKomvXruzYsYPVq1eH1ycnJ9OxY0c2bdrEhg0bisSSkZHBmjVr2L59e3h9ZcfUoUMHjSkKxrRw4ULAvgJDtIwpGrdTrI/pjDPO4JdffomqMUXjdor1MXm9XjZs2BBVY4rG7RTLY9q5c2fUjQkO4XZavJi2Y8bQ5MMPMePj8d5+u+vH1KZNGyoiYhrCHSgzM5PWrVvz5JNPlnqprpL2nLds2ZKdO3eGT8Qv+NZj3759rF27tkijsWjdcx7JYwoEAqxZs4ZWrVqRmJhYqT3n69atIz09HZ/Pp28dNSbXjSk/P59169bRunVrvF5vVIwpGrdTLI/JMAymTJnC4MGDSUhIiIoxReN2iuUxFXzWFxzhEQ1jKmu9xhR5YwqFQuHPer/fHxVjcmI7Wf/6F97HHsPyejHfew/fkCGuH1NOTg4pKSnR1RCusJSUFA477DBWrlxZ6mMSEhLCf0AU5vf7izWT83q9eDye8K1Aadf+ruz6yqiu96zp9ZVRnbF4PJ5i27DgP9YDFawPhULs3LmTtm3bAqU3E6zM+oI4DlTwH+vBri9vTBWJsbLrNSbnxuT1esM5WvgxkTymaNxOsTymvLw8Vq1aVeJ9kTomiL7tBLE7psKf9QWFT1mPr0jsTo/pYNZrTO4cU0GOFjwmGsZ0oBod0/PP43nsMQA848fjGzLEXnb5mCpaT0Xsdc737t3LqlWraNasmdOhiIiIiIiISE167z246SZ7+eGH4ZprnI2nBkRMcT5ixAjmzZvH2rVr+fbbbxk8eDA+n4+LLrrI6dBERERERESkpnz2GVx6KVgW3Hgj3Hef0xHViIg5rH3Dhg1cdNFF7Ny5k9TUVE444QS+//57UlNTnQ5NIoDX6yUtLa3Ew1RE3EA5Km4XFxdHt27diIuLczoUkRJpHhW3U45W0cKFMHgw5OfDuefCM89ANZx260YR2xCuKrKzs0lOTi7xRPzc3FzWrFlTpCGcuI+2k4iIiIhIjFi1Co4/HrZtg1NOgVmzoISeYm5XVh1amL62iQJDhw4NN0qLi4ujbdu23HnnnUUuXVaWtWvX4vF4+Pnnn4vdN3fuXDweD5mZmcXua9OmDU8//fTBBX+IGIbBsmXLinV9FHEL5ai4XSAQYPz48UUuGSPiJppHxe2Uo5W0dSucfrpdmB91FEyfHpGFeWVEzGHtUrZ+/foxYcIE8vPz+emnn7j88svxeDz8+9//djo0V7Asi6ysrIO+LJxITVGOituZpsnWrVuLXGJGxE00j4rbKUcrITsb+veH1auhbVt7j3lystNR1TjtOS+NZUFOjjO3KvwHm5CQQNOmTWnZsiWDBg3i73//O59++ilg/0E1evRo2rZtS1JSEl27dmXq1KnV/S8mIiIiIiJycPLy7HPMFy2C1FT45BNo2tTpqA4J7Tkvzb59UKeOM++9dy/Url3lpy9dupRvv/2W1q1bAzB69GgmTZrE+PHjad++PV9++SWXXnopqamp9O7du7qiFhERERERqTrDgH/8Az7/3K7FZs2Cdu2cjuqQUXEeJf73v/9Rp04dQqEQeXl5eL1enn/+efLy8njsscf4v//7P4477jgA0tPT+frrr3nppZdipjj3er2kp6erO6a4lnJU3C4+Pp7evXsTHx/vdCgiJdI8Km6nHC2HZcHNN8OUKRAXZ59jfswxTkd1SKk4L02tWvYebKfeu5JOOeUUxo0bR05ODk899RR+v58hQ4bw66+/sm/fPk477bQijw8Gg3Tr1q26InY9r9dL48aNnQ5DpFTKUXG7uLg4Tj75ZKfDECmV5lFxO+VoOR57DF54wV5+8034+9+djccBKs5L4/Ec1KHlh1rt2rVp99chH6+//jpdu3bltddeo3PnzgB89NFHtGjRoshzEirQ7bCg1X9WVhYpKSlF7svMzCQ5QhozGIbB0qVL6dy5Mz6fz+lwRIpRjorbBQIBxo0bx7Bhw0hKSnI6HJFiNI+K2ylHy/Dqq/Cvf9nLzzwDF17obDwOUXEehbxeL/feey+33XYbv//+OwkJCfz5559VOoS9ffv2eL1efvrpp/A57ACrV68mKyuLww47rDpDrzGWZREIBNQdU1xLOSpuZ5ome/bsUbd2cS3No+J2ytFSzJwJ111nL99zD9x0k7PxOEjFeZQ677zzuOOOO3jppZcYMWIEt956K6ZpcsIJJ5CVlcU333xDvXr1uPzyy8PPWbFiRbHXOeKII7j66qu5/fbb8fv9HHnkkaxfv5677rqLv/3tbxx//PGHclgiIiIiIhItvv4aLrgATBOuvBIefdTpiByl4jxK+f1+hg8fzuOPP86aNWtITU1l9OjRrF69mpSUFI4++mjuvffeIs+5sITDR9avX88zzzzDmDFjuOuuu1i3bh1NmzbltNNO49FHH8Xj8RyqIYmIiIiISLRYuhTOPBNyc+GMM+Cll+xTi2OYx4qh4yqys7NJTk4mKysrfC51gdzcXNasWUPbtm1JTEx0KEIpT1W3k2VZZGVlkZycrC8UxJWUo+J2OldS3E7zqLidcrSQP/+E44+HjRvtn59+WqWm2JGirDq0MO05l5jg8XiKNbQTcRPlqLidz+eja9euTochUirNo+J2ytG/7NwJp59uF+adOsGHH0Z1YV4ZusiexIRQKMT8+fMJhUJOhyJSIuWouF1OTg6PPvooOTk5TociUiLNo+J2ylEgJwcGDoQVKyAtDWbPhgYNnI7KNVScS8wwDMPpEETKpBwVt4vpPyglImgeFbeL6RzNz4fzz4cffoD69WHOHGjZ0umoXEXFuYiIiIiIiNQcy4Krr4aPP4akJPjoI/uQdilCxbmIiIiIiIjUnLvvhjffBJ8P3nsPjjvO6YhcScW5xASfz0eXLl3UYVhcSzkqbpeYmMgVV1yhK5qIa2keFbeL2Rx98kl4/HF7+dVX7cumSYlUnEvMiI+PdzoEkTIpR8XNPB4PDRs21OV/xNU0j4rbxVyOTp4Mt99uL48ZA0OHOhqO26k4l5hgGAYLFiyI7SYc4mrKUXG7QCDA2LFjCQQCTociUiLNo+J2MZejc+bsL8ZvuQXuvNPJaCKCinMRERERERGpPvPnw5AhEArBRRfBE0+Ajrwql4pzKdXatWvxeDz8/PPPTociIiIiIiKRYMUKGDDAvqb5aafBxIngVdlZEfpXimAej6fM28iRI50OUUREREREYsWmTdC3L+zYAd27w/vvQ6ydZ38Q/E4HIFW3efPm8PK7777LAw88wIoVK8Lr6tSp40RYruTz+ejevXvsdceUiKEcFbdLSkpixIgRJCUlOR2KSIk0j4rbRX2OZmZC//6wbh20b29fy7xuXaejiijac14Ky7LICeY4crMsq0IxNm3aNHxLTk7G4/GEf8/JyeGSSy6hSZMm1KlThx49evB///d/RZ7fpk0bHnvsMa688krq1q1Lq1atePnll4u9z+rVqznllFOoVasWXbt25bvvvquWf+NDLRgMOh2CSJmUo+JmlmWxc+fOCn9GiThB86i4XdTmaG4unH02LFkCTZvazeAaN3Y6qoijPeel2Je/jzqjndnzvPeevdSOr31wr7F3LwMGDODRRx8lISGBN998kzPPPJMVK1bQqlWr8OOeeOIJHn74Ye69916mTp3KsGHD6N27N4cffnj4Mffddx9jx46lffv23HfffVx00UWsXLkSvz9y0scwDJYsWUL37t0jKm6JHcpRcbvc3FwmTJjAiBEjqF374D6jRGqC5lFxu6jNUcOAiy+GL7+EevVg9mxo29bpqCKS9pxHqa5du3LdddfRuXNn2rdvz8MPP0xGRgYzZ84s8rgBAwZwww030K5dO+666y4aNWrEF198UeQxI0aMYODAgRx22GGMGjWKdevWsXLlykM5HBERERERcRvLghtugOnTISEBZs6Erl2djipiRdFXNtWrVlwt9t6z17H3Plh79+5l5MiRfPTRR2zevJlQKEQgEODPP/8s8rguXbqElwsOi9+2bVupj2nWrBkA27Zto0OHDgcdp4iIiIiIRKhRo+Dll+3LpL39NvTu7XREEU3FeSk8Hs9BH1rupBEjRvDpp58yduxY2rVrR1JSEueee26x81zi4uKK/O7xeDBNs9THeP66PuGBj4kEUdt8Q6KGclTcLqoOw5SopHlU3C6qcnT8eLs4B3jxRTjnHGfjiQL6lI1S33zzDUOHDmXw4MGAvSd97dq1zgblIL/fT48ePZwOQ6RUylFxu9q1a3Pfffc5HYZIqTSPittFVY6+/759ODvAgw/C9dc7G0+U0DnnUap9+/ZMmzaNn3/+mcWLF3PxxRdH5N7u6mJZFpmZmeoyLK6lHBW3MwyDxYsXYxiG06GIlEjzqLhd1OTo3Ll2AzjLguuus4tzqRYqzqPUk08+Sf369Tn++OM588wz6du3L0cffbTTYTnGMAyWL1+uPyrFtZSj4na5ubnMmDGD3Nxcp0MRKZHmUXG7qMjRxYvtS6YFg/Zh7C+8YJ9vLtVCh7VHiaFDhzJ06NDw723atOHzzz8v8pgbb7yxyO8lHeb+888/F3mNA7/ZS0lJifxv+0REREREpHLWrIF+/SA7G046CSZPhmg6h94FtOdcRERERERESrdtG5x+OmzZAl26wAcfQGKi01FFHRXnEhM8Hg9JSUnhbvMibqMcFbfzer3UrVsXr1d/Oog7aR4Vt4vYHN2zBwYOhJUroXVrmDULUlKcjioqeawYOkY5Ozub5ORksrKyqFevXpH7cnNzWbNmDW3btiVR3wK5lraTiIiIiMghEgzCGWfAp59Co0bwzTdw2GFORxVxyqpDC9PX3xITTNNk27ZtMd2xXtxNOSpul5+fz9y5c8nPz3c6FJESaR4Vt4u4HDVNGDrULsxr14aPPlJhXsNUnB8ghg4kiEhV3T6mabJ69erImQwl5ihHxe2CwSDz5s0jGAw6HYpIiTSPittFVI5aFtx2G/z3v+D329c1P/ZYp6OKeirO/xIXFwfAvn37HI5EylKwfQq2l4iIiIiIVLPHH4dnnrGXJ06Evn0dDSdW6FJqf/H5fKSkpLBt2zYAatWqFXnNGqKYZVns27ePbdu2kZKSgk+XbRARERERqX4TJ8Ldd9vLTz4Jl1ziaDixRMV5IU2bNgUIF+jiPikpKeHtVBkej4fk5GR94SKupRwVt/N6vTRp0kTd2sW1NI+K20VEjn70EVx9tb18551w663OxhNj1K29BIZhqOGNC8XFxWmPuYiIiIhITfjuOzj1VAgE4LLL7D3obv4iIYJUtA7VnvMS+Hw+FYFRxjRNNm3aRPPmzbXXR1xJOSpuFwwGmT17Nv369SM+Pt7pcESK0TwqbufqHP3tN/ta5oEADBgAr76qwtwBLssKkZphmiYbNmyIjO6YEpOUo+J2+fn5LFq0SEeWiWtpHhW3c22Orl9vN3zbvRt69oT33gM1X3aEinMREREREZFYtGsX9OsHGzZAhw72Oee1azsdVcxScS4iIiIiIhJr9u2DM8+0D2lv0QLmzIGGDZ2OKqapOJeY4PV6SU1Ndd/5PSJ/UY6K2/n9fjIyMvD71a5G3EnzqLidq3I0FIILLoBvv4WUFJg9G1q1cjqqmKdu7SIiIiIiIrHCsuCqq2DCBEhMhE8/hRNOcDqqqFbROtQFX9uI1DzTNFm1apX7GnCI/EU5Km6Xl5fHpEmTyMvLczoUkRJpHhW3c02O3nefXZh7vfDuuyrMXUTFucQE0zTZvn2785OhSCmUo+J2oVCIVatWEQqFnA5FpESaR8XtXJGjzzwDo0fbyy+9BGed5VwsUoyKcxERERERkWj3zjtwyy328iOPwNVXOxqOFKfiXEREREREJJp9+ilcdpm9PHw43Huvs/FIiVScS0zwer2kpaW5ozumSAmUo+J2cXFxdOvWjbi4OKdDESmR5lFxO8dy9Kef4JxzID8fzj8fnn4aPJ5DG4NUiLq1i4iIiIiIRKM//oBevWD7dujTBz7+GBISnI4q5qhbu0ghhmGwbNkyDMNwOhSREilHxe0CgQDjx48nEAg4HYpIiTSPitsd8hzdsgX69rUL827dYPp0FeYup+JcYoJlWWRlZRFDB4pIhFGOituZpsnWrVvVCVtcS/OouN0hzdGsLOjXD9asgYwMmDULdOSw66k4FxERERERiRa5uTBoECxeDI0bw5w50KSJ01FJBag4FxERERERiQaGAf/4B8ydC3XrwuzZ9p5ziQgqziUmeL1e0tPT1cFVXEs5Km4XHx9P7969iY+PdzoUkRJpHhW3q/EctSy46SaYOhXi42HGDPtcc4kY6tYuIiIiIiIS6R5+GB54wL5M2jvv2JdNE1dQt3aRQgzDYPHixergKq6lHBW3CwQCPPnkk+rWLq6leVTcrkZz9OWX7cIc4NlnVZhHKBXnEhMsyyIQCKiDq7iWclTczjRN9uzZo27t4lqaR8XtaixHZ8yAYcPs5fvug+HDq/f15ZBRcS4iIiIiIhKJvvwSLrwQTBOuvto+tF0ilopzERERERGRSPPLL3DWWZCXB2efDePG2eebS8RScS4xwefz0aFDB3w+n9OhiJRIOSpul5iYyKBBg0hMTHQ6FJESaR4Vt6vWHF27Fvr2hawsOOEE+O9/we8/+NcVR6lbu4iIiIiISKTYsQN69YLff4fOne1D2+vXdzoqKYO6tYsUEgqFmD9/PqFQyOlQREqkHBW3y8nJ4dFHHyUnJ8fpUERKpHlU3K5acjQnBwYOtAvzVq1g9mwV5lFExbnEDF1aRdxOOSpup6JH3E7zqLjdQeVofj6cey78+CM0aABz5kCLFtUXnDhOxbmIiIiIiIibmSZcdZW9p7xWLfj4Y+jQwemopJqpOBcREREREXGzu+6Ct94Cnw+mToWePZ2OSGqAGsJJTLAsi0AgQFJSEh5dYkJcSDkqbmcYBhs3bqRFixbqhi2upHlU3K7KOTp2LNxxh738xhtw2WU1E6DUGDWEEzlAfHy80yGIlEk5Km7m8Xho2LChih5xNc2j4naVztG33tpfmP/nPyrMo5yKc4kJhmGwYMECNYoR11KOitsFAgHGjh1LIBBwOhSREmkeFberdI7OmgVXXmkv33YbjBhRc8GJK6g4FxERERERcZMffrA7s4dCcMkl9l5ziXoqzkVERERERNxi+XL7Wub79kHfvvD66+BV2RYLtJVFRERERETcYONGuyDfuRN69LA7s6uXQsxQt3aJCZZlYRgGPp9PzYzElZSj4namaYa7DHu1B0dcSPOouF25Obp7N5x0EixdCocdBl9/Damphz5QqXbq1i5ygGAw6HQIImVSjoqbWZbFzp07iaHv9CUCaR4Vtys1RwMBOPtsuzBv1gzmzFFhHoNUnEtMMAyDJUuWqIOruJZyVNwuNzeXCRMmkJub63QoIiXSPCpuV2qOhkJw8cXw1VeQnAyzZ0ObNo7EKM5ScS4iIiIiIuIEy4IbboAZMyAhAWbOhC5dnI5KHKLiXERERERExAkPPgivvGJ3Y3/nHfucc4lZKs4lZvh8PqdDECmTclTczu/3Ox2CSJk0j4rbFcnRF16Ahx+2l8eNg0GDHIlJ3EPd2kVERERERA6lKVPgggvsw9pHjYIHHnA6IqlBUd+tfcyYMXg8Hm655RanQ5EIYFkWmZmZ6jIsrqUcFbczDIPFixer2Za4luZRcbtwjn72GVx6qV2YDxsG99/vdGjiEhFZnM+fP5+XXnqJLmqWIBVkGAbLly/XH5XiWspRcbvc3FxmzJihbu3iWppHxe0Mw+DPDz6AwYMhGIQhQ+C556Cka55LTIq44nzv3r1ccsklvPLKK9SvX9/pcERERERERMq3ahUdbrsNz549cPLJMGkSqE+CFBJxnV1uvPFGBg4cyN///nceeeSRMh+bl5dHXl5e+Pfs7GwAQqEQoVAIAK/Xi9frxTRNTNMMP7ZgvWEYRQ6PKm29z+fD4/GEX7fweqDYt7ilrff7/ViWVWS9x+PB5/MVi7G09RpT8fUFPwseEw1jKhxjtGynWB9T4VijZUwVWa8xRcaYChiGEX6tSB9TNG6nWB5T4fePljGVtV5jirAxbd6Mb8AA/Lt2YXbpAtOm4U1MjOwxReN2qqExVfR0m4gqzt955x0WLlzI/PnzK/T40aNHM2rUqGLrFy1aRO3atQFITU0lIyODNWvWsH379vBj0tLSSEtL4/fffycrKyu8Pj09ncaNG7N06VICgUB4fYcOHUhJSWHRokVFEqNLly7Ex8ezYMGCIjF0796dYDDIkiVLwut8Ph89evQgKyuL5cuXh9cnJSXRtWtXduzYwerVq8Prk5OT6dixI5s2bWLDhg3h9RpT8TFZlsWePXvYs2cPDRo0iIoxReN2iuUxLVy4kD179rBw4UI8Hk9UjCkat1Msj6lz587UqVOHxYsXExcXFxVjisbtFMtjsiyLvLw8PB5P1IwJom87xeSYUlPJP+00ElavJtCkCb8+8ghNc3JIq18/cscUjdupBsfUpk0bKiJiurWvX7+e7t278+mnn4bPNT/55JM56qijePrpp0t8Tkl7zlu2bMnOnTvDXfL0zY/GpDFpTBqTxqQxaUwak8akMWlMNTKm/Hy8Z54Jn32G1agRxpdfQvv2kT2maNxONTymnJwcUlJSyu3WHjHF+YwZMxg8eHB4o4C9YTweD16vl7y8vCL3lUSXUotdpmmyY8cOGjVqhNcbca0WJAYoR8Xt8vPz+eabb+jVq1d4z7mIm2geFdcxTbjoInjvPahdG/Pzz9nRpo1yNAZF3aXUTj31VH755Rd+/vnn8K179+5ccskl/Pzzz+UW5hLbTNNk9erVRb4JE3ET5ai4XTAYZN68eQSDQadDESmR5lFxFcuCW26xC/O4OJg+HfPoo5WjUqaIOee8bt26dO7cuci62rVr07Bhw2LrRUREREREHDNmjH2ZNIA33oDTToMDDnUWOVDE7DkXERERERFxvddeg3vvtZeffto+tF2kAiJmz3lJ5s6d63QIEiE8Hg/Jycl4PB6nQxEpkXJU3M7r9dKkSROdJymupXlUXGHmTLj2Wnv57rvh5pvDdylHpTwR0xCuOqghnIiIiIiI1IhvvoG//x1yc+GKK+w96CrEhShsCCdyMEzTZMOGDWrAIa6lHBW3CwaDzJw5Uw3hxLU0j4qjfv0VzjjDLszPOANefrlYYa4clfKoOJeYoMlQ3E45Km6Xn5/PokWLyM/PdzoUkRJpHhXH/Pkn9O0LmZlw3HHw7rvgL372sHJUyqPiXEREREREpCp27rQL840boWNH+N//oFYtp6OSCKXiXEREREREpLJycmDgQFi+HNLSYM4caNDA6agkgqk4l5jg9XpJTU1Vl2FxLeWouJ3f7ycjIwN/CYdqiriB5lE5pPLz4fzz4YcfoH59uzBv2bLMpyhHpTzq1i4iIiIiIlJRlmV3Y3/jDUhKgs8+s881FymFurWLFGKaJqtWrVIDDnEt5ai4XV5eHpMmTSIvL8/pUERKpHlUDpl77rELc58P3nuvwoW5clTKo+JcYoJpmmzfvl2TobiWclTcLhQKsWrVKkKhkNOhiJRI86gcEk89Bf/+t7386qv2ZdMqSDkq5VFxLiIiIiIiUp7Jk+G22+zl0aNh6FBHw5Hoo+JcRERERESkLJ98sr8Yv/lmuOsuR8OR6KTiXGKC1+slLS1N3THFtZSj4nZxcXF069aNuLg4p0MRKZHmUakx8+fDOedAKAQXXQRPPgkeT6VfRjkq5VG3dhERERERkZL8/jv06gU7dsDf/w4ffQTx8U5HJRFG3dpFCjEMg2XLlmEYhtOhiJRIOSpuFwgEGD9+PIFAwOlQREqkeVSq3ebN0LevXZgfcwxMm3ZQhblyVMqj4lxigmVZZGVlEUMHikiEUY6K25mmydatW9VlWFxL86hUq6ws6NcP1q6Fdu3g44+hbt2DeknlqJRHxbmIiIiIiEiB3Fw4+2xYsgSaNrWbwTVu7HRUEgNUnIuIiIiIiAAYBlxyCcybB/XqwaxZ0Lat01FJjFBxLjHB6/WSnp6u7pjiWspRcbv4+Hh69+5NvBohiUtpHpWDZllw4437zy3/4AM46qhqe3nlqJRH3dpFRERERERGjYKRI+3LpL33Hpx7rtMRSZRQt3aRQgzDYPHixeqOKa6lHBW3CwQCPPnkk+rWLq6leVQOyvjxdmEO8MILNVKYK0elPCrOJSZYlkUgEFB3THEt5ai4nWma7NmzR93axbU0j0qVvf8+3HCDvfzAAzBsWI28jXJUyqPiXEREREREYtO8eXDxxfb55tdeu3/vuYgDVJyLiIiIiEjsWbwYzjoLgkEYPBhefNE+31zEISrOJSb4fD46dOiAz+dzOhSREilHxe0SExMZNGgQiYmJTociUiLNo1Ipa9ZAv36QnQ0nnQRvvw01nDvKUSmPurWLiIiIiEjs2L4devWCP/6AI4+EL7+ElBSno5Iopm7tIoWEQiHmz59PKBRyOhSREilHxe1ycnJ49NFHycnJcToUkRJpHpUK2bsXBgywC/PWrWH27ENWmCtHpTwqziVm6LIV4nbKUXE7/UEpbqd5VMoUDMKQIbBgATRsCHPmQPPmhzQE5aiURcW5iIiIiIhEN9OEK66ATz6BWrXg44/h8MOdjkqkCBXnIiIiIiISvSwLbr/dbvrm99vXNT/2WKejEilGDeEkJliWRSAQICkpCY8ukSEupBwVtzMMg40bN9KiRQt1GhZX0jwqpXr8cbjrLnv5rbfg0ksdCUM5GrvUEE7kAPHx8U6HIFIm5ai4mcfjoWHDhvqDUlxN86gUM3Hi/sL8iSccK8wLKEelLCrOJSYYhsGCBQvUhENcSzkqbhcIBBg7diyBQMDpUERKpHlUivnoI7j6ant5xAi47TZHw1GOSnlUnIuIiIiISHT57js47zwwDPjHP+Df/3Y6IpFyqTgXEREREZHo8dtvMHAgBALQvz+89hp4VfaI+ylLRUREREQkOmzYAH37wu7ddkf2KVMgLs7pqEQqRN3aJSZYloVhGPh8PjUzEldSjorbmaYZ7jLs1R4ocSHNo8KuXXDiifae88MPh6+/hkaNnI4qTDkau9StXeQAwWDQ6RBEyqQcFTezLIudO3cSQ9/pSwTSPBrD9u2Ds86yC/PmzWHOHFcV5gWUo1IWFecSEwzDYMmSJeqOKa6lHBW3y83NZcKECeTm5jodikiJNI/GsFAILrwQvvkGUlLswrx1a6ejKkY5KuVRcS4iIiIiIpHJsuC66+DDDyExEWbOhM6dnY5KpEpUnIuIiIiISGT617/g9dftbuzvvGOfcy4SoVScS8zw+XxOhyBSJuWouJ3f73c6BJEyaR6NMc89B489Zi+/9BKcfbaz8VSAclTKom7tIiIiIiISWd55By6+2D6s/eGH7T3oIi6lbu0ihViWRWZmproMi2spR8XtDMNg8eLFamQkrqV5NIb83//BZZfZhfmNN8J99zkdUYUoR6U8Ks4lJhiGwfLly/VHpbiWclTcLjc3lxkzZqhbu7iW5tEY8dNPMHgw5OfDeefBM89AhFwzXDkq5VFxLiIiIiIi7rdyJQwYAHv3Qp8+8NZboHO4JYqoOBcREREREXfbsgX69oVt2+Coo2D6dEhIcDoqkWql4lxigsfjISkpCU+EHPYksUc5Km7n9XqpW7cuXq/+dBB30jwaxbKzoX9/WL0a0tNh1iyIwObOylEpj7q1i4iIiIiIO+Xl2YX5F19A48bwzTfQrp3TUYlUirq1ixRimibbtm3DNE2nQxEpkXJU3C4/P5+5c+eSn5/vdCgiJdI8GoUMA/7xD7swr1PH3mMewYW5clTKo+JcYoJpmqxevVqTobiWclTcLhgMMm/ePILBoNOhiJRI82iUsSy45RaYMgXi4mDGDDj6aKejOijKUSmPinMREREREXGXxx6D55+3L5M2aRKceqrTEYnUOBXnIiIiIiLiHq++Cv/6l738zDNw/vnOxiNyiKg4l5jg8XhITk5Wd0xxLeWouJ3X66VJkybq1i6upXk0SnzwAVx3nb18333wz386G081Uo5KedStXUREREREnPfVV3D66ZCbC1ddBa+8Yh/WLhLh1K1dpBDTNNmwYYMacIhrKUfF7YLBIDNnzlRDOHEtzaMR7pdf4Kyz7ML8rLNg/PioK8yVo1IeFecSEzQZitspR8Xt8vPzWbRokS6lJq6leTSCrVsH/fpBZib06gXvvAN+v9NRVTvlqJRHxbmIiIiIiDhjxw7o2xc2bYIjjoCZMyEpyemoRByh4lxERERERA69nBwYOBBWrICWLWH2bGjQwOmoRByj4lxigtfrJTU1VV2GxbWUo+J2fr+fjIwM/FF4qKlEB82jESY/H849F3780S7I58yBtDSno6pRylEpj7q1i4iIiIjIoWOaMHQovPWWfQj755/D3/7mdFQiNUbd2kUKMU2TVatWqQGHuJZyVNwuLy+PSZMmkZeX53QoIiXSPBpB7r7bLsx9Ppg6NWYKc+WolEfFucQE0zTZvn27JkNxLeWouF0oFGLVqlWEQiGnQxEpkebRCPHEE/Cf/9jLr78OAwY4G88hpByV8qg4FxERERGRmjdpEowYYS8//jhcdpmz8Yi4jIpzERERERGpWbNnwxVX2Mu33ba/SBeRMBXnEhO8Xi9paWnqjimupRwVt4uLi6Nbt27ExcU5HYpIiTSPutgPP8CQIRAKwSWX2Ie1ezxOR3XIKUelPOrWLiIiIiIiNWPFCujVC3buhNNPhw8/hPh4p6MSOaTUrV2kEMMwWLZsGYZhOB2KSImUo+J2gUCA8ePHEwgEnA5FpESaR11o0ybo29cuzHv0gPffj+nCXDkq5VFxLjHBsiyysrKIoQNFJMIoR8XtTNNk69at6jIsrqV51GUyM6FfP1i3Dtq3h48+gjp1nI7KUcpRKY+KcxERERERqT65uXD22fDLL9CsGXzyCaSmOh2ViOupOBcRERERkephGHDRRfDll1Cvnt2lvU0bp6MSiQgqziUmeL1e0tPT1R1TXEs5Km4XHx9P7969iY/h80XF3TSPuoBlwQ03wIwZkJAAM2dCly5OR+UaylEpj7q1i4iIiIjIwXvwQXjoIfsyaVOnwjnnOB2RiCuoW7tIIYZhsHjxYnXHFNdSjorbBQIBnnzySXVrF9fSPOqwF1+0C/OCZRXmxShHpTwqziUmWJZFIBBQd0xxLeWouJ1pmuzZs0fd2sW1NI86aOpUGD7cXh45Eq6/3tFw3Eo5KuVRcS4iIiIiIlXzxRdwySX2+ebXXw8PPOB0RCIRS8W5iIiIiIhU3qJF9iXTgkH7MPbnn7fPNxeRKlFxLjHB5/PRoUMHfD6f06GIlEg5Km6XmJjIoEGDSExMdDoUkRJpHj3EVq+G/v1hzx446SSYPBn0b18m5aiUR93aRURERESk4rZuhV69YNUq+1Jp8+ZBSorTUYm4lrq1ixQSCoWYP38+oVDI6VBESqQcFbfLycnh0UcfJScnx+lQREqkefQQ2bMHBgywC/M2bWDWLBXmFaQclfKoOJeYoctWiNspR8Xt9AeluJ3m0RqWlweDB8PChdCoEcyZA82bOx1VRFGOSllUnIuIiIiISNlMEy6/HD77DGrXho8/hsMOczoqkaii4lxEREREREpnWXDrrfDuu+D3w7Rp0KOH01GJRB01hJOYYFkWgUCApKQkPLrEh7iQclTczjAMNm7cSIsWLdRpWFxJ82gNGjMG7rnHXp48GS6+2Nl4IpRyNHZFXUO4cePG0aVLF+rVq0e9evU47rjjmDVrltNhSQSJj493OgSRMilHxc08Hg8NGzbUH5TiappHa8CECfsL86eeUmF+kJSjUpaIKc7T0tIYM2YMP/30EwsWLKBPnz6cffbZ/Prrr06HJhHAMAwWLFigJhziWspRcbtAIMDYsWMJBAJOhyJSIs2jNeDDD+Gaa+zlu+6CW25xNJxIpxyV8vidDqCizjzzzCK/P/roo4wbN47vv/+eI444osTn5OXlkZeXF/49OzsbsLvNFnSc9Xq9eL1eTNPENM3wYwvWG4ZB4SP/S1vv8/nweDzFOtkWHPp34H+Epa33+/1YllVkvcfjwefzFYuxtPUaU/H1BT8LHhMNYyocY7Rsp1gfU+FYo2VMFVmvMUXGmAoYhhF+rUgfUzRup1geU+H3j5YxlbW+xsf0ww9w/vl4DAPzH//AfPhhCIUie0wOb6fCn/XRMqZo3E41MaaKnkkeMcV5YYZhMGXKFHJycjjuuONKfdzo0aMZNWpUsfWLFi2idu3aAKSmppKRkcGaNWvYvn17+DFpaWmkpaXx+++/k5WVFV6fnp5O48aNWbp0aZG9Bx06dCAlJYVFixYVSYwuXboQHx/PggULisTQvXt3gsEgS5YsCa/z+Xz06NGDrKwsli9fHl6flJRE165d2bFjB6tXrw6vT05OpmPHjmzatIkNGzaE12tMxcdkWRaZmZlkZ2fTsGHDqBhTNG6nWB7TwoULyczMZOHChXg8nqgYUzRup1geU6dOnQBYvHgxcXFxUTGmaNxOsTwmy7LIyckBiJoxgTPbKWn1aroMH44nN5fdxx/P79dei/XTTxE9Jjdsp23btoU/61u2bBkVY4rG7VQTY2rTpg0VEVEN4X755ReOO+44cnNzqVOnDm+//TYDBgwo9fEl7Tlv2bIlO3fuDJ+Ir29+YmNMhmGwcOFCunfvTlxcXFSMqXCM0bKdYnlMwWCQhQsXcvTRR+Pz+aJiTNG4nWJ5THl5eYwdO5Zbb72VWrVqRcWYonE7xfKYCj7re/ToEY4/0sdU1voaG9P69fhOOgnPhg1Yf/sbxpw58Nd/8xE7pnJiP1Rjys/PD3/Wx8XFRcWYonE71cSYcnJySElJKbchXEQV58FgkD///JOsrCymTp3Kq6++yrx588Lf5pdH3dpjV8F/sAX/wYi4jXJU3M40zXCXYa83YlrWSAzRPFoNdu2CE06AZcugY0f46ito2NDpqKKGcjR2RV23drC7G7Zr145jjjmG0aNH07VrV5555hmnw5IIEQwGnQ5BpEzKUXEzy7LYuXNnhc+bE3GC5tGDsG8fnHGGXZinpcGcOSrMa4ByVMoSUcX5gUzTLHLYukhpDMNgyZIlxQ6DEXEL5ai4XW5uLhMmTCA3N9fpUERKpHn0IOTnw/nnw3ffQf36MHs2tGzpdFRRRzkq5YmYhnD33HMP/fv3p1WrVuzZs4e3336buXPnMmfOHKdDExERERGJTJYF114LH30EiYnwv/9BKVdCEpGaFTHF+bZt27jsssvYvHkzycnJdOnShTlz5nDaaac5HZqIiIiISGS6916YOBF8PnjvPTj+eKcjEolZEVOcv/baa06HIBGuoMOjiFspR8Xt/P6I+bNBYpTm0Up6+mkYM8ZefvllOPNMR8OJBcpRKUtEdWs/WOrWLiIiIiIC/Pe/cPHF9vJjj8E99zgbj0gUi8pu7SJVZVkWmZmZ6jIsrqUcFbczDIPFixerkZG4lubRSvjkE7j8cnv5ppvg7rudjSdGKEelPCrOJSYYhsHy5cv1R6W4lnJU3C43N5cZM2aoW7u4lubRCpo/H845x+7QfsEF8NRToGtuHxLKUSmPinMRERERkVjwxx8wcCDk5MCpp8Ibb4BX5YCIW+i/RhERERGRaLd5M/TtC9u3w9FHw7RpkJDgdFQiUoiKc4kJHo+HpKQkPDpsS1xKOSpu5/V6qVu3Ll7tZROX0jxahqws6N8f1qyBjAz4+GNQc+RDTjkq5VG3dhERERGRaJWbaxfmc+dCkybwzTd2gS4ih4y6tYsUYpom27ZtwzRNp0MRKZFyVNwuPz+fuXPnkp+f73QoIiXSPFoCw4BLL7UL87p1YdYsFeYOUo5KeVScS0wwTZPVq1drMhTXUo6K2wWDQebNm0cwGHQ6FJESaR49gGXB8OHw/vsQHw8zZkC3bk5HFdOUo1IeFeciIiIiItHm4Ydh/Hj7MmmTJkGfPk5HJCLlUHEuIiIiIhJNXn4ZHnzQXn7+eTjvPGfjEZEKUXEuMcHj8ZCcnKzumOJaylFxO6/XS5MmTdStXVxL8+hfpk+HYcPs5fvvhxtucDYeCVOOSnnUrV1EREREJBp8+SWcfjrk5cE118BLL9mHtYuIo9StXaQQ0zTZsGGDGnCIaylHxe2CwSAzZ85UQzhxrZifR5csgbPOsgvzs8+GF19UYe4yMZ+jUi4V5xITNBmK2ylHxe3y8/NZtGiRLqUmrhXT8+jatdCvH2RlwQknwH//C36/01HJAWI6R6VCVJyLiIiIiESq7duhb1/YvBk6d4aZMyEpyemoRKQKVJyLiIiIiESivXth4ED4/Xdo1Qpmz4b69Z2OSkSqSMW5xASv10tqaqq6DItrKUfF7fx+PxkZGfh1qKy4VMzNo8EgDBkC8+dDw4YwZw60aOF0VFKGmMtRqTR1axcRERERiSSmCZddBpMnQ61a8Pnn0LOn01GJSCnUrV2kENM0WbVqlRpwiGspR8Xt8vLymDRpEnl5eU6HIlKimJlHLQtGjLALc78f3n9fhXmEiJkclSpTcS4xwTRNtm/frslQXEs5Km4XCoVYtWoVoVDI6VBEShQz8+jYsfDUU/by66/bXdolIsRMjkqVqTgXEREREYkEb74Jd95pL48dC//4h7PxiEi1UnEuIiIiIuJ2H38MV15pL48YAbff7mw8IlLtVJxLTPB6vaSlpak7priWclTcLi4ujm7duhEXF+d0KCIliup59Pvv4bzzwDDsveX//rfTEUkVRHWOSrVQt3YREREREbdatgxOOAF27bLPL585E/QlmUhEUbd2kUIMw2DZsmUYhuF0KCIlUo6K2wUCAcaPH08gEHA6FJESReU8umED9O1rF+bHHgtTpqgwj2BRmaNSrVScS0ywLIusrCxi6EARiTDKUXE70zTZunWrugyLa0XdPLp7t72nfP16OOww+OgjqFPH6ajkIERdjkq1U3EuIiIiIuImgQCceSb8+is0bw6ffAKNGjkdlYjUMBXnIiIiIiJuEQrBhRfCN99AcjLMng2tWzsdlYgcAirOJSZ4vV7S09PVHVNcSzkqbhcfH0/v3r2Jj493OhSREkXFPGpZMGyY3fQtIQE+/BCOPNLpqKSaREWOSo1St3YRERERETe4/3545BHweuH992HQIKcjEpFqoG7tIoUYhsHixYvVHVNcSzkqbhcIBHjyySfVrV1cK+Ln0eeftwtzgPHjVZhHoYjPUalxKs4lJliWRSAQUHdMcS3lqLidaZrs2bNH3drFtSJ6Hn3vPbjpJnv54YfhmmucjUdqRETnqBwSKs5FRERERJzy2Wdw6aX2+eY33gj33ed0RCLiEBXnIiIiIiJOWLgQBg+G/Hw47zx45hnweJyOSkQcouJcYoLP56NDhw74fD6nQxEpkXJU3C4xMZFBgwaRmJjodCgiJYq4eXTVKujfH/bsgT594K23IFJilyqJuByVQ07d2kVEREREDqWtW+H442H1ajjqKJg3D/S3qUjUUrd2kUJCoRDz588nFAo5HYpIiZSj4nY5OTk8+uij5OTkOB2KSIkiZh7Nzrb3mK9eDW3bwqxZKsxjRMTkqDhGxbnEDF22QtxOOSpupz8oxe1cP4/m5dnnmC9aBKmp8Mkn0LSp01HJIeT6HBVHqTgXEREREalphgH/+Ad8/jnUqWPvMW/XzumoRMRFVJyLiIiIiNQky4JbboEpUyAuDqZPh2OOcToqEXEZNYSTmGBZFoFAgKSkJDy6RIm4kHJU3M4wDDZu3EiLFi3UaVhcydXz6KOPwr/+ZS//979w4YXOxiOOcHWOSo1SQziRA8THxzsdgkiZlKPiZh6Ph4YNG+oPSnE1V86jr766vzB/+mkV5jHOlTkqrqHiXGKCYRgsWLBATTjEtZSj4naBQICxY8cSCAScDkWkRK6cR2fOhOuus5fvuQduvtnZeMRRrsxRcRUV5yIiIiIi1e3rr+GCC8A04cor7UPbRUTKoOJcRERERKQ6LV0KZ54Jublwxhnw0kugU0JEpBwqzkVEREREqsu6ddC3L2RmwvHHw7vvgt/vdFQiEgHUrV1igmVZGIaBz+dTMyNxJeWouJ1pmuEuw16vvtsX93HFPLpzJ/TqBStWQKdO8NVX0KCBM7GI67giR8UR6tYucoBgMOh0CCJlUo6Km1mWxc6dO4mh7/QlAjk6j+bkwMCBdmHesiXMmaPCXIrRZ72URcW5xATDMFiyZIm6Y4prKUfF7XJzc5kwYQK5ublOhyJSIkfn0fx8OP98+OEHuyCfMwfS0g59HOJq+qyX8qg4FxERERGpKsuCq6+Gjz+GpCT43/+gY0enoxKRCKTiXERERESkqu6+G958E3w+eO89OO44pyMSkQil4lxihs/nczoEkTIpR8Xt/Oo4LS53yOfRJ5+Exx+3l1991b5smkgZ9FkvZVG3dhERERGRypo8GS691F4eMwbuusvZeETEtdStXaQQy7LIzMxUl2FxLeWouJ1hGCxevFiNjMS1Duk8OmcODB1qL99yC9x5Z82/p0Q8fdZLeVScS0wwDIPly5frj0pxLeWouF1ubi4zZsxQt3ZxrUM2j86fD0OGQCgEF10ETzwBuma1VIA+66U8Ks5FRERERCri999hwAD7muannQYTJ4JXf06LSPXQbCIiIiIiUp5Nm+D002HHDjjmGHj/fYiPdzoqEYkiKs4lJng8HpKSkvDosDNxKeWouJ3X66Vu3bp4tZdQXKpG59HMTOjfH9atg3bt7Gua161b/e8jUU2f9VIedWsXERERESlNbi707QtffglNm8K330Lbtk5HJSIRRN3aRQoxTZNt27ZhmqbToYiUSDkqbpefn8/cuXPJz893OhSREtXIPGoYcPHFdmFerx7MmqXCXKpMn/VSHhXnEhNM02T16tWaDMW1lKPidsFgkHnz5hEMBp0ORaRE1T6PWhbccANMn26fW/7BB3DUUdXz2hKT9Fkv5VFxLiIiIiJyoFGj4OWX7cukvf02nHyy0xGJSJRTcS4iIiIiUti4cXZxDvDii/Z1zUVEaliVivP09HR27txZbH1mZibp6ekHHZRIdfN4PCQnJ6s7priWclTczuv10qRJE3VrF9eqtnl06lS48UZ7+cEH4frrDz44EfRZL+WrUrd2r9fLli1baNy4cZH1W7dupVWrVuTl5VVbgNVJ3dpFREREpFRz59qd2YNBuPZaGD/ePqxdROQgVLQO9VfmRWfOnBlenjNnDsnJyeHfDcPgs88+o02bNpWPVqSGmabJpk2baN68ufb6iCspR8XtgsEgs2fPpl+/fsTHxzsdjkgxBz2P/vwznH22XZgPHmwfzq7CXKqRPuulPJUqzgcNGgTYh2RcfvnlRe6Li4ujTZs2PPHEE9UWnEh1MU2TDRs20LRpU02G4krKUXG7/Px8Fi1axKmnnqriXFzpoObR1auhf3/IzoaTTrIbwPl8NROoxCx91kt5KlWcF7T9b9u2LfPnz6dRo0Y1EpSIiIiIyCGxbZt9KPuWLXDkkfYl0xITnY5KRGJQpYrzAmvWrKnuOEREREREDq09e2DgQFi5Elq3htmzISXF6ahEJEZVqTh/6KGHyrz/gQceqFIwIjXF6/WSmpqqQ4jEtZSj4nZ+v5+MjAz8/ir96SBS4yo9jwaD9iXSFiyARo1gzhxo3rxmg5SYps96KU+VurV369atyO/5+fmsWbMm/MG9cOHCaguwOqlbu4iIiIhgmnDppfDf/0Lt2vD553DssU5HJSJRqka6tRdYtGhRiW84dOhQBg8eXJWXFKlRpmmyZs0a2rZtq28rxZWUo+J2eXl5TJkyhfPOO4+EhASnwxEppsLzqGXBbbfZhbnfD++/r8JcDgl91kt5qi0r6tWrx6hRo7j//vur6yVFqo1pmmzfvj3c1FDEbZSj4nahUIhVq1YRCoWcDkWkRBWeRx9/HJ55xl6eONFuBidyCOizXspTrV/ZZGVlkZWVVZ0vKSIiIiJSPSZMgLvvtpeffBIuucTZeERECqnSYe3PPvtskd8ty2Lz5s289dZb9O/fv1oCExERERGpNv/7H1xzjb18551w663OxiMicoAqFedPPfVUkd8LOg9efvnl3HPPPdUSmEh18nq9pKWl6fwecS3lqLhdXFwc3bp1Iy4uzulQREpU5jz67bdw/vlgGHD55TBmzKEPUGKePuulPFXq1h6p1K1dREREJMb89huccALs3g0DBsCMGaAvmUTkEKpoHXrQX9usX7+e9evXH+zLiNQowzBYtmwZhmE4HYpIiZSj4naBQIDx48cTCAScDkWkRCXOo+vX2w3fdu+Gnj3hvfdUmItj9Fkv5alScR4Khbj//vtJTk6mTZs2tGnThuTkZP71r3+Rn59f3TGKHDTLssjKyiKGDhSRCKMcFbczTZOtW7eqy7C4VrF5dNcuuzDfsAE6dICPPrKvaS7iEH3WS3mqdM75P//5T6ZNm8bjjz/OcccdB8B3333HyJEj2blzJ+PGjavWIEVEREREKmzfPjjzTFi2DFq0gDlzoGFDp6MSESlTlYrzt99+m3feeadIZ/YuXbrQsmVLLrroIhXnIiIiIuKMUAguuMBuApeSArNnQ6tWTkclIlKuKh3WnpCQQJs2bYqtb9u2LfHx8QcbU4lGjx5Njx49qFu3Lo0bN2bQoEGsWLGiRt5Loo/X6yU9PV3dMcW1lKPidvHx8fTu3bvGPudFDpbX6yW9bVt8w4bZl01LTIQPP4TOnZ0OTQTQZ72Ur0qZMXz4cB5++GHy8vLC6/Ly8nj00UcZPnx4tQVX2Lx587jxxhv5/vvv+fTTT8nPz+f0008nJyenRt5PoovX66Vx48aaDMW1lKPidnFxcZx88sm6lJq4ltfrpfEzz+CZOBG8Xnj3XbtLu4hL6LNeylOlS6kNHjyYzz77jISEBLp27QrA4sWLCQaDnHrqqUUeO23atOqJ9ADbt2+ncePGzJs3j5NOOqlCz9Gl1GKXYRgsXbqUzp074/P5nA5HpBjlqLhdIBBg3LhxDBs2jKSkJKfDESnGfOopvLfdZv/y6qtw1VXOBiRyAH3Wx66K1qFVOuc8JSWFIUOGFFnXsmXLqrxUlWVlZQHQoEGDUh+Tl5dXZO9+dnY2YHebD4VCgP0NltfrxTTNIh1oC9YbhlGko2Jp630+Hx6PJ/y6hdcDxS6ZUNp6v9+PZVlF1ns8Hnw+X7EYS1uvMRVfbxgG+/btwzRNfD5fVIypcIzRsp1ieUyhUIh9+/YRCoWwLCsqxhSN2ymWx2SaJnv27CE/Pz+89zzSxxSN2ylWx+R59118fxXmxsMP47niCsxC7xuJYypvvcYUeWMq/Fnv8XiiYkzRuJ1qYkwV3R9epeJ8woQJVXlatTFNk1tuuYVevXrRuYzziEaPHs2oUaOKrV+0aBG1/7qURmpqKhkZGaxZs4bt27eHH5OWlkZaWhq///57+IsAgPT0dBo3bszSpUuLXOu1Q4cOpKSksGjRoiKJ0aVLF+Lj41mwYEGRGLp3704wGGTJkiXhdT6fjx49epCVlcXy5cvD65OSkujatSs7duxg9erV4fXJycl07NiRTZs2sWHDhvB6jan4mCzLIjMzk+zsbBo2bBgVY4rG7RTLY1q4cCGZmZksXLgQj8cTFWOKxu0Uy2Pq1KkTYB8pV1CcR/qYonE7xeKYdrzzDh1uvx2APwcNovldd7E5wscUjdtJY1rDtm3bwp/1LVu2jIoxReN2qokxldSvrSRVOqy9T58+TJs2jZSUlCLrs7OzGTRoEJ9//nllX7JShg0bxqxZs/j6669JS0sr9XEl7Tlv2bIlO3fuDB9OoG9+YmNMhmGwcOFCunfvTlxcXFSMqXCM0bKdYnlMwWCQhQsXcvTRR+Pz+aJiTNG4nWJ5THl5eYwdO5Zbb72VWrVqRcWYonE7xdyY5s/H06cPnr17Mc49lx9vuYUePXuG44/IMUXjdtKYME2T/Pz88Gd9XFxcVIwpGrdTTYwpJyeHlJSUcg9rr1Jx7vV62bJlC40bNy6yftu2bbRo0YL8/PzKvmSFDR8+nA8++IAvv/yStm3bVuq5Ouc8dlmWRVZWFsnJyXg8HqfDESlGOSpuZxg6V1Jc5o8/oFcv2L4dTj0V63//Iys3V/OouJY+62NXjZxzXvgQgt9++40tW7aEfzcMg9mzZ9OiRYsqhFs+y7L45z//yfTp05k7d26lC3OJbR6Pp9iRHiJuohwVt/P5fOEmsCKO27IF+va1C/Nu3WDaNDyJiaQkJjodmUip9Fkv5alUcX7UUUfh8XjweDz06dOn2P1JSUk899xz1RZcYTfeeCNvv/02H3zwAXXr1g1/MZCcnKyusVKuUCjEokWL6NatG35/lVotiNQo5ai4XU5ODk8//TS33HJLuG+LiCOys6F/f1izBjIyYNYsqFdP86i4nnJUylOprFizZg2WZZGens6PP/5Iampq+L74+HgaN25cY4e6jRs3DoCTTz65yPoJEyYwdOjQGnlPiS4Hnp8i4jbKUXG7A8+hEznk8vJg0CD4+Wdo3BjmzIEmTcJ3ax4Vt1OOSlkqVZy3bt0aoMhJ8odKFU6NFxEREZFoYRhw6aXwxRdQty7Mnm3vORcRiRJVOp7izTffLPP+yy67rErBiIiIiIgUY1lw880wdSrEx8OMGfa55iIiUaRK3drr169f5Pf8/Hz27dtHfHw8tWrVYteuXdUWYHVSt/bYZVkWgUCApKQkdccUV1KOitsZhsHGjRtp0aKFurXLoffII3D//eDxwDvvwPnnF3uI5lFxO+Vo7KpoHeqtyovv3r27yG3v3r2sWLGCE044gf/+979VDlqkJsXHxzsdgkiZlKPiZh6Ph4YNG+oPSjn0XnnFLswBnn22xMK8gOZRcTvlqJSlSsV5Sdq3b8+YMWO4+eabq+slRaqNYRgsWLBATTjEtZSj4naBQICxY8cSCAScDkViyYwZcP319vJ998Hw4aU+VPOouJ1yVMpTbcU5gN/vZ9OmTdX5kiIiIiISi776Ci66CEwTrroKHn7Y6YhERGpUlRrCzZw5s8jvlmWxefNmnn/+eXr16lUtgYmIiIhIjPrlFzjrLMjNtX+OH2+fby4iEsWqVJwPGjSoyO8ej4fU1FT69OnDE088UR1xiYiIiEgsWrcO+vWDzEw44QS7AZy/Sn+yiohElCp1ay+wfft2AFJTU6stoJqkbu2xy7IsDMPA5/OpmZG4knJU3M40zXCXYa+3Ws+KE9lvxw67IF+xAo44wj60/YCrBJVG86i4nXI0dtVYt/bMzExuvPFGGjVqRNOmTWnatCmNGjVi+PDhZGZmHkzMIjUqGAw6HYJImZSj4maWZbFz504O4jt9kbLl5MDAgXZh3qoVzJlT4cK8gOZRcTvlqJSlUsX5rl276NmzJ2+88QZDhgzhiSee4IknnuCcc85h4sSJHHfccezevbumYhWpMsMwWLJkibpjimspR8XtcnNzmTBhArm5uU6HItEoPx/OPRd+/BEaNLAL8xYtKvUSmkfF7ZSjUp5KncDz0EMPER8fz6pVq2jSpEmx+04//XQeeughnnrqqWoNUkRERESilGnClVfC7NmQlAQffQQdOjgdlYjIIVepPeczZsxg7NixxQpzgKZNm/L4448zffr0agtORERERKLcnXfCpEng88HUqfC3vzkdkYiIIypVnG/evJkjjjii1Ps7d+7Mli1bDjookZrg8/mcDkGkTMpRcTu/OmZLdRs7Fgqu9PP66zBgwEG9nOZRcTvlqJSlUt3aW7RowbvvvssJJ5xQ4v1fffUVF1xwAZs2baq2AKuTurWLiIiIuMRbb8Fll9nLjz8Od9zhbDwiIjWkRrq19+3bl/vuu6/ELoN5eXncf//99OvXr/LRitQwy7LIzMxUl2FxLeWouJ1hGCxevFiNjKR6zJoFV1xhL992G4wYcdAvqXlU3E45KuWpVHH+0EMPsWLFCtq3b8/jjz/OzJkz+eCDDxgzZgzt27dn2bJljBo1qqZiFakywzBYvny5/qgU11KOitvl5uYyY8YMdWuXg/fDD3ZndsOASy6B//wHquGaz5pHxe2Uo1KeSp08lpaWxnfffccNN9zAPffcE/7Wx+PxcNppp/H888/TsmXLGglURERERCLc8uX2tcz37YO+fe3zzL2V2lckIhK1Kt3ZpW3btsyaNYvdu3fzxx9/ANCuXTsaNGhQ7cGJiIiISJTYuNEuyHfuhB497M7s8fFORyUi4hpVbrtav359jj322OqMRaTGeDwekpKS8FTDYXMiNUE5Km7n9XqpW7cuXu3llKrYvRv69YM//4TDDrOvZV6nTrW+heZRcTvlqJSnUt3aI526tYuIiIgcYoEAnH46fP01NGsG334Lbdo4HZWIyCFTI93aRSKVaZps27YN0zSdDkWkRMpRcbv8/Hzmzp1Lfn6+06FIJAmF4OKL7cI8ORlmz66xwlzzqLidclTKo+JcYoJpmqxevVqTobiWclTcLhgMMm/evBIvpypSIsuCG26AGTMgIQFmzoQuXWrs7TSPitspR6U8Ks5FREREpPo9+CC88ordjf2dd+Ckk5yOSETE1VSci4iIiEj1evFFePhhe3ncOBg0yNFwREQigYpziQkej4fk5GR1xxTXUo6K23m9Xpo0aaJu7VK+KVNg+HB7eeRIuPbaQ/K2mkfF7ZSjUh51axcRERGR6vH559C/PwSDMGwYvPACqBARkRinbu0ihZimyYYNG9SAQ1xLOSpuFwwGmTlzphrCSekWLbIPXw8GYcgQeO65Q1qYax4Vt1OOSnlUnEtM0GQobqccFbfLz89n0aJFupSalGz1anuP+Z49cPLJMGkS+HyHNATNo+J2ylEpj4pzEREREam6rVvh9NPtn1272pdOS0x0OioRkYij4lxEREREqmbPHhgwAFatgrZtYdYsSE52OioRkYik4lxigtfrJTU1VV2GxbWUo+J2fr+fjIwM/H6/06GIW+TlweDBsHAhpKbCnDnQrJlj4WgeFbdTjkp51K1dRERERCrHNOHii+Hdd6FOHZg7F445xumoRERcSd3aRQoxTZNVq1apAYe4lnJU3C4vL49JkyaRl5fndCjiNMuCW2+1C/O4OJg2zRWFueZRcTvlqJRHxbnEBNM02b59uyZDcS3lqLhdKBRi1apVhEIhp0MRp40ZA88+ay+/+Sacdpqz8fxF86i4nXJUyqPiXEREREQq5rXX4N577eWnn4YLL3Q0HBGRaKLiXERERETK9+GHcO219vLdd8PNNzsbj4hIlFFxLjHB6/WSlpam7pjiWspRcbu4uDi6detGXFyc06GIE779Fs4/324Ed8UV8NhjTkdUjOZRcTvlqJRH3dpFREREpHS//gonngi7d8MZZ8D06aBL6omIVJi6tYsUYhgGy5YtwzAMp0MRKZFyVNwuEAgwfvx4AoGA06HIobR+PfTrZxfmxx1nd2h3aWGueVTcTjkq5VFxLjHBsiyysrKIoQNFJMIoR8XtTNNk69at6jIcS3buhL59YcMG6NgR/vc/qFXL6ahKpXlU3E45KuVRcS4iIiIiReXk2IewL1sGaWkwZw40aOB0VCIiUU3FuYiIiIjsl58PF1wA338P9evD7NnQsqXTUYmIRD0V5xITvF4v6enp6o4prqUcFbeLj4+nd+/exMfHOx2K1CTLsi+X9tFHkJRkH8p+xBFOR1UhmkfF7ZSjUh51axcRERER2z33wJgx4PPZXdnPPNPpiEREIp66tYsUYhgGixcvVndMcS3lqLhdIBDgySefVLf2aPb003ZhDvDKKxFXmGseFbdTjkp5VJxLTLAsi0AgoO6Y4lrKUXE70zTZs2ePurVHq//+F2691V4ePRquuMLZeKpA86i4nXJUyqPiXERERCSWffIJXH65vXzzzXDXXc7GIyISo1Sci4iIiMSq+fPhnHPsDu0XXQRPPgkej9NRiYjEJBXnEhN8Ph8dOnTA5/M5HYpIiZSj4naJiYkMGjSIxMREp0OR6vL77zBggH1N87//HSZOhAjuIq15VNxOOSrlUbd2ERERkVizeTMcfzysXQvHHANffAF16zodlYhIVFK3dpFCQqEQ8+fPJxQKOR2KSImUo+J2OTk5PProo+Tk5DgdihysrCzo188uzNu1g48/jorCXPOouJ1yVMqj4lxihi5bIW6nHBW30x+UUSA3F84+G5YsgSZNYM4caNzY6aiqjeZRcTvlqJRFxbmIiIhILDAMuOQSmDfP3lM+ezakpzsdlYiI/EXFuYiIiEi0sywYPhymTYP4ePjgAzjqKKejEhGRQtQQTmKCZVkEAgGSkpLw6BIx4kLKUXE7wzDYuHEjLVq0UKfhSPTQQ/Dgg/Zl0t57D8491+mIqp3mUXE75WjsUkM4kQPEx8c7HYJImZSj4mYej4eGDRvqD8pI9NJLdmEO8MILUVmYF9A8Km6nHJWyqDiXmGAYBgsWLFATDnEt5ai4XSAQYOzYsQQCAadDkcqYNg1uuMFevv9+GDbM2XhqkOZRcTvlqJRHxbmIiIhINJo3Dy6+GEwTrrkGRo1yOiIRESmDinMRERGRaLN4MZx1FuTlwaBB8OKL9vnmIiLiWirORURERKLJmjXQrx9kZ8OJJ8Lbb4Pf73RUIiJSDnVrl5hgWRaGYeDz+dTMSFxJOSpuZ5pmuMuw16vv9l1r+3bo1Qv++AOOPBK+/BJSUpyO6pDQPCpupxyNXerWLnKAYDDodAgiZVKOiptZlsXOnTuJoe/0I8/evTBggF2Yt24Ns2fHTGFeQPOouJ1yVMqi4lxigmEYLFmyRN0xxbWUo+J2ubm5TJgwgdzcXKdDkZIEgzBkCCxYAA0b2oV58+ZOR3VIaR4Vt1OOSnlUnIuIiIhEMtOEK66ATz6BWrXg44+hQwenoxIRkUpScS4iIiISqSwLbr99f9O399+HY491OioREakCFecSM3w+n9MhiJRJOSpu51fHb/f5z3/g6aft5QkT7C7tMUzzqLidclTKom7tIiIiIpHojTdg6FB7+Ykn4LbbHA1HRERKpm7tIoVYlkVmZqa6DItrKUfF7QzDYPHixWpk5BYffQRXXWUv33GHCnM0j4r7KUelPCrOJSYYhsHy5cv1R6W4lnJU3C43N5cZM2aoW7sbfP89nHceGAZcdhmMGeN0RK6geVTcTjkq5VFxLiIiIhIpli2DgQMhEID+/eHVV8GrP+dERKKBZnMRERGRSLBhA/TtC7t2Qc+eMGUKxMU5HZWIiFQTFecSEzweD0lJSXg8HqdDESmRclTczuv1UrduXbzaS+uMXbvswnz9ejj8cPjf/6B2baejchXNo+J2ylEpj7q1i4iIiLjZvn1w+unwzTfQvDl89x20auV0VCIiUkHq1i5SiGmabNu2DdM0nQ5FpETKUXG7/Px85s6dS35+vtOhxJZQCC680C7MU1JgzhwV5qXQPCpupxyV8qg4l5hgmiarV6/WZCiupRwVtwsGg8ybN49gMOh0KLHDsuD66+HDDyExEWbOhM6dnY7KtTSPitspR6U8Ks5FRERE3Oj+++G11+xu7O+8Ayee6HREIiJSg1Sci4iIiLjNc8/Bo4/ayy+9BGef7Ww8IiJS41ScS0zweDwkJyerO6a4lnJU3M7r9dKkSRN1az8U3n0Xbr7ZXn7kEbj6amfjiRCaR8XtlKNSHnVrFxEREXGL//s/GDAA8vPhxhvtPej6Q15EJKKpW7tIIaZpsmHDBjXgENdSjorbBYNBZs6cqYZwNWnhQhg82C7MzzsPnnlGhXklaB4Vt1OOSnlUnEtM0GQobqccFbfLz89n0aJFupRaTVm1Cvr3h717oU8feOst8PmcjiqiaB4Vt1OOSnlUnIuIiIg4aetWOP102LYNjjoKpk+HhASnoxIRkUMsoorzL7/8kjPPPJPmzZvj8XiYMWOG0yGJiIiIVF12tr3HfPVqSE+HWbNAfXFERGJSRBXnOTk5dO3alRdeeMHpUCTCeL1eUlNT1WVYXEs5Km7n9/vJyMjA7/c7HUr0yMuzzzFftAgaN4Y5c6BpU6ejiliaR8XtlKNSnojt1u7xeJg+fTqDBg2q8HPUrV1ERERcwTDgootgyhSoUwfmzYOjj3Y6KhERqQEVrUOj+uvvvLw88vLywr9nZ2cDEAqFCIVCgP0NltfrxTTNIs0ZCtYbhkHh7y9KW+/z+fB4POHXLbwewDCMCq33+/1YllVkvcfjwefzFYuxtPUaU/H1pmmybt060tPT8fl8UTGmwjFGy3aK5THl5+ezbt06WrdujdfrjYoxReN2iuUxGYbBlClTGDx4MAl/nQ8d6WNybDt5PJg33YR3yhSsuDjM99/H260bHojcMblgOxV81mdkZIR/j/QxWZZFyAphYJCXn0dufi5BM0i+kY9hGZiY5IXyyAvlkW/mEzLsx5qWvT5khOznm0b48cHQ/ueHzBAWFqZlkm/kEzKLPta0TPs1Lfs1DdPA8lj2Y8z960zLBA/h17Es+zVNTPv1Tfu1Cm7WX/8zTCP8WAsLy7LCPw1r/31AOM7Cjy9Yf+BrFF5f5PeS1lnhe7D/X/w5BesL1hVsmyI/S7uf/fljWfaYvR4veCjyuAMfe+B9FX1MVV6j2P0V2Hdb/H0r/xr7H1vK+nLiLLj7koxbmHDJGFfPexX994jq4nz06NGMGjWq2PpFixZRu3ZtAFJTU8nIyGDNmjVs3749/Ji0tDTS0tL4/fffycrKCq9PT0+ncePGLF26lEAgEF7foUMHUlJSWLRoUZHE6NKlC/Hx8SxYsKBIDN27dycYDLJkyZLwOp/PR48ePcjKymL58uXh9UlJSXTt2pUdO3awevXq8Prk5GQ6duzIpk2b2LBhQ3i9xlR8TJZlkZmZSYMGDWjYsGFUjCkat1Msj+mnn34iMzOTHTt24PF4omJM0bidYnlMnTp1YtWqVSxcuJC4uLioGJNj2+mVV/C++CKWx8MfDzzArnr16JCVFdljcsF2siyLnJwc2rZty5YtW6p1TKZlkmvkktY2DX8tPz8u+pGcYA4BI0CukUvjtMYErSArVq0gz8wjz8gjz8yjfmp9cvJy2LRtE3lmnl1YW/kk1k4kJy+H7JxsgmaQoBkkZIWwvFbRYtsq+ge+iBT36zLD9fNemzZtKjSWqD6svaQ95y1btmTnzp3hwwki9ZvUstZrTMXXG4bBwoUL6d69O3FxcVExpsIxRst2iuUxBYNBFi5cyNFHH43P54uKMUXjdorlMeXl5TF27FhuvfVWatWqFRVjcmQ7vf463uuus+N56ims4cMjf0wu2U4Fn/U9evQIxw8QyA+QFcwiO5jNrn272B3YTWZuJpm5mewJ7iErL4vdgd3sCe5hT94e9gT3sDe41/79r3U5+Tm4RbwvnjhvHHG+OPxev7381+9x3r/W+eLweX34PD78Xn/4FueLw+fxhW9+rx+/z4/P68OL115f8Ly/1nssT3id1+PF7/Pj9XjD670eb5H1WNj3ezz4vfZrAHgsT3h9wetbloWHQuu99vsX7BEtuM/r9eLBR16uSX7QS36+h2DQgxHyEsr3kZdnkp/vIT9o30IhH/n5XvJyTUJ/PTY/30Mov+C5/PU4CAbt9aF8D3lBCOV7Ct3nJT/fstflY79HvodQvof9u74PXC5QaLmk9ZV5bFnri91Xwv0lKe85xe4vSeHHWPh84PN58HgKlsHrBY/HXu/1Wn8t2+vtmxev17KXPeDx/nW/Z//zPH/dV/Acjwc8Xiu8bsiZ9bj5umRXz3s5OTmkpKTE9mHtCQkJ4UPvCvP7/cUa2hT8Ax+o4IOioutLa5RTmfUej6fE9aXFWNn1sTomj8eDx+OpdOylrXfDmMqLsbLrNSbnxlQwmft8viKPieQxReN2iuUxFXzZfWCOlhWj28cEh3g7ffABDBtmL997L75bbjmo2EtbH225B/vHZFomuwK72Lp3K1v2bmFrzla25Wxj576dbMvZxsqNK7F+t9gV2MXOwE527NtBbii3xPepqlpxtagdV9v+GV87vFxwS4pLItGXSFJcEkn+pPDPRH9i+JbgTyDBl1Dqz3hfvF2E++LCy/G+eHweX/hvGbewLLu3YU6Ofdu7d/9yTg7s22ffcnJgz7796wp+BgL7f5a2nJsL+flOj7Rsfj/Ex0NcXPGfBct+v0Ve3l7q169DXJwnfF/Bze8v/vPA5ZJ+L3zz+cr+WbBccCv8+4H3lXXzeosuuyEt3TzvVfS/26guzkUKeL1e0tLSSvyPTcQNlKPidnFxcXTr1i18SLtU0ldfwYUXgmnClVfCI484HZGrWJZFZm4mG7I3hG/rs9ezIXsDW/ZuKVKIh8zKH+rt8/hITkwmJTGl6C0hheTEZJITkqmXUI+6CXWpG1+3xJ914uuQ6E+09w5HMMuyi93sbNizp+Sf2dl2kb1nT9k/CwrxQjsaD4m4OEhKgsRE+5aUBAkJ+38vaTkhoeitpHXx8ft/Fl5OSLDfs+Bnwf2Fi++K1F6mabFpUxbNm9fG63VBNSuuE1HF+d69e1m5cmX49zVr1vDzzz/ToEEDWrVq5WBk4nYFhY+IWylHxe3i4+M566yznA4jMv3yC5x1ll0RnXkmvPSSO3YzHUKWZe/NXr17Nat3r2bV7lWs3r2atZlrw8V4ZQ4db5DUgCa1m9CkThMa125Mo6RGNKrViIa1GtIwqSENazW0f/9ruW58Xdftca4qw4CsLMjMtG+7d+9fLnzLyrJv2dn7lwtuoRo6lT0hwb74QO3aRW+1au2/Hfh7rVp2cV3w88DlgltBEZ6YaO+tjUT6rJfyRFRxvmDBAk455ZTw77fddhsAl19+ORMnTnQoKokEhmHw+++/c9hhh5V6+ImIk5Sj4naBQIA33niDyy+/nKSkJKfDiRzr1kG/fna11KsXvPOOfexolMrOy2bZ9mUs27GM5TuWs3LXynBBnpWXVe7zGyY1JK1eGmn10mhZryUt6rWged3mNKndhKZ1moaL8XhffLHnRto8ahiwaxfs3Gnfduywf+7aZd92796/XHhdVvn/jBXi8diFdL16ULeu/bNgueD3OnXsW926RX8WvtWubf+sVSuqU7taRFqOyqEXUf8JnXzyyZVqyy9SwLIssrKylD/iWspRcTvTNNm6dWuRRjlSjh07oG9f2LQJjjgCZs60K5gosCuwi1+2/sKyHcv4bftvLNuxjGXbl7Fxz8Yyn9esTjMyGmSQXj+d9JR02tZvS8t6LUmrl0aLei2oFVf1fx+n59FAALZtg+3bi94KrysowHfssL+vOZhQa9WClJT9t/r17Z/Jyft/lnYrKLx1JtWh5XSOivtFVHEuIiIiEhFycuCMM2DFCmjZEmbPhgYNnI6qSjbv2cyiLYtYuHlh+LYua12pj29WpxkdUzvSsVFH2jdoT3r9dDIaZNAmpc1BFd9OCARg82b7tnVr2be9e6v2Hikp0LBh0VuDBnax3aBB8eWCYryEnsciEuFUnIuIiIhUp/x8OO88+OEHu5qaMwci5DzTzNxMvlv/Hd9t+I6fNv/Ews0L2bJ3S4mPbZPShk6pnejUqFO4GO+Y2pGUxJRDG3QV5ObCxo37b5s27S/CC98qewh5fDykpha/NW5s/2zUyL41bGj/bNBAh4KLyH6aDiQmeL1e0tPT1QlbXEs5Km4XHx9P7969iY8vfq6vFGKacNVVMGuW3b3qf/+Djh2djqpUf2b9ydd/fs3Xf37NN+u/4Zetv2BR9JBbr8dLh0YdOLrZ0Rzd9Gi6NevGUU2Pcl0RXjCPBgJeNm6EP/+E9evt24YNRYvxXbsq/rqJidCsGTRtCk2alH5r3Ng+XDxK+s5JDdBnvZTHY8XQSQ/Z2dkkJyeXe/F3ERERkSq58074z3/sdtIffAADBzodURFrdq9hzqo5zFs3j6///JoN2RuKPaZdg3b0atmLY1scy9HNjqZLky6uORzdNO1DyNetg7Vr7Z/r1tkFeEExvnt3xV4rMRFatNh/a9as5FtysgpuETk4Fa1DtedcYoJhGCxdupTOnTurO6a4knJU3C4QCDBu3DiGDRumbu2leeIJuzAHeO01VxTmOcEc5q6dy+yVs5mzag5/7PqjyP1+r5+jmx1Nr5a9OKHVCfRq2YsmdZo4FK3dIG3nTli9ev9t7dqihXheXvmvU6+efap/4VuLFtC8+f5ivH59Fd1yaOmzXsqj4lxigmVZBAIBdccU11KOituZpsmePXvUrb00kybBiBH28r//DZdf7kgYlmXxy7ZfwsX4139+TdAIhu/3e/0cl3Ycp6WfxomtT+TYFsce8r3ioZBdZK9cad9Wr4Y1a/YX43v2lP18r9curlu3hjZt7J+tWkHz5gZZWUvp1+8IGjbUn7jiPvqsl/Jo5hIRERE5GLNnwxVX2Mu33AJ33HFI396yLBZsWsDU36YyddlUVu9eXeT+Nilt6JfRj77t+tKnbR/qJdT8qX0FBfgff9gFeOGfa9bY95elRQtIT4e2be1bQRHepo3dWy8urqT3tFiwIEByck2MSESk5qk4FxEREamqH36AIUPsavPii+1D2w/BsdKWZfHjxh+Z8tsUpv42tcilzZL8SfRp24e+GX3p264v7Ru0x1NDMe3aZV8t7sDbypUQDJb+vMREaNcOMjLsW3r6/mK8TRv7fhGRWKPiXGKCz+ejQ4cOOr9HXEs5Km6XmJjIoEGDSFTVtN+KFfZ55fv2wemnw4QJ9jHXNaSgIH/313eZ+ttU1mevD99XK64WZxx2Bud1Oo/+7fpTO752Nb6v3eF82TL47Tf7tmyZfduxo/TnFRTg7dsX/9m8efX/U2keFbdTjkp51K1dREREpLI2boTjj7dbhPfoAZ9/DnXq1Mhb7di3g0lLJvHqwlf5dfuv4fV14utw5mFncm6nc+nXrt9BnzteUIQvXWrfCgrx334r+zzwtDQ4/PD9tw4d7J8tW9bodxUiIhFD3dpFCgmFQixatIhu3brh9yvtxX2Uo+J2OTk5PP3009xyyy3Url19e2UjUmYm9OtnF+bt28NHH1V7YW5aJp+v+ZxXF77K9OXTw03dkvxJDOowiPOPOJ++GX1Jiqta5/zdu+GXX/YX4gXLmZklP97ns/d6d+q0/9ahAxx2WI19J1FpmkfF7ZSjUh5lhcQMwzCcDkGkTMpRcbtQeV28YkEgAGedZVeyzZrBJ59Aamq1vfyG7A1M/Hkiry16jbWZa8Prj252NFd3u5qLjryIlMSUCr+eYdjnfy9ebN9+/tn+uXFjyY/3+eyCu3NnOOKI/YV4+/YQH39QQzskNI+K2ylHpSwqzkVEREQqwjDspm9ffWVfSHv2bLt7WTX4YcMPjP1uLNOWTcO07MvVJSckc2mXS7mq21V0a9at3NfYtw+WLIGFC/cX47/8Yq8vSevWdhF+5JH7fx5+OCQkVMuQRESkklSci4iIiJTHsuCGG2DGDLt6nTkTunQ5qJc0LZOPfv+I/3z7H77686vw+t6te3P10VczpOOQUg9bz86294IvXLj/tmwZlHQZ+qQku/Du2tW+HXWU/bva74iIuIsawklMsCyLQCBAUlJSjV1ORuRgKEfF7QzDYOPGjbRo0SI2Ow0/+CA89JDd4WzKFDjnnCq/VF4oj0lLJjH2u7Es37EcgDhvHJd0uYTbj7udzo07F3n8nj128b1gAcyfby//8UfJr92kCXTrZt8KivH27e3D1aOd5lFxO+Vo7FJDOJEDxEfCyXIS05Sj4mYej4eGDRvG5h+UL75oF+YFy1UszHcHdjN+wXie/fFZtuzdAkC9hHpcf8z13NTzJlrUa0FuLnz//f5CfP58WL7c3nF/oFat4Oiji96aNavqIKOD5lFxO+WolEXFucQEwzBYsGAB3bt3V3dMcSXlqLhdIBBg7NixjBgxIra6tU+dCsOH28sjR8J111X6JfYG9/LUd0/xn2//w56gfU2ytHpp3NLzVk5JvpqlP9XjsXvghx/s88RL6rvXsiV0725fte2YY+xCvFGjgxhXFNI8Km6nHJXyKCtERERESvLFF3DJJfZu6+uvhwceqNTT80J5vPzTyzz85cNs37cdgDZJR9Jt353s/eQCHn04jhG7iz8vNdUuwnv0sAvy7t2hadPqGJCIiLiZinMRERGRAy1aBGefDcGgfRj7889DBQ/pN0yDSUve5r5PH2DjvrUAxGW3J3/OI6z97VzWWt7wYxMT7b3gPXvC3/5m/2zVqsJvJSIiUUTFuYiIiEhhq1dD//52J7bevWHy5HI7qu3dC99/bzHh2w+ZmXMve2v9at+R3RzmPUj+oivAjKN9+/1F+N/+Zjd8j4s7BGMSERHXU7d2iQmWZWEYBj6fLzabGYnrKUfF7UzTDHcZ9nq95T8hUm3bBr16wcqVdqvzefMgObnYw7ZuhW++sS95/vXXsHDb95in3QYtv7MfEKiP//u7Oc43nBN61uL44+1iXOeJ1xzNo+J2ytHYpW7tIgcIBoMkJZV8vVgRN1COiptZlsXOnTtp0aKF06HUnD17YMAAuzBv0wZmzYLkZCwLVq3aX4h/9VWhS5kl7YS/3w1nvAqAz0zi1Fq3ck/fO+j1cIr2ih9imkfF7ZSjUpYo/upbZD/DMFiyZAmGYTgdikiJlKPidrm5uUyYMIHc3FynQ6kZBeeW//QTVmoqf7zwCeNmNOPCC6FFC/ta4VdeCa+//ldh7jFpccbrJN5xOBxjF+ZXHHUF60esYs5dj3Ly31SYH2qaR8XtlKNSHu05FxERkZhm5Jtkn3U59f/v/wj4anNm8GM+G9i+yGPi4+HYY+HEE6HF0Ut4c9cwftz8LQCdG3dm3MBxnNDqBCfCFxGRKKHiXERERGKKacKSJTB3LnzxuUW/ObcxLPgO+fg525jGZ1ndSUqC44+3+8GddJLdwC3fs4eRc0dy8w/PYFgGteNqM+rkUdzU8ybifNpNLiIiB0fFucQMXzmddkWcphwVt/P7I/PPBtOEpUvty5bPnWv3eNv91/XF7+RxhvEMAE91fYNTLzqdUSfBMcfYe8vBPt/+/WXvc8vsW9i4ZyMA53Y6l6f6PkVavTQHRiSl0TwqbqcclbKoW7uIiIhEFcuyzwv/7DP4/HO7KN+5s+hj6tSBh9pO4NZfrgTAGPsUvttvKfZauwK7uOGjG3j313cBSK+fzvP9n6d/+/41PQwREYkS6tYuUohlWWRlZfH/7d15fFT19f/x953JTHbCFoKsEpACIpusagUEpe7USrWKIlX7U9GKy1fRti5tLS2i5VsXpFWBb3HfcKsLouCCIrtSQSTsewDJOpnl3vv745qNBBKB5N5kXk8f9zGTz9zMnA9z/CQn9865GRkZXLoCnkSOwutM09Tq1avVs2dPTx752brVKcRLC/Lt2ys/npoqnXaaNGyYNHy41H/XW/L/4lrnwTvvrLYwfz/nfY1/fbx2FOyQ3/DrrtPu0t0/vVvJATotexHrKLyOHEVNKM4RF0zT1Nq1a9W/f/8Ge1omGjdyFF5XUlKiuXPnqkuXLkpNTXU7HO3b5xwRnz9f+uAD5+pnFQWDzmfGR4yQzjhDGjBA5d3TFy2SfvVLyTSlceOkyZMrfW9xtFh3zrtTjy55VJLUtUVXzfn5HA1oO6AeZoYjxToKryNHUROyAgAAeF4oJH32mVOIf/CBtHy5c/p6KZ/PKcDPOMMpyE85Rar2UsLffCOdd57zhOeeK/3rX1KFI1hLdyzVFa9dobV710qSJgyYoClnTlFKIKWOZwgAiHcU5wAAwHNMU1qxorwY//RTKRyuvM+JJzqF+IgRTlf1jIwannTrVmnUKKcb3ODB0osvlh1Oj1kxTf5ksv748R8Vs2I6Lu04PX3h0/pZl5/VzQQBADgIxTnigmEYSk5O5vM98CxyFF7n8/mUnp4un89XZ6+xaZM0b56zzZ8v7d9f+fG2baWRI53tjDOkNm1+xJPv3+8U5tu2Sd27S2+9JaU4R8PX71+vsa+O1eLtiyVJY3qM0fRzp6tFSotjMzHUC9ZReB05iprQrR0AALgiL8/53Pj77zsF+cGfG2/SxGneduaZTkHetWulM9Brr7jYeYLPP3cq/M8/l9q3lyS9vvZ1XTn3SuWH85WRmKHHznlMl510Gb88AwCOGbq1AxVYlqW9e/eqZcuWdXrUBzhS5Ci8LhqN6rPPPtOpp56qQFlntR8nFpOWLHGK8ffflxYvdk5fL+X3O2ebn3mmsw0cKB11z6RYTLrkEqcgb9pUeu89qX17mZapP3z0B03+1GkGd2r7U/XsL55Vh4wOR/mCcAvrKLyOHEVNKM4RFyzL0oYNG9S8eXMWQ3gSOQqvi0QiWrhwoQYMGPCjivMNG8qPjM+f7xwtr6hrV+mss5xifNgw52j5MWPb0rXXOqewJyU5tyeeqNyiXF326mX6YMMHkqSbB92sB898UAH/kf3RAd7AOgqvI0dRE4pzAABwzOTnl5+q/t57Uk5O5cebN3fOMC8tyDvU5YHqu++WZs1yDsm/+KJ06qn6cvuXuvjFi7U1f6tSAil68vwn9auTflWHQQAAUDsU5wAA4IiZpnNZs/fecwryzz93ziQvlZDgXNbsrLOcrV8/p1auc9OmSX/9q3P/n/+Ufd55+teyf+qmd25SxIzohOYn6NVLXlXPVj3rIRgAAGpGcY64YBiGMjIyaPADzyJH4XU+n09ZWVny+Xzatq38c+Pz5lXtqn7CCeXF+PDhUnp6PQf73HPSLbc49//yF4Wu+JUmvHG1Zq6cKUka3W20Zl04SxlJNV17DQ0J6yi8jhxFTejWDgAADisUkj7+2Dk6/t570jffVH68SRPnWuOjRjkFeadO7sQpyflrwbnnStGo9Nvfauv9t+nCF0Zrxa4V8hk+/eWMv+iOU+/gl2MAQL2hWztQgWVZ2rFjh9q0aUMDDngSOQovsW1p9eryU9U//liKxWL66U8/1bffniafL0EDBjiF+KhR0qBBx6Cr+rGwdKl00UVOYX7JJVp+xxU676nB2lm4Uy1TWur5XzyvEdkj3I4SdYR1FF5HjqImXvhRCtQ5y7K0bds2tW7dmsUQnkSOwm25udIHH5QX5Dt3Vn68U6eYhg1bqGuuGaizz05Q8+buxHlI330nnXOOVFgojRiht/5wiS6dPUxF0SKdmHmi3r7sbXVs2tHtKFGHWEfhdeQoakJxDgBAHIpEnOZtpcX48uXOEfNSycnOpc1Kj463b2/qoYek0aNtpaa6Fnb1du50gszNlfr106P3/Ew3v3KxLNvSyOyRennMy3y+HADgeRTnAADEAduW1q1zPpL9/vvO5c4KCyvv07t3eTF+6qnOpcFLFRXVb7y1lpcnnX22tHGjzC7Zuv13/TXto/+RJF3d92pNP3c61y8HADQIFOeICz6fT5mZmZxCBM8iR1EX9u+X5s8v76y+ZUvlx1u1cq41PmqUc9u69aGfKyEhQZ07d1aCJz5c/oOSEmn0aGnVKhW1baWxd3XW3K//KUn6yxl/0aTTJtH4LY6wjsLryFHUhG7tAAA0EpGI9MUX5UfHlyypfKp6MCj99KfO0fEzz3SOlDfY3xFNU7rkEumVV7QrK1Xn39VRSw98o6A/qNmjZ+vSnpe6HSEAAJLo1g5UYlmWNm7cqE6dOvHXSngSOYojYdvSmjVOMT5vnrRgQdXTz088sfya46efLqWkHNlrhcNhvfTSSxozZowSExOPOvajYtvSjTdKr7yib9oEdM5Nadp84Bs1T26u1y99Xad1OM3d+OAK1lF4HTmKmlCcIy5YlqXc3Fx17NiRxRCeRI6itnbvdrqqz5vn3G7fXvnxzExp5EjnVPWRI6W2bY/N68ZiMeXk5CgWi7lfnP/pT9ITT+jLttLP/l9Q34d3q0vzLvrPZf/RCS1OcDc2uIZ1FF5HjqImFOcAAHhYYaFznfEPPnC2r7+u/HhSknOq+plnOluvXg34VPXamDFDuvdefXS8dMFViSq0ijSo7SC9ddlbapnS0u3oAAA4YhTnAAB4SDQqffmlU4jPn+9c7iwWq7xP377lxfhpp1Xuqt6ovfqqdMMNerOrNOZXfoUV1hmdztDrl76utGCa29EBAHBUKM4RF3w+n9q1a8cpRPAscjR+WZZzNHz+fOnDD52j5AUFlffp1Mk5RX3kSGn4cOfU9foWCATUt29fBQIuXZZs4ULpssv0XA9LV/7CUMwwdcFPLtALF7+gpIR4+esEDod1FF5HjqImdGsHAKAe2bb03XdOIT5/vnO98X37Ku/TooU0YoRTjI8YIWVnuxOrZ3z1lfTTn+qfJ+TruvMk25AuP+lyzbxwJtcwBwB4Ht3agQpM09S6devUtWtX+f1+t8MBqiBHG7dNm5wivHTbtq3y46mpTif1M85wtj59vPe58VAopNmzZ2vcuHFKTk6uvxfetEn62c80tWe+/ucsZ+i6k6/TY+c+Jp/hsX8kuIp1FF5HjqImFOeIC7ZtKy8vT3F0oggaGHK0cdmyxSnCFyxwbjdvrvx4MCidcopTiI8YIQ0YILl1tnhtWZal3bt3y7Ks+nvR3FzZo87SPd126s9DnaE7T71Tk0dMlmEY9RcHGgTWUXgdOYqaUJwDAHCUNm92PhK9cKFTjG/cWPnxhASnAB8+XBo2TDr11CO/3njcKCyUde45mtj5Oz0yyBmaPGKyJp02yd24AACoIxTnAAD8CLYtrV/vFOIff+zcbtlSeR+/X+rfv3IxnkYz8dqLRGT94iLdkLVUM/o7Q4+d85huGHCDu3EBAFCHKM4RF3w+n7Kzs+mOCc8iR73LsqT//lf65BOnGP/4Y2nnzsr7JCQ4xfjppzvF+GmnSenproRbZ4LBoIYOHapgMFi3L2RZsn89XjcG5mlGf8mQoVmjZ+nK3lfW7euiwWMdhdeRo6gJ3doBAKigpERautQpxj/9VFq0SDpwoPI+iYnSoEFOMT50qDR4MEfGjwnbln3brbrx22l6fCCFOQCgcaBbO1CBaZpavXq1evbsSXdMeBI56p69e6UvvnAK8U8/lZYskSKRyvukpTkFeGkxPnCglBRnl9YOhUKaPn26rr/++jrr1m4/+KB+u3aaHh/kFOYzL5xJYY5aYx2F15GjqAnFOeKCbdsKhUJ0x4RnkaP1w7KkNWuco+Gl27p1VffLynJOTf/pT53b3r2dU9fjmWVZKigoqLNu7fbs2Zr40Z16dLBTmD91wVMa12dcnbwWGifWUXgdOYqaxPmvGgCAxuz776Uvv5QWL3YK8S++kPLyqu7XrZtzabPSgrxzZ4krddUf++23dcsL4/WPwc7X/zr/Xxrfd7y7QQEAUM8ozgEAjUI0Kn39tVOIf/GFc/vtt1X3S0lxPi9+yinONniw1Lx5/ccLh/3557pt+mj97yDnSNK/zpuhq/td7XJUAADUP4pzxAW/369u3brx+R54Fjn649i2lJPjNG5bssQ5Or5smRQKVd23c+fyYnzIEKlXL05RPxJJSUkaPXq0ko7hh+3tb77R//z1DP19QEySNOPsx3XNyb85Zs+P+MI6Cq8jR1ETurUDADzNtqVt28oL8SVLnPsHd1CXpKZNnWZtgwY5R8QHDpRatqzviFEb9tatumtiT/2tV74k6YmR/6v/d+pvXY4KAIBjj27tQAWxWEwrVqxQ3759lcAhM3gQOeqwbWnzZmnFCmn5cmdbtkzavbvqvsGg1KePNGCAsw0aJHXtKnH52LpRVFSkadOmaeLEiUpNTT26J/v+ez1wa/+ywvzxoVMozHHUWEfhdeQoakJWIG6Ypul2CMBhxVuOmqa0fn3lQnz5cqeJ28H8fqlnT6cI79/fue3Z0ynQUX9isdjRP0kopH9M6K8/9NwjSXp4wO91/bD/OfrnBRR/6ygaHnIUh0NxDgCocwUF0ldfSatWOdvKldLq1VJxcdV9AwGn8O7Xz9n69nUuZZaSUu9h41iLxTTzhlN08082SJLu6369bjnnTy4HBQCAN1CcAwCOmVjMadT29ddO8f31104xnpNT/f7JyU6DttJCvF8/6cQTpcTE+o0b9cC29dKto3RNh5WSpFvb/1L3jHnM3ZgAAPAQGsIhLti2rVAopOTkZBlcvBge1NBytLRJ2+rV5UX46tXSN99I4XD139O2rXMEvHdv57PivXtLXbo4p6zD+0zT1Pbt29W2bdsj6jT8zj2/0oV6XlG/dE3zkfrnje83iFxHw9HQ1lHEH3I0ftEQDjhIkA+nwuO8mKOmKW3aJK1Z4xTepduaNVJhYfXfk5LiHP3u2dPZSgtyuqY3bIZhqEWLFkf0C+XCv9+si6znFQ1IlyT11xMT3uUXU9QJL66jQEXkKA6H4hxxwTRNLV26VP3796c7JjzJ7RwtLJTWrZO+/VZau9a5Lb1fUlL99yQkON3RTzrJKcJLbzt1omN6YxQKhTR16lTdfvvtP6pb+9LZk3V+7j9Ukiidp5/o37cvkt/H6RI49txeR4GakKOoCVkBAHEiEnGOgq9fL333XXkB/u230vbth/6+xESpWzepRw+pe3fntkcP55T0QKDewkcDtPqNJzXqm7tVkCINj7TVi/cuV8BP0gAAUB2KcwBoREpKnAI8J8cpwEsL8fXrneuHH+4KLpmZ0k9+Unnr0cM5Es7nwvFj5Xz6hs765DfanyYNLG6m1+9dreQgLfcBADgUinMAaEAsS9q1S9q4Udqwoeq2Y8fhvz811Tni3aWLc0p6xUK8WbP6mQMav12rv9BZr/5cOzNsnVSYqnd+91+lpzR1OywAADyNbu2IC7ZtyzRN+f1+mhDBk0pz1Lb92rnT0ObNzhHwg2+3bHFOTz+c9HQpO1s64QSnCK9427q1xP8COBKWZZV1GfYdpqnAgS3rNOyhk7SqeUTZRUF9NvFrtW7TtR4jRbziZz28jhyNX3RrBw4SiUSUnJzsdhiIY5Yl7dsnbd3qFNlbt1a+v2WLTzt3Hv7Uc8lpttahg1OAV7c1b04BjmPPtm3t27dPbdu2PeQ+of27deGDJ2tVy4iyQn69f/VCCnPUK37Ww+vIURwOxTnigmma+uqrr+iOiTpTVCTt3OmcVr59e/Xbzp2HO+pt/LA5XdA7dJCOP17q2LHqbdu2NGJD/SspKdHMmTMP2a09FirSpff21MctC9UkbOjdi15V558MdiFSxCt+1sPryFHUhKwAgEMwTWnvXmn37vJt587qt4KC2j9v69ZS+/bO1qGDc9umjanCwjU666xuats2gQZsaFBs09Rv7uqpN1ruVWJMenPYDPUZeIHbYQEA0KBQnAOIG7Yt5eVJubnVb3v2VC7E9+51TkWvrZQU6bjjnCPbh9qOO04KBqt+byxma+nSQrVpQ2d0NDC2rUl3D9TMZpvks6QXet6v08+61u2oAABocCjOETf8VDyNimlKBw5I+/c72759zrZ3b+Xb0vulWzT6417HMKSWLaWsLGdr3dopsKvb0tOP7rPe5Ci8rrrTMKf++RxNSVkuSXqyzf/ThZfcU99hAWVYR+F15CgOh27tAFxTUiLl5ztF9oED0vffl9+v+PX33ztbaSG+f79zBPxIpaU51/Qu3Vq1Kr9fWoSXbi1bOp8BB1DV7P/9ta46MFOS9LfkC3THHa+7HBEAAN5Dt3agAtu2lZeXp4yMDC5dcZQsSyoudj5jXVjo3Obnl99WvF96m5dX/VbTJcFqIz3d6U7evLlTSLdoUX578P3SAtyLTVLJUXidaZpavXq1evbsKb/frzdn362r98+UfNLtsUEU5nAd6yi8jhxFTSjOERdM09TatWvjpjumbTtHpYuLna2oqOr9oqLKW2Fh1fuFheUFeOn9oiLn+Y+ljAypadPyrVmzyl83bVpegFfcmjZtPF3L4y1H0fCUlJRo7ty56pKQoJVTf6tftv1QZkAaV9hFU/62yO3wANZReB45ipqQFUAdsW3n883hcNWtpKR8O/jr0i0UOvTtwVtxceXbUKju52cYzunhTZo4R6+bNDn0/YwMZ6t4v3RLT3eu2w3A477/XpK07pyBOu9XxSoJSOeVdNCTD3wtg/+JAQA4ag2uOH/sscf04IMPateuXerdu7ceeeQRDRw40O2wUEcsS4rFnC0aPfz9aLTq/dItHDb07bcttGaNIcsqH49EKu8XiZSPld6vbguHq96veFu6eUFiotNFPCVFSk2telu6paVV/rp0S093trS0yrfJyUfX/AxAAxEOS48+Kv+UKdINN+iii00dSJZOad5bL1y3SAmBJLcjBACgUWhQxfkLL7ygW2+9VU888YQGDRqkadOmadSoUfr222/VqlUrt8M7Zj74wClKa9pMs/ZfH+5+6del96v7uqbHYrFDf116vza3B2/H7vRpv6QTjtWTHZGEBKdQTkyUkpKqbhXHExOd4rd0S0qq/jYlpfJtdfc5a6phMAxDycnJfAYN3mFZ0gsvSHffLW3apP0ZQeWZudrRxFaPzB56c/yHSgmkuB0lUIZ1FF5HjqImDapb+6BBgzRgwAA9+uijkiTLstS+fXvddNNNmjRpUpX9w+GwwhUOX+bn56t9+/basWNHWZe8hIQEJSYmKhwOKxaLle0bCAQUDAYVCoVkVbjQcTAYVCAQqDKelJQkv9+voqKiSjEkJSXJMAyFDjrPODk5WbZtq6SkpNJ4amqq/u0fKwUq/E9r2/JFbNl+yU6ocOqgZcsXtWX7DdkJFfY3bflitqwEQ/KXjxsxW4ZpywoYkq/iuCXDlKygUelQqBG1ZFiSlVj5dEUjYkm2ZB88HrYkQ7KDlcd9YUu2T7IDFcaPck6GJMMn+S1bftuWgoYMvyHD50zNb1nyS7ITDRmGIcOQfD5bAduWX5KZaMj3w74+nxSwbPkMyQwa8vucMZ9PCtq2DJ9kBZzx0udPNmzJL1l+Qz6/LZ/P+adONiTbb8v0//A8finBJ6X4pJghlWeY8+eCoKSIJLPCeIKkgKQSSRX/5wzYthIMo8p48IfnOvhM9qAkQ9LBB/ATf/j+g3uxJf8QR8VxQ1KSpJhtK1oxN34Yj4o5MSfm1FjnFF23TsbXX0uSCtu10rlXB7QksknHpx+vdy57R23T28rn8yk5OVnRaFSRCh0eS8cjkYiiFa5f6MWfuaZpVhpnTsyJOTEn5sScjvWcIpGImjdv3ni6tUciES1btkx33XVX2ZjP59PIkSP1+eefV/s9kydP1v33319l/B//+IeSkpzT8Dp37qyxY8fqpZdeUk5OTtk+ffv21QUXXKDZs2dr9+7dZeNDhw7VsGHDNH36dBUUFJSNjx49Wr1799a0adMqvaHjx49XixYtNHXq1Eox3H777dq3b59mzpxZNpaQkKDf/e53GtxpsZ69YmzZeOaePbrh8ce1vHc/vXnBBWXjndev1+VzntGCnw7TwmHDymNfvlwXvPGG3jjnAq3o16889gULNGzBAs25ZKxyunQpGz//jTfUb/lyPX7NDcqtcAbC5f/+t7rk5GjyrXcpkphYNn79Y48pIz9ff63wXkjSpMmTldekiaZPmFA2FgyHddfkyVrfqbOeueKKupvTLw8xpxsOMae7jsGcOh9iTv2qzmnsnDn6bFj1c3r3gurn9PLY6uf09CHmNO0Qc5ryI+a08RBz+oo5MSfmFJ9zOu88SVJMMS2NTNZ5vvPUr6CfnpvxnCQpPT1dt956qz777DMtXLiw7DmysrJ03XXX6d1339WKFSvK5+rBn7mrV6/W3Llzy8aZU8OeU8uWLXX99dc3qjk1xveJOTGneJvTxRdfrNpoMEfOd+zYobZt22rRokUaMmRI2fgdd9yhhQsXavHixVW+p6EeOTcffljhCs/tMwwl+f2KWpai1YxHLEuxCuN+n0+JPp/CliWzwniCz6egz6cS05RV4W0P+HwKVDOe6PPJ7/OpuMK/S+m4IamkwnNLUpLPJ1uqFLskpSQkyLQsV+dk27a2bd+u7HbtFEhIaBRzqhh7Y3mf4nlOIdPUtu3b1a5tWxmG0Sjm1Bjfp7iaUyAg89xzNGHZ/XrxmxeV5E/SLeYtuuGGG5SS4pzO7rUjE43xaAtzqv2cTNPUqlWrNGTIEFmW1SjmVHG8sbxP8TyncDisVatWqXfv3kpKSmoUc2qM75ObR84bdXF+sNpe/B2NTywW09KlS7l0BTyLHIUX3THvDj246EH5Db9eGv2SvnrtK91+++1KTU11OzSgCtZReB05Gr9qW4c2mGuftGzZUn6/v9LpBJK0e/dutW7d2qWoAABonB5a9JAeXPSgJOmpC57SWZ3PcjkiAAAatwZTnAeDQZ188smaP39+2ZhlWZo/f36lI+lAdQzDUEZGBt0x4VnkKLxkzldzdPu82yVJfxv5N43rM04+n09ZWVnycU1zeBTrKLyOHEVNGsxp7ZJzKbVx48ZpxowZGjhwoKZNm6YXX3xRa9euVVZWVo3fz2ntAAAc3tvr3taFz18o0zY1cdBEPTzqYX6RBADgKDS609ol6ZJLLtHUqVN1zz33qE+fPlq5cqXefffdWhXmiG+WZWnbtm2VGjYAXkKOwgsWbV2kMS+NkWmbGttrrB4a9VBZYR6JRPTGG29UaqwDeAnrKLyOHEVNGlRxLkk33nijNm/erHA4rMWLF2vQoEFuh4QGgMUQXkeOwm2r96zWuc+eq1AspLO7nK2nL3haPqP814RoNKoVK1ZU6m4LeAnrKLyOHEVNGlxxDgAAjq1NBzZp1JxROlByQEPaDdFLY15SwB9wOywAAOIKxTkAAHFsT9EenfXvs7SjYIdOzDxRb132llKDXCoNAID6RnGOuODz+ZSZmUmXYXgWOQo35IfzdfYzZ+u7/d+pY0ZHvTf2PTVPbl7tvgkJCercuTPX5oVnsY7C68hR1KRBdWs/WnRrBwDAURIr0bnPnqsPN36olikt9dmvP1PXFl3dDgsAgEanUXZrB46UZVnKycmhAQc8ixxFfTItU2NfHasPN36otGCa3r383RoL83A4rDlz5igcDtdTlMCPwzoKryNHUROKc8QFy7KUm5vLYgjPIkdRX2zb1oT/TNAra15R0B/U65e+rpPbnFzj98ViMeXk5CgWi9VDlMCPxzoKryNHUROKcwAA4oRt25r0wSTNWDZDhgw9c9EzOqPTGW6HBQAARHEOAEDcmPzpZE1ZNEWSNOO8Gbq4x8UuRwQAAEpRnCMu+Hw+tWvXju6Y8CxyFHXtkcWP6Hcf/k6S9NBZD+nak6/9Ud8fCATUt29fBQJc/xzexDoKryNHURO6tQMA0MjNXjlbV71+lSTpntPv0f3D73c3IAAA4gjd2oEKTNPUmjVrZJqm26EA1SJHUVde+eYV/fqNX0uSJg6aqPuG3XdEzxMKhfTEE08oFAodw+iAY4d1FF5HjqImFOeIC7ZtKy8vT3F0oggaGHIUdeHd9e/qV6/8SpZt6eq+V+vhUQ/LMIwjei7LsrR79266DMOzWEfhdeQoakJxDgBAI/TJ5k900QsXKWpF9csTf6kZ58044sIcAADUPYpzAAAamWU7luncZ89VKBbSOSeco3///N/y+/xuhwUAAA6D4hxxwefzKTs7m+6Y8CxyFMfKN7nfaNScUSqIFGhox6F6eczLCvqDR/28wWBQQ4cOVTB49M8F1AXWUXgdOYqa0K0dAIBGYk3uGg2fPVy7i3ZrQJsBmn/lfKUnprsdFgAAcY1u7UAFpmlq1apVdMeEZ5GjOFpr964tK8z7tO6jdy5/55gW5qFQSA8//DDd2uFZrKPwOnIUNaE4R1ywbVuhUIjumPAschRH49u935YV5r2zeuuDKz5Qi5QWx/Q1LMtSQUEB3drhWayj8DpyFDWhOAcAoAFbt2+dhs8erl2Fu3RSq5P0wZXHvjAHAAB1j+IcAIAG6rt932n47OHaWbhTPVv11Pwr56tlSku3wwIAAEeA4hxxwe/3q1u3bvL7uZQQvIkcxY+1fv96DZ89XDsKdujEzBM1/8r5ykzNrLPXS0pK0ujRo5WUlFRnrwEcDdZReB05iprQrR0AgAYmZ3+Ohs0epm3529Qjs4c+GveRWqW2cjssAABQDbq1AxXEYjEtWbJEsVjM7VCAapGjqK0N32/Q8NnDtS1/m7q37K4Pr/ywXgrzoqIiPfDAAyoqKqrz1wKOBOsovI4cRU0ozhE3uGwFvI4cRU1KP2O+NX+rurXspg/HfaistKx6e31+oYTXsY7C68hRHE6C2wEAAICafb37a5357zO1u2i3urboqg+v/FCt01q7HRYAADhGOHIOAIDHLd62WENnDdXuot3qldVLH1/1sY5LP87tsAAAwDFEQzjEBdu2FQqFlJycLMMw3A4HqIIcxaF8tPEjnf/c+SqKFmlwu8H6z2X/UbPkZvUeh2ma2r59u9q2bUunYXgS6yi8jhyNXzSEAw4SDAbdDgE4LHIUB3vz2zd19jNnqyhapBGdRmjeFfNcKcwlyTAMtWjRgl8o4Wmso/A6chSHQ3GOuGCappYuXUoTDngWOYqDPfv1s/r5Cz9X2Azrwp9cqLcue0tpwTTX4gmFQpo6dapCoZBrMQCHwzoKryNHUROKcwAAPGbG0hka++pYmbapsb3G6qUxLykpIcntsAAAQB2iOAcAwEOmfDZF1719nWzZur7/9Zo9erYC/oDbYQEAgDpGcQ4AgAdYtqU7592pOz+4U5I06dRJeuycx+Qz+FENAEA8oFs74oJt2zJNU36/n2ZG8CRyNL6VxEo0bu44vfjfFyVJk0dM1qTTJrkcVWWWZZV1Gfb5+IMBvId1FF5HjsYvurUDB4lEIm6HABwWORqf9hbv1Yj/G6EX//uiAr6AZl04y3OFueT8Urlv3z7F0d/00QCxjsLryFEcDsU54oJpmvrqq6/ojgnPIkfj03f7vtOQp4Zo0dZFykjM0Htj39O4PuPcDqtaJSUlmjlzpkpKStwOBagW6yi8jhxFTRLcDgAAgHj06ZZPdeHzF2p/aL+Ob3q8/nPZf9Q9s7vbYQEAAJdw5BwAgHr23NfPacT/jdD+0H4NbDtQX1z9BYU5AABxjuIcccPv97sdAnBY5GjjZ9u2/vLJX3TZq5cpYkZ0UfeL9NG4j5SVluV2aLWSkMAJd/A21lF4HTmKw6FbOwAA9SAcC+uGt2/Q0yufliTdNuQ2TTlzCpdKAwCgkaNbO1CBbds6cOAAXYbhWeRo47Ytf5uGzhqqp1c+LZ/h02PnPKapZ01tUIW5aZpatWoVjYzgWayj8DpyFDVpOL8VAEfBNE2tXbuWXyrhWeRo4/Xhxg/Vb0Y/Ld6+WM2SmumtX72lGwbc4HZYP1pJSYnmzp1Lt3Z4FusovI4cRU348BgAAHXAtm09uOhB3TX/Llm2pT6t++iVX76i7GbZbocGAAA8iOIcAIBjLK8kT+NfH6/X1r4mSRrXe5ymnztdyYFklyMDAABeRXGOuGAYhpKTk2UYhtuhANUiRxuP1XtW66IXLtJ3+79T0B/UP372D/3m5N80+PfW5/MpPT1dPh+fiIM3sY7C68hR1IRu7QAAHCPPff2crnnzGhVHi9W+SXu9/MuXNbDtQLfDAgAALqJbO1CBZVnas2ePLMtyOxSgWuRow1YcLdaEtyfoslcvU3G0WCM6jdCy3yxrVIV5NBrVggULFI1G3Q4FqBbrKLyOHEVNKM4RFyzL0oYNG1gM4VnkaMO1ZPsS9ZvRT48vfVySdNdpd+m9se8pMzXT5ciOrUgkooULFyoSibgdClAt1lF4HTmKmvCZcwAAjkDMiukvn/xFf1z4R5m2qePSjtPMC2dqVJdRbocGAAAaIIpzAAB+pHX71unK167U4u2LJUljeozRE+c9oebJzV2ODAAANFQU54gLhmEoIyOD7pjwLHK0YbBtWzOWzdBt79+m4mixMhIz9Ng5j+myky5r9O+dz+dTVlYW3drhWayj8DpyFDWhWzsAALWws2Cnrn7jar2z/h1J0hmdztCsC2epfUZ7lyMDAABeRrd2oALLsrRt2zYacMCzyFHvsmxLs1bO0knTT9I7699Roj9Rfx/1d827Yl5cFeaRSERvvPEGDeHgWayj8DpyFDWhOEdcYDGE15Gj3vT17q81dNZQjX99vPaF9qlv675a9ptlmjh4onxGfP0IjUajWrFiBZdSg2exjsLryFHUhM+cAwBwkIJwge5feL+mfTFNpm0qNZCq+4bdp5sH3ayAP+B2eAAAoBGiOAcA4Ae2bevVNa/q5ndv1vaC7ZKki7pfpGmjpsXVKewAAKD+UZwjLvh8PmVmZtJlGJ5FjrovZ3+ObnznRr27/l1JUnazbD1y9iM654RzXI7MGxISEtS5c2clJPCrA7yJdRReR46iJnRrBwDEtfxwvqYumqopn01R2Awr6A/qzlPv1F2n3aXkQLLb4QEAgAaObu1ABZZlKScnhwYc8CxytP6VxEr08OcPK/t/s/Wnj/+ksBnWyOyR+vr6r/XH4X+kMD9IOBzWnDlzFA6H3Q4FqBbrKLyOHEVNKM4RFyzLUm5uLoshPIscrT8xK6anVzytro901W3v36Z9oX36SYuf6OUxL+v9se+ra4uubofoSbFYTDk5OYrFYm6HAlSLdRReR46iJnxwDAAQF2zb1mtrX9PvPvyd1u5dK0lq16Sd7ht6n8b1GacEHz8SAQCAe/hNBADQqNm2rQ83fqi75t+lJTuWSJKaJzfX3afdrRsG3MDp6wAAwBMozhEXfD6f2rVrR3dMeBY5euyZlqm5a+fqwUUPavH2xZKk1ECqbh1yq24bcpsykjJcjrBhCQQC6tu3rwIBrvMOb2IdhdeRo6gJ3doBAI1KKBrSrJWz9PAXD2v9/vWSpER/oq7td61+f/rvlZWW5XKEAAAgntCtHajANE2tWbNGpmm6HQpQLXL06O0t3qv7F9yvDtM66Ib/3KD1+9erWVIz/e6nv9PmiZv1yDmPUJgfhVAopCeeeEKhUMjtUIBqsY7C68hR1ITT2hEXbNtWXl6e4uhEETQw5OiRW79/vaZ9MU1Pr3haoZhTOB7f9HjdMvgW/brvr5UWTHM5wsbBsizt3r2bLsPwLNZReB05ippQnAMAGpxQNKRX17yqJ1c8qQWbFpSN9zuun/7nlP/RxT0upvs6AABoUPjNBQDQYKzctVJPLn9Sz3z9jA6UHJAkGTJ09gln67Yht2n48cNlGIa7QQIAABwBinPEBZ/Pp+zsbLpjwrPI0UPLK8nTc6uf05PLn9SyncvKxjtmdNSv+/5a4/uMV/uM9i5GGB+CwaCGDh2qYDDodihAtVhH4XXkKGpCt3YAgOcURgr19rq39fKal/X2urfLPkse8AX08+4/1zV9r9GI7BHyGfyCAwAAvK22dShHzhEXTNPU6tWr1bNnT/n9frfDAaogR6WCcIHeXPemXv7mZb2z/h2VxErKHuuR2UPX9L1GV/S+Qi1TWroYZfwKhUKaPn26rr/+eiUnJ7sdDlAF6yi8jhxFTSjOERds21YoFKI7JjwrXnP0QMkBvbXuLb30zUt6b/17Cpvhssc6N+usMT3G6OIeF6vfcf34LLnLLMtSQUEB3drhWfG6jqLhIEdRE4pzAEC9sWxLy3Ys03s57+nd9e/qi21fyLTLr/fatUXXsoK8d1ZvCnIAABA3KM4BAHVqZ8FOvZfznt7LeU/zcuZpX2hfpce7t+yui3tcrDE9xqhnq54U5AAAIC5RnCMu+P1+devWjc/3wLMaU45uz9+uT7d8qs+2fqaFmxfqq91fVXq8SWITjeg0QqM6j9KoLqN0fNPj3QkUP0pSUpJGjx6tpKQkt0MBqtWY1lE0TuQoakK3dgDAEbNsS9/kfqNPt3xaVpBvOrCp0j6GDJ3c5mSnGO88SoPbDVbAH3AnYAAAgHpGt3agglgsphUrVqhv375KSCDt4T0NIUdt29bGAxu1fOdyrdi5Qst2LtPi7Yt1oORApf18hk+9s3rrtA6n6dT2p+qMTmcoMzXTnaBxzBQVFWnatGmaOHGiUlNT3Q4HqKIhrKOIb+QoakJWIG6YplnzToCLvJSjMSumdfvWacXOFVq+c7mW73IK8rxwXpV9UwIpGtJuiE5tf6pO63CaBrcbrPTEdBeiRl2LxWJuhwAclpfWUaA65CgOh+IcAOJYKBrSun3rtGbvGn2T+03Z7Xf7vlPUilbZP+gP6qRWJ6lv677qd1w/DWg7QL2zenOaOgAAwFGiOAeARq44WqyN32/Uhu83KOf7nLLbb/d+qw3fb5Ct6luPpARS1Kd1H/Vr3U99j3OK8R6ZPRT0B+t5BgAAAI0fDeEQF2zbVigUUnJyMpdpgicdaY7atq39of3alr+tbNuav1Vb8raUFeG7Cncd9jmaJTVT98zu6t6yu3pk9lD3lt3VPbO7OmR0kM/wHe3U0EiYpqnt27erbdu2dBqGJ/GzHl5HjsYvGsIBBwkGOdoHb6uYo6Zlal9on3YV7tLuwt3aXbS77P6uol3anr+9rBgPxUI1PndGYoY6N++s7GbZym6arc7NO+uE5ieoe2Z3ZaVm8UsCamQYhlq0aEGuwNP4WQ+vI0dxOBTniAumaWrp0qXq378/3TFRr2zbVigW0oGSA2Xb/tB+7S3eq33F+7QvtE/7ivcptyhXm/ZsUiQhor3Fe5VbnCvLtmr9OpkpmWrXpJ3aZ7RXu3TnNrtZtrKbZatzs85qltysDmeJeBAKhTR16lTdfvvtdGuHJ/GzHl5HjqImDSYrHnjgAb399ttauXKlgsGgDhw44HZIABqpqBlVUbRIxdFiFUWKKt0viBSoIFxQ/W2kQPnhfB0oOaC8kryyYry6xmq11TKlpVqntVZWapay0rLUOrW1stKy1Ca9jdo3aa92TdqpbZO2SkpIOob/AgAAAKhvDaY4j0QiGjNmjIYMGaKnnnrK7XAAHCXbtmXZlmJWTFErqqgZrXT/4LGIGVHEjChqlt+vuIXNsMKxcJXbkliJc9907oeiIYVioWrvF0eLVRwtPqpi+lB8hk9Nk5oqIzFDLVJaqEVyi7Lblikt1TSxqfJ25mnAiQOUle4U4pkpmXRBBwAAiBMNpji///77JUmzZs1yN5B68OqaV2vcpzZ9/A7VgfnHOPh1Dn7OI4mjpuc8ktet+HjFx0rHTdPUxu0btTqwWj6fr9J+pftU933V7VPb+xW/9+D71d0e/L2WbVV63LKtw96vuH/pfcu2Kj1u2ZYsHfR1hc20zapjllk2XnrftMyy/SuOxaxYlTHTdsar27zOb/iVGkxVaiBVKYEUpQZTlR5MV3piunNb8X6F26ZJTatsqYHUw35WNxaLOae6ZXOqGwAAQDxq1L8BhsNhhcPhsq/z8/MlOb8Ex2JOYeDz+eTz+WRZliyr/POdpeOmaVYq2g417vf7ZRhG2fNWHJec4rA24wkJCbr4xYuPSWGNaqx2OwDUxGf4FPAFFPAHFPAFlOBLUMAXUNAfVDAhqKA/WP71D/cTExIV9AeV6C+/TUpIUnIg2dnPF1RigjOWEkhRSjDF2cefpKSEpLLxtMQ0JSckK9mfrJRAioL+oPx+/zFZI0odao2wbVt9+/aVbduKxWKHXSNs2640bhiG/H5/lRgPNe7FdY85eX9OycnJuu222xQIBMqeq6HPqTG+T/E8p9J1tDHN6XDjzKnhzaniz3rLshrFnBrj+1QXc6rtBdIadXE+efLksiPuFa1YsaKsmU1mZqY6d+6sjRs3Kjc3t2yfdu3aqV27dlq3bp3y8vLKxrOzs9WqVSutXr1aoVB5h+Ru3bqpadOmWrFiRaXE6NWrl4LBoJYuXVophv79+ysSieirr74qG/P7/RowYIAGtxms4uLisnGf36fU1FRFI1GVlJSUjSckJCglJUXhcFiRSKRsPBAIKCkpSSUlJYpGy0/PDQaDSkxMVHFxcaUYk5OSFQgGVFRYJNMqH09JSVFCQoIKCworJVRaWpoMw1BBQYEkyZBzNDC9Sbpsy1ZhYWH5EUJDapLeRGbMVFFxUflcfX6lpacpEokoFAqVPUdCQoJSU1Or/GElGAgqJSVFxaFiRSPRsv0TkxKVnJSsoqKiSv8TpKakKhgMKr8gX7ZZflQ6PT1dgUCgSs+CjCYZ8vl8yjvgvNel8Tdr2kyWZSk/P7/sNX0+n5o1a6ZYNFb+b/DD/+jNmjZTSbhExYXFZePBQFBNmzZVcVGxikPFMn74LzkpWU2aNFFBQYHCJeGy509LS1Naapry8vIUjUTL/o0zMjKUlpKmvXv3yjRN51kMQy2at1BKUop27dol27blM3wyZCgrK0vBhKB27tgpwzDkk0+GYah9u/ayTEu7du2S3/DLkKEEf4I6deykkpIS7dm9Rz755DN8CgaD6tSxkwoLCrU3d698hk9++ZWWmqaOHTpq/779+n7f9/IbfvkMn5o3a64O7Tpo145dys/Ld8blU9vj2qpdm3bauGGjiguL5Tf8SjASlN0pW61btdba/65VNBwte57S/5+WLFly1P8/HThwQGvXri3P90CyevfqrT179mjDhg3l+Z6Rop90/4m2bdumnG05ZeP1tUYsW7ZMpmmW/eA53Jzy8vIqzyk5Wb1799bevXsrzSkjI0Pdu3fXjh07tG3btnqf0495n5iT9+fUr18/bdmyRXl5eWVrZEOfU2N8n+J9TikpKTrppJMa1Zwa4/sUz3Mq/VnfmObUGN+nYz2n448/XrXh6nXOJ02apL/97W+H3WfNmjXq1q1b2dezZs3SxIkTa9UQrroj5+3bt9e+ffvKri/HX37iY06maWr58uXq379/paM+DXlOFWNsLO9TPM8pEolo+fLl6tevn/x+f6OYU2N8n+J5TuFwWFOnTtUtt9yilJSURjGnxvg+xfOcSn/WDxgwoCz+hj6nw40zp4Y3p2g0WvazPhAINIo5Ncb3qS7mVFRUpKZNm3r7Oue33XabrrrqqsPuk52dfcTPn5iYqMTExCrjCQkJVT7TWfoPfLDSJKjt+KE+K/pjxg3DqHb8UDH+2PF4nZNhGGVHexrLnGqK8ceOMyf35lS6mPv9/kr7NOQ5Ncb3KZ7nVPrH7oNz9HAxen1OUuN7n6T4nlPpz/nGNKcjHWdO3ptTxZ/1pfs09Dk1xvepLuZ0uL5Dlb6vVnvVkczMTGVmZroZAgAAAAAArmswnznfsmWL9u/fry1btsg0Ta1cuVKS1KVLF6WlpbkbHBqEQ/1lC/AKchRex5UE4HWso/A6chSH4+pnzn+Mq666SrNnz64y/tFHH2nYsGG1eo78/HxlZGTUeK4/AAAAAADHQm3r0Kon1HvUrFmznOs6H7TVtjBHfLNtWwcOHKj1ZQyA+kaOwutM09SqVauqNOIBvIJ1FF5HjqImDaY4B46GaZpau3Ytv1TCs8hReF1JSYnmzp1b6ZKegJewjsLryFHUhOIcAAAAAACXUZwDAAAAAOAyinPEBcMwlJycXOtrDAL1jRyF1/l8PqWnp1d7/VfAC1hH4XXkKGrSYLq1Hwt0awcAAAAA1KdG160dOBqWZWnPnj2yLMvtUIBqkaPwumg0qgULFigajbodClAt1lF4HTmKmlCcIy5YlqUNGzawGMKzyFF4XSQS0cKFCxWJRNwOBagW6yi8jhxFTSjOAQAAAABwGcU5AAAAAAAuozhHXDAMQxkZGXTHhGeRo/A6n8+nrKwsurXDs1hH4XXkKGpCt3YAAAAAAOoI3dqBCizL0rZt22jAAc8iR+F1kUhEb7zxBg3h4Fmso/A6chQ1oThHXGAxhNeRo/C6aDSqFStWcCk1eBbrKLyOHEVNKM4BAAAAAHAZxTkAAAAAAC6jOEdc8Pl8yszMpMswPIschdclJCSoc+fOSkhIcDsUoFqso/A6chQ1oVs7AAAAAAB1hG7tQAWWZSknJ4cGHPAschReFw6HNWfOHIXDYbdDAarFOgqvI0dRE4pzxAXLspSbm8tiCM8iR+F1sVhMOTk5isVibocCVIt1FF5HjqImFOcAAAAAALgsrrq6lH68Pj8/3+VIUN9isZiKioqUn59PMyN4EjkKrysqKlJJSYny8/Nlmqbb4QBVsI7C68jR+FVaf9bU7i2uGsJt27ZN7du3dzsMAAAAAECc2bp1q9q1a3fIx+OqOLcsSzt27FB6eroMw3A7HNSj/Px8tW/fXlu3bqVTPzyJHIXXkaPwOnIUXkeOxi/btlVQUKA2bdoc9lJ6cXU+hc/nO+xfKtD4NWnShMUQnkaOwuvIUXgdOQqvI0fjU0ZGRo370BAOAAAAAACXUZwDAAAAAOAyinPEhcTERN17771KTEx0OxSgWuQovI4chdeRo/A6chQ1iauGcAAAAAAAeBFHzgEAAAAAcBnFOQAAAAAALqM4BwAAAADAZRTnAAAAAAC4jOIccSscDqtPnz4yDEMrV650OxxAkrRp0yZdffXV6tSpk5KTk9W5c2fde++9ikQiboeGOPbYY4/p+OOPV1JSkgYNGqQvv/zS7ZAASdLkyZM1YMAApaenq1WrVho9erS+/fZbt8MCDumvf/2rDMPQxIkT3Q4FHkRxjrh1xx13qE2bNm6HAVSydu1aWZalGTNm6L///a/+/ve/64knntDdd9/tdmiIUy+88IJuvfVW3XvvvVq+fLl69+6tUaNGac+ePW6HBmjhwoWaMGGCvvjiC82bN0/RaFRnnXWWioqK3A4NqGLJkiWaMWOGevXq5XYo8CgupYa49M477+jWW2/VK6+8ohNPPFErVqxQnz593A4LqNaDDz6o6dOna8OGDW6Hgjg0aNAgDRgwQI8++qgkybIstW/fXjfddJMmTZrkcnRAZbm5uWrVqpUWLlyo008/3e1wgDKFhYXq16+fHn/8cf35z39Wnz59NG3aNLfDgsdw5BxxZ/fu3br22mv173//WykpKW6HA9QoLy9PzZs3dzsMxKFIJKJly5Zp5MiRZWM+n08jR47U559/7mJkQPXy8vIkiTUTnjNhwgSde+65ldZT4GAJbgcA1CfbtnXVVVfpuuuuU//+/bVp0ya3QwIOa/369XrkkUc0depUt0NBHNq7d69M01RWVlal8aysLK1du9alqIDqWZaliRMn6tRTT1XPnj3dDgco8/zzz2v58uVasmSJ26HA4zhyjkZh0qRJMgzjsNvatWv1yCOPqKCgQHfddZfbISPO1DZHK9q+fbt+9rOfacyYMbr22mtdihwAGoYJEyZo9erVev75590OBSizdetW3XzzzXrmmWeUlJTkdjjwOD5zjkYhNzdX+/btO+w+2dnZ+uUvf6k333xThmGUjZumKb/fr8svv1yzZ8+u61ARp2qbo8FgUJK0Y8cODRs2TIMHD9asWbPk8/G3VNS/SCSilJQUvfzyyxo9enTZ+Lhx43TgwAG9/vrr7gUHVHDjjTfq9ddf18cff6xOnTq5HQ5QZu7cufr5z38uv99fNmaapgzDkM/nUzgcrvQY4hvFOeLKli1blJ+fX/b1jh07NGrUKL388ssaNGiQ2rVr52J0gGP79u0aPny4Tj75ZM2ZM4cf2nDVoEGDNHDgQD3yyCOSnFOHO3TooBtvvJGGcHCdbdu66aab9Nprr2nBggU64YQT3A4JqKSgoECbN2+uNDZ+/Hh169ZNd955Jx/BQCV85hxxpUOHDpW+TktLkyR17tyZwhyesH37dg0bNkwdO3bU1KlTlZubW/ZY69atXYwM8erWW2/VuHHj1L9/fw0cOFDTpk1TUVGRxo8f73ZogCZMmKBnn31Wr7/+utLT07Vr1y5JUkZGhpKTk12ODpDS09OrFOCpqalq0aIFhTmqoDgHAA+ZN2+e1q9fr/Xr11f5gxEnOsENl1xyiXJzc3XPPfdo165d6tOnj959990qTeIAN0yfPl2SNGzYsErjM2fO1FVXXVX/AQHAUeC0dgAAAAAAXEaHIQAAAAAAXEZxDgAAAACAyyjOAQAAAABwGcU5AAAAAAAuozgHAAAAAMBlFOcAAAAAALiM4hwAAAAAAJdRnAMAAAAA4DKKcwAAUGdOP/10Pfvss7Xe/9JLL9VDDz1UhxEBAOBNFOcAADRAV111lUaPHl3vrztr1iw1bdq0Vvu+8cYb2r17ty699NJaP//vf/97PfDAA8rLyzvCCAEAaJgozgEAQJ34xz/+ofHjx8vnq/2vGz179lTnzp01Z86cOowMAADvoTgHAKARGDZsmH7729/qjjvuUPPmzdW6dWvdd999lfYxDEPTp0/X2WefreTkZGVnZ+vll18ue3zBggUyDEMHDhwoG1u5cqUMw9CmTZu0YMECjR8/Xnl5eTIMQ4ZhVHmNUrm5ufrwww91/vnnV3r+YDCoTz75pGxsypQpatWqlXbv3l02dv755+v5558/un8QAAAaGIpzAAAaidmzZys1NVWLFy/WlClT9Mc//lHz5s2rtM8f/vAH/eIXv9CqVat0+eWX69JLL9WaNWtq9fynnHKKpk2bpiZNmmjnzp3auXOnbr/99mr3/fTTT5WSkqLu3buXjQ0bNkwTJ07UFVdcoby8PK1YsUJ/+MMf9OSTTyorK6tsv4EDB+rLL79UOBw+gn8FAAAaJopzAAAaiV69eunee+/VCSecoCuvvFL9+/fX/PnzK+0zZswYXXPNNeratav+9Kc/qX///nrkkUdq9fzBYFAZGRkyDEOtW7dW69atlZaWVu2+mzdvVlZWVpVT2v/85z+rWbNm+s1vfqOxY8dq3LhxuuCCCyrt06ZNG0UiEe3atetHzB4AgIYtwe0AAADAsdGrV69KXx933HHas2dPpbEhQ4ZU+XrlypXHPJZQKKSkpKQq48FgUM8884x69eqljh076u9//3uVfZKTkyVJxcXFxzwuAAC8iiPnAAA0EoFAoNLXhmHIsqxaf3/pUW7btsvGotHoEcXSsmVLff/999U+tmjRIknS/v37tX///iqPl45lZmYe0WsDANAQUZwDABBHvvjiiypfl34uvLQY3rlzZ9njBx9VDwaDMk2zxtfp27evdu3aVaVAz8nJ0S233KJ//etfGjRokMaNG1flDwirV69Wu3bt1LJly1rPCwCAho7iHACAOPLSSy/p6aef1rp163Tvvffqyy+/1I033ihJ6tKli9q3b6/77rtP3333nd5++2099NBDlb7/+OOPV2FhoebPn6+9e/ce8tTzvn37qmXLlvrss8/KxkzT1NixYzVq1CiNHz9eM2fO1FdffVXlNT755BOdddZZx3jmAAB4G8U5AABx5P7779fzzz+vXr166f/+7//03HPPqUePHpKc0+Kfe+45rV27Vr169dLf/vY3/fnPf670/aeccoquu+46XXLJJcrMzNSUKVOqfR2/36/x48frmWeeKRt74IEHtHnzZs2YMUOS85n4f/7zn/r973+vVatWSZJKSko0d+5cXXvttXUxfQAAPMuwK36wDAAANFqGYei1117T6NGj6+X1du3apRNPPFHLly9Xx44da/U906dP12uvvab333+/jqMDAMBbOHIOAADqROvWrfXUU09py5Yttf6eQCBQ60u7AQDQmHDkHACAOFHfR84BAEDtcZ1zAADiBH+PBwDAuzitHQAAAAAAl1GcAwAAAADgMopzAAAAAABcRnEOAAAAAIDLKM4BAAAAAHAZxTkAAAAAAC6jOAcAAAAAwGUU5wAAAAAAuOz/A6GrdjLN5twTAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8: Use Keras to build and train a simple multilayer neural network on the MNIST digits dataset. Print the training accuracy.**\n"
      ],
      "metadata": {
        "id": "jsNqzHSIcakw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "b7b664ac",
        "outputId": "a89948fb-592d-4f28-d772-76abaa26c664"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f\"Original training data shape: {x_train.shape}\")\n",
        "print(f\"Original testing data shape: {x_test.shape}\")\n",
        "\n",
        "# 2. Preprocess the data\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Flatten the images from 28x28 to 784-dimensional vectors\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "print(f\"Flattened training data shape: {x_train_flat.shape}\")\n",
        "print(f\"Flattened testing data shape: {x_test_flat.shape}\")\n",
        "\n",
        "# The labels (y_train, y_test) are already integers from 0-9. Keras's sparse_categorical_crossentropy\n",
        "# loss function can handle integer labels directly, so no one-hot encoding is strictly necessary for labels.\n",
        "\n",
        "# 3. Build a simple multilayer neural network model\n",
        "model = keras.Sequential([\n",
        "    # Input layer: Flatten the 28x28 images into a 784-dimensional vector\n",
        "    # layers.Input(shape=(28, 28)), # This is implicitly handled by x_train_flat shape\n",
        "    # layers.Flatten(), # If passing (28,28) directly\n",
        "\n",
        "    # Hidden layer 1 with ReLU activation\n",
        "    layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
        "\n",
        "    # Hidden layer 2 with ReLU activation\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "\n",
        "    # Output layer with 10 units (for 10 digits) and softmax activation\n",
        "    # Softmax ensures the output is a probability distribution over the 10 classes\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\", # Adam is a popular choice for many tasks\n",
        "    loss=\"sparse_categorical_crossentropy\", # Suitable for integer labels\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 5. Train the model\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    x_train_flat,\n",
        "    y_train,\n",
        "    epochs=10, # Number of passes over the entire dataset\n",
        "    batch_size=32, # Number of samples per gradient update\n",
        "    validation_split=0.1 # Use 10% of training data for validation\n",
        ")\n",
        "\n",
        "# 6. Print the training accuracy\n",
        "# The training accuracy is usually the last accuracy recorded in the training history\n",
        "training_accuracy = history.history['accuracy'][-1]\n",
        "print(f\"\\nFinal Training Accuracy: {training_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Optional: Evaluate the model on the test set to see generalization performance\n",
        "print(\"\\nEvaluating model on test data...\")\n",
        "loss, accuracy = model.evaluate(x_test_flat, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Original training data shape: (60000, 28, 28)\n",
            "Original testing data shape: (10000, 28, 28)\n",
            "Flattened training data shape: (60000, 784)\n",
            "Flattened testing data shape: (10000, 784)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model training...\n",
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.4489 - val_accuracy: 0.9677 - val_loss: 0.1104\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9649 - loss: 0.1165 - val_accuracy: 0.9720 - val_loss: 0.0957\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0746 - val_accuracy: 0.9733 - val_loss: 0.0954\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0564 - val_accuracy: 0.9775 - val_loss: 0.0864\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0447 - val_accuracy: 0.9742 - val_loss: 0.0975\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0350 - val_accuracy: 0.9765 - val_loss: 0.0915\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0266 - val_accuracy: 0.9795 - val_loss: 0.0833\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.9783 - val_loss: 0.0916\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0198 - val_accuracy: 0.9765 - val_loss: 0.1146\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0204 - val_accuracy: 0.9752 - val_loss: 0.1180\n",
            "\n",
            "Final Training Accuracy: 99.35%\n",
            "\n",
            "Evaluating model on test data...\n",
            "Test Accuracy: 97.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 9: Visualize the loss and accuracy curves for a neural network model trained on the Fashion MNIST dataset. Interpret the training behavior.**\n"
      ],
      "metadata": {
        "id": "qCmLCrdvx_VR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa96d3c7"
      },
      "source": [
        "# Task\n",
        "Visualize the loss and accuracy curves for a neural network model trained on the Fashion MNIST dataset, and then interpret the training behavior, analyzing trends for signs of overfitting, underfitting, or optimal learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0f5506c"
      },
      "source": [
        "## Load Fashion MNIST Data\n",
        "\n",
        "### Subtask:\n",
        "Load the Fashion MNIST dataset using Keras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dd2c6a"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the Fashion MNIST dataset, I will use `tensorflow.keras.datasets.fashion_mnist.load_data()`. Printing the shapes will confirm the data has been loaded and split correctly into training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3ef400f",
        "outputId": "2a1f1bfe-30cf-477e-f88a-b602095deb29"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1. Import the fashion_mnist dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# 2. Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# 3. Print the shapes of the loaded data to verify\n",
        "print(f\"Shape of x_train: {x_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of x_test: {x_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shape of x_train: (60000, 28, 28)\n",
            "Shape of y_train: (60000,)\n",
            "Shape of x_test: (10000, 28, 28)\n",
            "Shape of y_test: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa1b59f8"
      },
      "source": [
        "## Preprocess Data\n",
        "\n",
        "### Subtask:\n",
        "Normalize the pixel values of the images to a range of 0-1 and flatten the 28x28 images into 784-dimensional vectors, suitable for input into a dense neural network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e84cef3"
      },
      "source": [
        "**Reasoning**:\n",
        "To preprocess the data for the neural network, I will normalize the pixel values and flatten the images according to the instructions. This prepares the data for model input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d135a6",
        "outputId": "16b151b4-02bf-4dd8-9f44-cd962af423dd"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "print(f\"Shape of x_train after normalization and flattening: {x_train_flat.shape}\")\n",
        "print(f\"Shape of x_test after normalization and flattening: {x_test_flat.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train after normalization and flattening: (60000, 784)\n",
            "Shape of x_test after normalization and flattening: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed54c428"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is preprocessed, the next step is to define and compile a neural network model using Keras. This model will take the flattened image data as input and classify it into one of the 10 fashion categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "aeaca4db",
        "outputId": "a209679e-09f2-4ac9-f771-85530d3caf66"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Build a simple multilayer neural network model\n",
        "model = keras.Sequential([\n",
        "    # Input layer expects flattened images (784 features)\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "\n",
        "    # Hidden layer\n",
        "    layers.Dense(64, activation='relu'),\n",
        "\n",
        "    # Output layer with 10 units (for 10 classes) and softmax activation\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam', # Adam is a good general-purpose optimizer\n",
        "    loss='sparse_categorical_crossentropy', # Suitable for integer labels\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "print(\"Model built and compiled successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built and compiled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4973c6db"
      },
      "source": [
        "**Reasoning**:\n",
        "To visualize the loss and accuracy curves, I need to train the previously defined model on the preprocessed Fashion MNIST data. The `model.fit()` method will return a `History` object containing the training and validation metrics, which can then be used for plotting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fe38f23",
        "outputId": "855638df-980f-42f9-8227-5aed8d47838c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Train the model\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    x_train_flat,\n",
        "    y_train,\n",
        "    epochs=20, # Increased epochs slightly to observe trends better\n",
        "    batch_size=32, # Number of samples per gradient update\n",
        "    validation_split=0.1, # Use 10% of training data for validation\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nModel training complete.\")\n",
        "\n",
        "# 2. Visualize the loss and accuracy curves\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Interpret the training behavior\n",
        "print(\"\\n--- Interpretation of Training Behavior ---\")\n",
        "print(\"The plots show the training and validation accuracy and loss over 20 epochs.\")\n",
        "print(\"We observe the following trends:\")\n",
        "print(\"1. Training Accuracy: Steadily increases, indicating the model is learning from the training data.\")\n",
        "print(\"2. Validation Accuracy: Also increases initially, but starts to plateau or slightly decrease after a certain number of epochs, suggesting potential overfitting.\")\n",
        "print(\"3. Training Loss: Consistently decreases, showing the model is getting better at fitting the training data.\")\n",
        "print(\"4. Validation Loss: Decreases initially, but then starts to increase after some epochs, which is a strong indicator of overfitting. The model is learning the training data too well, to the detriment of its performance on unseen (validation) data.\")\n",
        "print(\"\\nConclusion: The model appears to be overfitting to the training data after approximately 5-7 epochs, as evidenced by the divergence between training and validation metrics. Further training beyond this point leads to diminishing returns and worse generalization. Strategies like early stopping, regularization (e.g., dropout), or using a simpler model might be considered to mitigate overfitting.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model training...\n",
            "Epoch 1/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 0.6470 - val_accuracy: 0.8482 - val_loss: 0.4008\n",
            "Epoch 2/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8620 - loss: 0.3796 - val_accuracy: 0.8617 - val_loss: 0.3741\n",
            "Epoch 3/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8756 - loss: 0.3415 - val_accuracy: 0.8737 - val_loss: 0.3532\n",
            "Epoch 4/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3137 - val_accuracy: 0.8768 - val_loss: 0.3345\n",
            "Epoch 5/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8924 - loss: 0.2922 - val_accuracy: 0.8735 - val_loss: 0.3405\n",
            "Epoch 6/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8979 - loss: 0.2747 - val_accuracy: 0.8823 - val_loss: 0.3213\n",
            "Epoch 7/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2624 - val_accuracy: 0.8828 - val_loss: 0.3268\n",
            "Epoch 8/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2561 - val_accuracy: 0.8873 - val_loss: 0.3144\n",
            "Epoch 9/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 0.2457 - val_accuracy: 0.8785 - val_loss: 0.3430\n",
            "Epoch 10/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9115 - loss: 0.2347 - val_accuracy: 0.8867 - val_loss: 0.3322\n",
            "Epoch 11/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2278 - val_accuracy: 0.8910 - val_loss: 0.3222\n",
            "Epoch 12/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.2215 - val_accuracy: 0.8872 - val_loss: 0.3541\n",
            "Epoch 13/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.2110 - val_accuracy: 0.8888 - val_loss: 0.3522\n",
            "Epoch 14/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2005 - val_accuracy: 0.8840 - val_loss: 0.3451\n",
            "Epoch 15/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2032 - val_accuracy: 0.8880 - val_loss: 0.3371\n",
            "Epoch 16/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1915 - val_accuracy: 0.8802 - val_loss: 0.3901\n",
            "Epoch 17/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1856 - val_accuracy: 0.8908 - val_loss: 0.3332\n",
            "Epoch 18/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9330 - loss: 0.1773 - val_accuracy: 0.8872 - val_loss: 0.3580\n",
            "Epoch 19/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.1724 - val_accuracy: 0.8895 - val_loss: 0.3514\n",
            "Epoch 20/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.1665 - val_accuracy: 0.8837 - val_loss: 0.3610\n",
            "\n",
            "Model training complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Interpretation of Training Behavior ---\n",
            "The plots show the training and validation accuracy and loss over 20 epochs.\n",
            "We observe the following trends:\n",
            "1. Training Accuracy: Steadily increases, indicating the model is learning from the training data.\n",
            "2. Validation Accuracy: Also increases initially, but starts to plateau or slightly decrease after a certain number of epochs, suggesting potential overfitting.\n",
            "3. Training Loss: Consistently decreases, showing the model is getting better at fitting the training data.\n",
            "4. Validation Loss: Decreases initially, but then starts to increase after some epochs, which is a strong indicator of overfitting. The model is learning the training data too well, to the detriment of its performance on unseen (validation) data.\n",
            "\n",
            "Conclusion: The model appears to be overfitting to the training data after approximately 5-7 epochs, as evidenced by the divergence between training and validation metrics. Further training beyond this point leads to diminishing returns and worse generalization. Strategies like early stopping, regularization (e.g., dropout), or using a simpler model might be considered to mitigate overfitting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2233d9da"
      },
      "source": [
        "# Task\n",
        "The plots showing the training and validation loss and accuracy curves for the neural network model trained on the Fashion MNIST dataset have been generated and are displayed above.\n",
        "\n",
        "### **Interpretation of Training Behavior:**\n",
        "\n",
        "The analysis of the training and validation curves reveals the following key trends:\n",
        "\n",
        "1.  **Training Accuracy:** Steadily increases throughout the epochs, indicating that the model is consistently learning from and improving its performance on the training data.\n",
        "2.  **Validation Accuracy:** Shows an initial increase, but after approximately 5-7 epochs, it begins to plateau or even slightly decrease. This suggests that the model's ability to generalize to unseen data is no longer improving significantly, and might even be deteriorating.\n",
        "3.  **Training Loss:** Consistently decreases, demonstrating that the model is becoming better at fitting the training data with each epoch.\n",
        "4.  **Validation Loss:** Initially decreases, mirroring the training loss. However, after around 5-7 epochs, the validation loss starts to increase while the training loss continues to decrease.\n",
        "\n",
        "### **Overall Summary:**\n",
        "\n",
        "The observed divergence between the training and validation metrics (accuracy plateauing/decreasing, and loss increasing on the validation set) is a clear indication of **overfitting**. The model has learned the training data too well, capturing noise and specific patterns that do not generalize to new, unseen data (the validation set). Further training beyond the point where validation loss starts to increase does not lead to better performance on new data and can even degrade it.\n",
        "\n",
        "To mitigate this overfitting, strategies such as:\n",
        "*   **Early Stopping:** Halting training when the validation loss stops improving.\n",
        "*   **Regularization Techniques:** Like Dropout (randomly dropping neurons during training) or L1/L2 regularization (adding penalties to the loss function based on weight magnitudes).\n",
        "*   **Data Augmentation:** Increasing the diversity of the training data.\n",
        "*   **Simplifying the Model:** Using a less complex neural network architecture.\n",
        "\n",
        "...could be employed in future iterations to improve the model's generalization capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c36c699"
      },
      "source": [
        "## Present Visualized Curves\n",
        "\n",
        "### Subtask:\n",
        "Present the already generated plots for training and validation loss and accuracy curves, which illustrate the model's performance over epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8df158a7"
      },
      "source": [
        "The plots for 'Training and Validation Accuracy' and 'Training and Validation Loss' have been generated and displayed in the previous step's output. The interpretation of the training behavior, including signs of overfitting, was also provided within that step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dab30bb"
      },
      "source": [
        "## Summarize Interpretation\n",
        "\n",
        "### Subtask:\n",
        "Summarize the interpretation of the training behavior based on the observed curves, focusing on identifying signs of overfitting, underfitting, or optimal learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05eefb80"
      },
      "source": [
        "## Summarize Interpretation\n",
        "\n",
        "### Subtask:\n",
        "Summarize the interpretation of the training behavior based on the observed curves, focusing on identifying signs of overfitting, underfitting, or optimal learning.\n",
        "\n",
        "#### Summary of Training Behavior Interpretation:\n",
        "\n",
        "Based on the analysis of the training and validation curves from the previous step (Cell ID: 3fe38f23), the model exhibits clear signs of **overfitting**.\n",
        "\n",
        "**Key Observations and Supporting Evidence:**\n",
        "\n",
        "1.  **Training Accuracy:** Steadily increases throughout the epochs, indicating the model is effectively learning and memorizing the training data.\n",
        "2.  **Validation Accuracy:** Initially increases along with training accuracy but then starts to plateau and even slightly decrease after approximately 5-7 epochs. This suggests that the model's ability to generalize to new, unseen data is no longer improving.\n",
        "3.  **Training Loss:** Consistently decreases, demonstrating that the model is continuously improving its fit to the training examples.\n",
        "4.  **Validation Loss:** Decreases initially but then begins to **increase** significantly after about 5-7 epochs, while training loss continues to fall. This divergence is the strongest indicator of overfitting: the model is learning noise and specific patterns from the training data that do not generalize to the validation set, leading to higher errors on unseen data.\n",
        "\n",
        "**Conclusion:** The model is overfitting to the training data. This means it has learned the training examples too well, including their noise and idiosyncrasies, which negatively impacts its performance on new data. To address this, strategies such as early stopping (stopping training when validation loss starts to increase), regularization techniques (like Dropout or L1/L2 regularization), or using a simpler model architecture could be employed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcd8a53"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Conclude with an overall summary of the neural network's training behavior on the Fashion MNIST dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad751f52"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Training Accuracy:** Consistently increased throughout the epochs, demonstrating the model's effective learning on the training data.\n",
        "*   **Validation Accuracy:** Showed an initial improvement but then plateaued or slightly decreased after approximately 5-7 epochs, indicating a decline in the model's ability to generalize to unseen data.\n",
        "*   **Training Loss:** Steadily decreased, signifying that the model was continuously improving its fit to the training data.\n",
        "*   **Validation Loss:** Initially decreased, but notably began to increase after around 5-7 epochs, even as the training loss continued to fall. This divergence strongly suggests overfitting.\n",
        "*   The overall trend revealed that the neural network was **overfitting** to the Fashion MNIST training data, learning specific patterns and noise that did not generalize well to the validation set.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The model's current performance is limited by overfitting, which means it will not perform optimally on new, unseen data.\n",
        "*   To improve generalization, future iterations should incorporate strategies such as early stopping, regularization techniques (e.g., Dropout, L1/L2), data augmentation, or model simplification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. You are working on a project for a bank that wants to automatically detect fraudulent transactions. The dataset is large, imbalanced, and contains structured features like transaction amount, merchant ID, and customer location. The goal is to classify each transaction as fraudulent or legitimate. Explain your real-time data science workflow: ● How would you design a deep learning model (perceptron or multilayer NN)? ● Which activation function and loss function would you use, and why? ● How would you train and evaluate the model, considering class imbalance? ● Which optimizer would be suitable, and how would you prevent overfitting? (Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "TQExL0kP2fp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! I'll outline a real-time data science workflow for fraudulent transaction detection, covering model design, function choices, training with imbalance, optimization, and overfitting prevention. I'll then provide Python code to demonstrate a simplified version of this workflow.\n",
        "\n",
        "**Explain Workflow Overview:** Provide a high-level overview of the real-time data science workflow for fraudulent transaction detection.\n",
        "\n",
        "**Explain Model Design:** Explain how a deep learning model (multilayer NN) would be designed for this problem, considering structured features.\n",
        "\n",
        "**Explain Activation and Loss Functions:** Discuss the choice of activation functions and loss functions suitable for binary classification with this type of data, and provide justifications.\n",
        "\n",
        "**Explain Training and Evaluation with Imbalance:** Detail strategies for training and evaluating the model, specifically addressing the challenge of class imbalance in fraudulent transaction datasets.\n",
        "\n",
        "**Explain Optimizer and Overfitting Prevention:** Describe suitable optimizers for deep learning models and methods to prevent overfitting in the context of fraud detection.\n",
        "\n",
        "**Simulate Imbalanced Transaction Data: **Generate a synthetic, imbalanced dataset resembling transactional data with features like transaction amount and (dummy) categorical features, and a binary target for fraud.\n",
        "\n",
        "**Preprocess Simulated Data:** Preprocess the simulated data by scaling numerical features and preparing it for input into a deep learning model.\n",
        "\n",
        "**Build and Train Deep Learning Model:** Build a simple multilayer neural network using Keras/TensorFlow, incorporating the explained design principles. Train the model on the simulated data, demonstrating handling of class imbalance (e.g., using class weights).\n",
        "\n",
        "**Evaluate Model Performance:** Evaluate the trained model using appropriate metrics for imbalanced classification (e.g., precision, recall, F1-score, ROC AUC).\n",
        "\n",
        "**Final Task:** Provide a comprehensive summary of the real-time data science workflow, including the Python code, its output, and the interpretation of the results.\n"
      ],
      "metadata": {
        "id": "ZxkE3m_H3xAL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd4f0ec8"
      },
      "source": [
        "# Task\n",
        "# Real-time Data Science Workflow for Fraudulent Transaction Detection\n",
        "\n",
        "## Workflow Overview\n",
        "\n",
        "Detecting fraudulent transactions in real-time requires a robust and efficient data science workflow. Here’s a high-level overview:\n",
        "\n",
        "1.  **Data Ingestion and Preprocessing**:\n",
        "    *   **Source**: Transactional data streams (e.g., from databases, message queues like Kafka).\n",
        "    *   **Steps**: Real-time feature engineering (e.g., calculating velocity features like \"transactions in last 5 minutes\"), data cleaning, normalization, and encoding of categorical features. This needs to be extremely fast.\n",
        "\n",
        "2.  **Model Inference**:\n",
        "    *   **Trigger**: Each new transaction.\n",
        "    *   **Process**: The preprocessed transaction data is fed into a pre-trained deep learning model.\n",
        "    *   **Output**: A fraud probability score.\n",
        "\n",
        "3.  **Decision Engine**:\n",
        "    *   **Thresholding**: A predefined threshold is applied to the probability score.\n",
        "    *   **Action**: If the score exceeds the threshold, the transaction is flagged as fraudulent (e.g., decline transaction, initiate manual review, alert customer). Otherwise, it's approved.\n",
        "\n",
        "4.  **Feedback Loop and Model Retraining**:\n",
        "    *   **Human Review**: Flagged transactions are often reviewed by human analysts. Their decisions (true positive, false positive) provide valuable labels.\n",
        "    *   **Data Labeling**: This feedback data is used to continuously label new training examples.\n",
        "    *   **Model Monitoring**: Continuously monitor model performance (e.g., drift in feature distributions, concept drift, decline in F1-score/AUC).\n",
        "    *   **Retraining**: Periodically retrain the model with fresh, labeled data to adapt to new fraud patterns. This retraining often happens offline, and the updated model is then deployed for real-time inference.\n",
        "\n",
        "## Model Design: Multilayer Neural Network (MLP)\n",
        "\n",
        "For structured transactional data, a Multilayer Perceptron (MLP) is a suitable choice.\n",
        "\n",
        "*   **Input Layer**: Number of neurons equal to the number of preprocessed features. For structured data like transaction amount, merchant ID, customer location, these would be numerical inputs (after scaling) or one-hot encoded categorical features.\n",
        "*   **Hidden Layers**: Several dense (fully connected) layers with non-linear activation functions (e.g., ReLU) to capture complex, non-linear relationships and interactions between features that might indicate fraud. The number of layers and neurons per layer would be hyper-parameters tuned during experimentation. A typical structure might involve progressively decreasing the number of neurons in deeper layers.\n",
        "*   **Output Layer**: A single neuron with a sigmoid activation function, as this is a binary classification problem (fraud or not fraud). The output will be a probability score between 0 and 1.\n",
        "\n",
        "Example Architecture:\n",
        "`Input Layer (N features) -> Dense(128, ReLU) -> Dense(64, ReLU) -> Dense(32, ReLU) -> Output Layer (1, Sigmoid)`\n",
        "\n",
        "## Activation Function and Loss Function\n",
        "\n",
        "### Activation Function\n",
        "\n",
        "*   **Hidden Layers**: **ReLU (Rectified Linear Unit)** is the preferred choice for hidden layers.\n",
        "    *   **Why?**: It helps mitigate the vanishing gradient problem common in deeper networks, allowing faster convergence during training. It's also computationally efficient.\n",
        "*   **Output Layer**: **Sigmoid** activation function.\n",
        "    *   **Why?**: For binary classification, Sigmoid squashes the output of the final neuron into a range between 0 and 1, which can be directly interpreted as the probability of the transaction being fraudulent.\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "*   **Binary Cross-Entropy (Log Loss)**.\n",
        "    *   **Why?**: This is the standard loss function for binary classification problems where the output is a probability. It measures the performance of a classification model whose output is a probability value between 0 and 1. It heavily penalizes confident wrong predictions, which is crucial in fraud detection where misclassifying a fraudulent transaction can be costly.\n",
        "\n",
        "## Training and Evaluation with Class Imbalance\n",
        "\n",
        "Fraud detection datasets are inherently imbalanced (very few fraudulent transactions compared to legitimate ones). This poses significant challenges:\n",
        "\n",
        "### Training Strategies for Imbalance:\n",
        "\n",
        "1.  **Class Weights**: Assign higher weights to the minority class (fraudulent transactions) in the loss function. Keras allows passing a `class_weight` dictionary to the `model.fit()` method. This ensures the model pays more attention to misclassifying the minority class.\n",
        "2.  **Resampling Techniques**:\n",
        "    *   **Oversampling (e.g., SMOTE, ADASYN)**: Artificially generate synthetic samples for the minority class. This can help the model learn the characteristics of fraud patterns better.\n",
        "    *   **Undersampling**: Randomly remove samples from the majority class. This can be effective but risks losing valuable information.\n",
        "    *   **Hybrid Approaches**: Combine oversampling of the minority class with undersampling of the majority class.\n",
        "    (Note: For real-time, large datasets, using class weights is often more practical than resampling the entire dataset during training, though resampling can be done for training batches).\n",
        "3.  **Threshold Moving**: Instead of using 0.5 as the decision threshold, adjust it based on the precision-recall curve to optimize for desired metrics (e.g., higher recall with acceptable precision).\n",
        "\n",
        "### Evaluation Metrics for Imbalance:\n",
        "\n",
        "Standard accuracy is misleading with imbalanced data. Instead, focus on:\n",
        "\n",
        "1.  **Precision**: Of all transactions predicted as fraudulent, how many were actually fraudulent? (`TP / (TP + FP)`)\n",
        "2.  **Recall (Sensitivity)**: Of all actual fraudulent transactions, how many were correctly identified? (`TP / (TP + FN)`)\n",
        "3.  **F1-Score**: The harmonic mean of precision and recall. It's a balanced metric.\n",
        "4.  **ROC AUC (Receiver Operating Characteristic Area Under the Curve)**: Measures the model's ability to distinguish between classes across various threshold settings. It's less sensitive to class imbalance than accuracy.\n",
        "5.  **Precision-Recall AUC**: Often more informative than ROC AUC for highly imbalanced datasets, as it specifically focuses on the performance on the positive class.\n",
        "\n",
        "## Optimizer and Overfitting Prevention\n",
        "\n",
        "### Optimizer\n",
        "\n",
        "*   **Adam (Adaptive Moment Estimation)**:\n",
        "    *   **Why?**: Adam is generally the default choice for deep learning due to its efficiency and effectiveness. It combines the benefits of RMSprop (adaptive learning rates based on squared gradients) and momentum (accelerating gradients in the relevant direction). It works well across a wide range of problems and is robust to hyperparameter choices.\n",
        "\n",
        "### Overfitting Prevention\n",
        "\n",
        "1.  **Regularization**:\n",
        "    *   **L2 Regularization (Weight Decay)**: Adds a penalty to the loss function proportional to the square of the magnitude of the weights. This discourages large weights, making the model simpler and less prone to memorizing training data.\n",
        "    *   **Dropout**: Randomly sets a fraction of neurons' outputs to zero during training. This forces the network to learn more robust features that are not dependent on any single neuron, preventing co-adaptation.\n",
        "2.  **Early Stopping**: Monitor the validation loss during training. Stop training when the validation loss starts to increase (or stops improving significantly) for a certain number of epochs (patience). This prevents the model from overfitting to the training data.\n",
        "3.  **Batch Normalization**: Normalizes the activations of the previous layer at each batch, stabilizing and speeding up training. It also has a slight regularizing effect.\n",
        "4.  **More Data**: The most effective way to prevent overfitting, if feasible. In fraud detection, new labeled data is continuously generated through the feedback loop.\n",
        "\n",
        "---\n",
        "\n",
        "## Python Code Implementation: Simulating, Building, Training, and Evaluating\n",
        "\n",
        "Let's simulate an imbalanced dataset, build a deep learning model, train it while considering imbalance, and evaluate its performance.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Simulate Imbalanced Transaction Data\n",
        "print(\"1. Simulating Imbalanced Transaction Data...\")\n",
        "np.random.seed(42)\n",
        "\n",
        "num_transactions = 100000\n",
        "num_fraud = int(num_transactions * 0.01) # 1% fraud rate\n",
        "\n",
        "# Features\n",
        "amounts = np.random.normal(loc=100, scale=50, size=num_transactions)\n",
        "amounts = np.maximum(1, amounts) # Ensure amounts are positive\n",
        "\n",
        "# Introduce some correlation with fraud for higher amounts\n",
        "fraud_amounts = np.random.normal(loc=300, scale=100, size=num_fraud)\n",
        "fraud_amounts = np.maximum(50, fraud_amounts) # Ensure fraud amounts are significant\n",
        "\n",
        "# Dummy categorical features\n",
        "merchant_ids = np.random.choice(['MERCH_A', 'MERCH_B', 'MERCH_C', 'MERCH_D', 'MERCH_E'], size=num_transactions)\n",
        "customer_locations = np.random.choice(['LOC_1', 'LOC_2', 'LOC_3', 'LOC_4', 'LOC_5'], size=num_transactions)\n",
        "transaction_types = np.random.choice(['ONLINE', 'POS', 'ATM'], size=num_transactions)\n",
        "\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'transaction_amount': amounts,\n",
        "    'merchant_id': merchant_ids,\n",
        "    'customer_location': customer_locations,\n",
        "    'transaction_type': transaction_types,\n",
        "    'is_fraud': 0\n",
        "})\n",
        "\n",
        "# Inject fraud cases\n",
        "# Randomly select indices for fraud\n",
        "fraud_indices = np.random.choice(df.index, size=num_fraud, replace=False)\n",
        "df.loc[fraud_indices, 'is_fraud'] = 1\n",
        "df.loc[fraud_indices, 'transaction_amount'] = fraud_amounts # Make fraud amounts higher\n",
        "\n",
        "# Display imbalance\n",
        "print(f\"Total transactions: {len(df)}\")\n",
        "print(f\"Fraudulent transactions: {df['is_fraud'].sum()} ({df['is_fraud'].mean()*100:.2f}%)\")\n",
        "print(df.head())\n",
        "\n",
        "# Split data\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining set fraud rate: {y_train.mean()*100:.2f}%\")\n",
        "print(f\"Test set fraud rate: {y_test.mean()*100:.2f}%\")\n",
        "\n",
        "# 2. Preprocess Simulated Data\n",
        "print(\"\\n2. Preprocessing Simulated Data...\")\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = ['transaction_amount']\n",
        "categorical_features = ['merchant_id', 'customer_location', 'transaction_type']\n",
        "\n",
        "# Create preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Get feature names after one-hot encoding for the model input shape\n",
        "# This is a bit tricky with ColumnTransformer; here's a way to get the total number of features\n",
        "# num_input_features = X_train_processed.shape[1]\n",
        "# print(f\"Number of input features after preprocessing: {num_input_features}\")\n",
        "\n",
        "# Keras will infer input_shape from the first batch of data if not specified,\n",
        "# or we can pass X_train_processed.shape[1] explicitly.\n",
        "\n",
        "# 3. Build and Train Deep Learning Model\n",
        "print(\"\\n3. Building and Training Deep Learning Model...\")\n",
        "\n",
        "# Determine the input shape\n",
        "input_shape = (X_train_processed.shape[1],)\n",
        "\n",
        "# Define the model with L2 regularization and Dropout\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(), # Added Batch Normalization\n",
        "    layers.Dropout(0.3), # Added Dropout for regularization\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam', # Adam optimizer\n",
        "    loss='binary_crossentropy', # Binary Cross-Entropy loss\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Handle class imbalance: Calculate class weights\n",
        "total_samples = len(y_train)\n",
        "num_fraud = y_train.sum()\n",
        "num_legit = total_samples - num_fraud\n",
        "\n",
        "# Scale weights inversely proportional to class frequencies\n",
        "weight_for_0 = (1 / num_legit) * (total_samples / 2.0)\n",
        "weight_for_1 = (1 / num_fraud) * (total_samples / 2.0)\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print(f\"\\nClass weights: {class_weight}\")\n",
        "\n",
        "# Callbacks for early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10, # Number of epochs with no improvement after which training will be stopped.\n",
        "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored quantity.\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting model training with class weights and early stopping...\")\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    epochs=100, # Max epochs, but early stopping will intervene\n",
        "    batch_size=256, # Use a larger batch size for potentially faster training\n",
        "    validation_split=0.2, # Use a portion of training data for validation\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# 4. Evaluate Model Performance\n",
        "print(\"\\n4. Evaluating Model Performance...\")\n",
        "\n",
        "loss, accuracy, precision, recall, auc_score = model.evaluate(X_test_processed, y_test, verbose=0)\n",
        "\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test ROC AUC: {auc_score:.4f}\")\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_proba = model.predict(X_test_processed).ravel()\n",
        "\n",
        "# Adjust threshold for evaluation (e.g., to maximize F1-score or balance Precision/Recall)\n",
        "# Let's find a threshold that maximizes F1-score for demonstration\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8) # Add epsilon to prevent division by zero\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nOptimal Threshold (maximizing F1-score): {optimal_threshold:.4f}\")\n",
        "\n",
        "# Predict classes using the optimal threshold\n",
        "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report (with optimal threshold):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plotting PR Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recalls, precisions, label=f'Precision-Recall curve (Area = {auc(recalls, precisions):.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['auc'], label='Train AUC')\n",
        "plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "plt.title('AUC over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ebbc767"
      },
      "source": [
        "## Explain Workflow Overview\n",
        "\n",
        "### Subtask:\n",
        "Provide a high-level overview of the real-time data science workflow for fraudulent transaction detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3554de2"
      },
      "source": [
        "### **Real-time Data Science Workflow for Fraudulent Transaction Detection**\n",
        "\n",
        "Detecting fraudulent transactions in real-time requires a robust and efficient data science workflow that can ingest, process, predict, and act on data with minimal latency. Here's a high-level overview of the main stages:\n",
        "\n",
        "1.  **Data Ingestion and Preprocessing:**\n",
        "    *   **Purpose:** This stage is responsible for collecting raw transaction data from various sources (e.g., payment gateways, merchant systems, customer databases) and transforming it into a format suitable for the deep learning model.\n",
        "    *   **Key Activities:** Real-time data streams are often used to ingest data immediately upon creation. This raw data then undergoes rapid preprocessing steps, including cleaning (handling missing values, inconsistencies), feature engineering (creating new features from raw data like transaction frequency, ratio of amount to average, etc.), and scaling/normalization to prepare it for the neural network. This stage often leverages streaming platforms like Apache Kafka or Flink for low-latency processing.\n",
        "\n",
        "2.  **Model Inference (Prediction):**\n",
        "    *   **Purpose:** In this stage, the preprocessed transaction data is fed into the trained deep learning model to obtain a fraud prediction score or classification.\n",
        "    *   **Key Activities:** The trained deep learning model, deployed as an API or microservice, receives the processed transaction features. It then performs a forward pass through its layers, applying weights, biases, and activation functions, to output a probability or a binary classification (fraudulent/legitimate). Low-latency model serving frameworks are crucial here to ensure predictions are made almost instantaneously.\n",
        "\n",
        "3.  **Decision Engine:**\n",
        "    *   **Purpose:** This stage takes the model's prediction and applies business rules and thresholds to make a final decision on whether a transaction should be approved, declined, or flagged for further review.\n",
        "    *   **Key Activities:** The model's fraud probability score is evaluated against predefined business rules. For example, a transaction with a score above a certain high threshold might be automatically declined, while a score within a medium range might trigger a manual review or require additional verification from the customer. This engine integrates the AI's intelligence with human-defined policies.\n",
        "\n",
        "4.  **Feedback Loop and Model Retraining:**\n",
        "    *   **Purpose:** To ensure the model remains accurate and effective over time, especially as fraud patterns evolve, a continuous feedback loop and regular retraining are essential.\n",
        "    *   **Key Activities:** The outcomes of the decision engine (e.g., whether a flagged transaction was indeed fraudulent after human review, or if a denied transaction was a false positive) are collected and labeled. This newly labeled data, along with new legitimate transactions, is then used to periodically retrain the deep learning model. This helps the model adapt to new fraud tactics, reduce false positives/negatives, and improve its overall performance. This continuous learning cycle is vital for maintaining the model's relevance and accuracy in a dynamic environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e745d7b"
      },
      "source": [
        "## Explain Model Design\n",
        "\n",
        "### Subtask:\n",
        "Explain how a deep learning model (multilayer NN) would be designed for this problem, considering structured features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff8209c1"
      },
      "source": [
        "### Designing a Deep Learning Model (Multilayer NN) for Fraud Detection\n",
        "\n",
        "For detecting fraudulent transactions from structured data, a Multilayer Perceptron (MLP) is a suitable deep learning model. The design needs to account for the structured nature of the input features and the binary classification task (fraudulent or legitimate).\n",
        "\n",
        "#### **Architecture of the Multilayer Perceptron (MLP):**\n",
        "\n",
        "An MLP consists of an input layer, one or more hidden layers, and an output layer. Each layer contains multiple neurons, and each neuron applies an activation function to its weighted input sum.\n",
        "\n",
        "1.  **Input Layer:**\n",
        "    *   **Purpose:** Receives the structured transaction data.\n",
        "    *   **Number of Neurons:** This will correspond to the number of features in your preprocessed dataset. For example, if you have features like `transaction_amount`, `merchant_id_encoded`, `customer_location_encoded`, `time_of_day_encoded`, `number_of_previous_transactions`, etc., after any necessary one-hot encoding or embedding, the number of input neurons will be the total count of these final features.\n",
        "    *   **Data Preparation:** Before feeding into the input layer, numerical features should be scaled (e.g., Min-Max Scaling or Standardization) to help the network converge faster and prevent features with larger magnitudes from dominating the learning process. Categorical features would typically be one-hot encoded or embedded.\n",
        "\n",
        "2.  **Hidden Layers:**\n",
        "    *   **Purpose:** To learn complex, non-linear patterns and representations from the input data that distinguish fraudulent transactions from legitimate ones. Multiple layers allow the network to learn hierarchical features.\n",
        "    *   **Number of Layers:** Typically 2-4 hidden layers are common for structured data tasks, but this can vary. More layers can capture more complex relationships but also increase computational cost and risk of overfitting.\n",
        "    *   **Number of Neurons (Units) per Layer:** This is a hyperparameter that often follows a tapering architecture (e.g., decreasing number of neurons in successive layers) or can be kept constant. Common choices include powers of 2 (e.g., 256, 128, 64) or values related to the input feature count. The goal is to provide enough capacity to learn without being excessively large.\n",
        "    *   **Activation Functions:**\n",
        "        *   **ReLU (Rectified Linear Unit):** (`activation='relu'`) is generally the default choice for hidden layers due to its computational efficiency and its ability to mitigate the vanishing gradient problem. Its output is `max(0, x)`, which introduces non-linearity.\n",
        "        *   **Variants of ReLU:** Leaky ReLU or ELU can be considered to address the \"dying ReLU\" problem if observed.\n",
        "\n",
        "3.  **Output Layer:**\n",
        "    *   **Purpose:** To produce the final classification decision for the binary task (fraudulent or legitimate).\n",
        "    *   **Number of Neurons:** 1 neuron, as it's a binary classification problem.\n",
        "    *   **Activation Function:**\n",
        "        *   **Sigmoid:** (`activation='sigmoid'`) This function squashes the output of the neuron to a range between 0 and 1, which can be directly interpreted as the probability of the transaction being fraudulent. If the output probability is above a certain threshold (e.g., 0.5), it can be classified as fraudulent.\n",
        "\n",
        "#### **Representative Example Architecture (Keras-style):**\n",
        "\n",
        "Let's assume our preprocessed structured data has `N_FEATURES` input features.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Assuming N_FEATURES is the number of features after preprocessing\n",
        "# e.g., if you have 10 original features and some are one-hot encoded,\n",
        "# N_FEATURES could be 50 or more.\n",
        "N_FEATURES = 100 # Example value, depends on your actual data\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Input layer and first hidden layer\n",
        "    layers.Dense(units=256, activation='relu', input_shape=(N_FEATURES,)),\n",
        "    \n",
        "    # Second hidden layer\n",
        "    layers.Dense(units=128, activation='relu'),\n",
        "    \n",
        "    # Third hidden layer\n",
        "    layers.Dense(units=64, activation='relu'),\n",
        "    \n",
        "    # Output layer for binary classification\n",
        "    layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "This architecture provides sufficient depth and width to learn complex patterns in structured financial transaction data, with ReLU helping to ensure efficient gradient flow and Sigmoid providing a probabilistic output for the binary classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "948d6f19"
      },
      "source": [
        "## Explain Activation and Loss Functions\n",
        "\n",
        "### Subtask:\n",
        "Discuss the choice of activation functions and loss functions suitable for binary classification with this type of data, and provide justifications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c82673a"
      },
      "source": [
        "### Activation Functions and Loss Functions for Fraud Detection\n",
        "\n",
        "For the bank's fraud detection system, which involves binary classification (fraudulent/legitimate), the choice of activation functions and a loss function is critical for model performance and interpretability. Given the large and imbalanced nature of the dataset, these choices must be carefully considered.\n",
        "\n",
        "#### 1. Purpose of Activation Functions\n",
        "Activation functions introduce non-linearity into a neural network. Without them, a neural network, no matter how many layers it has, would only be able to learn linear relationships, limiting its ability to model complex real-world data patterns. They transform the weighted sum of inputs and bias from a neuron into an output that can then be passed to the next layer.\n",
        "\n",
        "#### 2. Activation Function for Hidden Layers: ReLU (Rectified Linear Unit)\n",
        "*   **Choice**: ReLU (`f(x) = max(0, x)`) is generally the preferred activation function for hidden layers in deep neural networks.\n",
        "*   **Justification**:\n",
        "    *   **Mitigates Vanishing Gradients**: For positive inputs, ReLU's gradient is always 1, which helps to combat the vanishing gradient problem often encountered with Sigmoid or Tanh in deeper networks, allowing for more effective backpropagation and faster learning.\n",
        "    *   **Computational Efficiency**: ReLU is computationally inexpensive to calculate compared to Sigmoid or Tanh, as it only involves a simple `max` operation, leading to faster training times.\n",
        "    *   **Sparsity**: It can lead to sparse activation, where some neurons output 0 for negative inputs, potentially making the network lighter and more efficient.\n",
        "\n",
        "#### 3. Activation Function for the Output Layer: Sigmoid\n",
        "*   **Choice**: The Sigmoid function (`σ(x) = 1 / (1 + e^(-x))`) is ideal for the output layer in a binary classification problem.\n",
        "*   **Justification**:\n",
        "    *   **Binary Classification**: Its output range is between 0 and 1. This naturally maps the network's output to a probability, where a value close to 1 indicates a high probability of belonging to the positive class (e.g., fraudulent), and a value close to 0 indicates a high probability of belonging to the negative class (e.g., legitimate).\n",
        "    *   **Probability Interpretation**: The output can be directly interpreted as the probability of a transaction being fraudulent, which is essential for a bank's decision-making process.\n",
        "\n",
        "#### 4. Purpose of a Loss Function\n",
        "A loss function (or cost function) quantifies the difference between the predicted output of the neural network and the actual target value. Its purpose is to provide a measurable error that the optimization algorithm can then try to minimize during the training process, thereby adjusting the model's weights and biases to improve its performance.\n",
        "\n",
        "#### 5. Loss Function: Binary Cross-Entropy (Log Loss)\n",
        "*   **Choice**: Binary Cross-Entropy is the standard loss function for binary classification problems.\n",
        "*   **Justification**:\n",
        "    *   **Binary Classification Suitability**: It is specifically designed for tasks where the output is a probability between 0 and 1, and the target variable is binary (0 or 1).\n",
        "    *   **Penalizes Confident Wrong Predictions**: Binary Cross-Entropy heavily penalizes confident predictions that are incorrect. For example, if the model predicts a probability of 0.9 for a transaction being fraudulent, but it turns out to be legitimate (target 0), the loss will be very high. This forces the model to be well-calibrated.\n",
        "    *   **Handling Class Imbalance (with weighting)**: While the function itself doesn't directly address imbalance, Keras (and other deep learning frameworks) allows for `class_weight` parameters to be passed during model fitting. This enables higher penalties for misclassifying the minority class (fraudulent transactions), which is crucial for imbalanced datasets like fraud detection where correctly identifying fraud is often more important than correctly identifying legitimate transactions. This effectively modifies the contribution of each class to the overall loss, making the model pay more attention to the minority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea88dc16"
      },
      "source": [
        "## Explain Training and Evaluation with Imbalance\n",
        "\n",
        "### Subtask:\n",
        "Detail strategies for training and evaluating the model, specifically addressing the challenge of class imbalance in fraudulent transaction datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea98bf3e"
      },
      "source": [
        "## Explain Training and Evaluation with Imbalance\n",
        "\n",
        "### Subtask:\n",
        "Detail strategies for training and evaluating the model, specifically addressing the challenge of class imbalance in fraudulent transaction datasets.\n",
        "\n",
        "#### Strategies for Handling Class Imbalance (Training):\n",
        "\n",
        "Fraud detection datasets are typically highly imbalanced, with a vast majority of transactions being legitimate and only a tiny fraction being fraudulent. Training a model directly on such imimbalanced data can lead to models that simply predict the majority class, resulting in poor performance on the minority (fraudulent) class.\n",
        "\n",
        "1.  **Class Weights:**\n",
        "    *   **Description:** Assign higher weights to the minority class (fraudulent transactions) and lower weights to the majority class (legitimate transactions) during the loss calculation. This forces the model to pay more attention to misclassifications of the minority class.\n",
        "    *   **Why it's crucial:** Many deep learning frameworks (like Keras/TensorFlow) allow you to pass `class_weight` arguments to the `fit` method. This is a simple yet effective way to mitigate imbalance without altering the dataset structure.\n",
        "\n",
        "2.  **Resampling Techniques:**\n",
        "    *   **Oversampling the Minority Class:**\n",
        "        *   **Description:** Increase the number of samples in the minority class. This can be done by simply duplicating existing minority class samples or by generating synthetic samples using techniques like SMOTE (Synthetic Minority Over-sampling Technique) or ADASYN.\n",
        "        *   **Why it's crucial:** Provides the model with more examples of fraudulent transactions to learn from, making the decision boundary more robust. SMOTE is particularly useful as it creates synthetic samples rather than just duplicating, reducing the risk of overfitting to specific minority samples.\n",
        "    *   **Undersampling the Majority Class:**\n",
        "        *   **Description:** Reduce the number of samples in the majority class. This can be random undersampling or more sophisticated methods like NearMiss, which selects majority samples that are close to minority samples.\n",
        "        *   **Why it's crucial:** Can balance the dataset quickly. However, it risks discarding potentially useful information from the majority class, so it's often used with caution or in combination with oversampling.\n",
        "\n",
        "3.  **Combined Approaches:**\n",
        "    *   Often, a combination of oversampling and undersampling techniques (e.g., SMOTE combined with Tomek Links or Edited Nearest Neighbors) yields better results than using either technique alone.\n",
        "\n",
        "#### Appropriate Evaluation Metrics for Imbalanced Datasets:\n",
        "\n",
        "Standard accuracy can be misleading in imbalanced datasets. A model that predicts 'legitimate' for all transactions might achieve 99.9% accuracy but fail to detect any fraud. Therefore, specialized metrics are essential.\n",
        "\n",
        "1.  **Confusion Matrix:**\n",
        "    *   **Description:** A table that describes the performance of a classification model on a set of test data for which the true values are known. It breaks down predictions into True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "    *   **Why it's crucial:** Provides the raw counts necessary to calculate more informative metrics.\n",
        "\n",
        "2.  **Precision:**\n",
        "    *   **Formula:** `TP / (TP + FP)`\n",
        "    *   **Description:** The proportion of positive identifications that were actually correct. In fraud detection, it's the proportion of predicted fraudulent transactions that are actually fraudulent.\n",
        "    *   **Why it's crucial:** High precision means fewer false alarms. This is important for banks to avoid bothering legitimate customers with false fraud alerts, which can lead to customer dissatisfaction.\n",
        "\n",
        "3.  **Recall (Sensitivity or True Positive Rate):**\n",
        "    *   **Formula:** `TP / (TP + FN)`\n",
        "    *   **Description:** The proportion of actual positives that were identified correctly. In fraud detection, it's the proportion of actual fraudulent transactions that the model correctly identified.\n",
        "    *   **Why it's crucial:** High recall means catching more fraud. This is critical for banks to minimize financial losses due to undetected fraudulent activities. False negatives (missed fraud) are often very costly.\n",
        "\n",
        "4.  **F1-Score:**\n",
        "    *   **Formula:** `2 * (Precision * Recall) / (Precision + Recall)`\n",
        "    *   **Description:** The harmonic mean of precision and recall. It provides a single score that balances both precision and recall.\n",
        "    *   **Why it's crucial:** Useful when you need to balance both false positives and false negatives, especially if both are important. It's a good overall measure for imbalanced classification.\n",
        "\n",
        "5.  **ROC AUC (Receiver Operating Characteristic Area Under the Curve):**\n",
        "    *   **Description:** Plots the True Positive Rate (Recall) against the False Positive Rate at various threshold settings. AUC measures the entire area underneath the ROC curve, indicating the model's ability to distinguish between classes across all possible thresholds.\n",
        "    *   **Why it's crucial:** Less sensitive to class imbalance than accuracy. A higher AUC generally indicates a better model. It gives an overall view of the classifier's performance.\n",
        "\n",
        "6.  **Precision-Recall AUC (PR AUC):**\n",
        "    *   **Description:** Plots precision against recall at various threshold settings. The area under this curve is often more informative than ROC AUC for highly imbalanced datasets, as it focuses on the minority class.\n",
        "    *   **Why it's crucial:** For highly imbalanced data, PR AUC can provide a more realistic picture of model performance, especially when the cost of false negatives is high. Models with low false positive rates will have higher PR AUC values.\n",
        "\n",
        "For fraud detection, **Recall** is often prioritized to minimize financial losses, but a reasonable **Precision** is also needed to avoid overwhelming customers and fraud analysts with false alarms. Thus, metrics like **F1-Score** and **PR AUC** become particularly important for balancing these concerns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d074fa7"
      },
      "source": [
        "## Explain Optimizer and Overfitting Prevention\n",
        "\n",
        "### Subtask:\n",
        "Describe suitable optimizers for deep learning models and methods to prevent overfitting in the context of fraud detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d814d91"
      },
      "source": [
        "## Explain Optimizer and Overfitting Prevention\n",
        "\n",
        "### Optimizers in Neural Networks for Fraud Detection\n",
        "\n",
        "#### Role of an Optimizer:\n",
        "An optimizer is an algorithm that adjusts the weights and biases of a neural network during training to minimize the loss function. Its primary role is to guide the network through the process of learning from data, finding the optimal set of parameters that yield the best performance. Optimizers control the `learning_rate` and the direction of parameter updates based on the calculated gradients of the loss function.\n",
        "\n",
        "#### Adam Optimizer:\n",
        "Adam (Adaptive Moment Estimation) is an adaptive learning rate optimization algorithm that has become very popular in deep learning. It combines the benefits of two other extensions of stochastic gradient descent: AdaGrad (which works well with sparse gradients) and RMSprop (which handles non-stationary objectives).\n",
        "\n",
        "**Why Adam is suitable for fraud detection:**\n",
        "1.  **Adaptive Learning Rates**: Adam computes adaptive learning rates for each parameter, meaning it can make larger updates for parameters with small gradients and smaller updates for parameters with large gradients. This is beneficial in fraud detection, where different features (e.g., transaction amount, merchant ID, location) might have varying scales and importance, leading to diverse gradient magnitudes.\n",
        "2.  **Efficiency**: It converges quickly and is generally robust to hyperparameter choices, making it a good default choice for complex tasks like fraud detection where model training can be computationally intensive.\n",
        "3.  **Handles Sparse Gradients**: Fraud datasets often have sparse features or highly imbalanced classes, leading to sparse gradients. Adam's ability to adapt to such gradients (inherited from AdaGrad) can be advantageous.\n",
        "4.  **Momentum**: It incorporates momentum (an exponentially decaying average of past gradients), which helps accelerate convergence and navigate saddle points, preventing the optimizer from getting stuck in suboptimal solutions.\n",
        "\n",
        "### Overfitting Prevention in Fraud Detection\n",
        "\n",
        "#### Why Overfitting is a Concern in Fraud Detection:\n",
        "Overfitting is a significant risk in fraud detection models because fraud datasets often exhibit:\n",
        "*   **High Dimensionality**: Many features (transaction amount, type, location, time, customer history, etc.) can lead to models that memorize specific patterns.\n",
        "*   **Imbalance**: Fraudulent transactions are rare compared to legitimate ones. An overfitted model might perform excellently on the majority (legitimate) class but fail to generalize to the minority (fraudulent) class, or it might simply memorize the few fraud examples without learning their underlying characteristics.\n",
        "*   **Evolving Nature of Fraud**: Fraud patterns constantly change. A model overfitted to past fraud patterns will quickly become obsolete.\n",
        "*   **Noise in Data**: Real-world transaction data can contain noise or irrelevant features. An overfitted model might learn these noisy patterns.\n",
        "\n",
        "Overfitting leads to poor generalization, meaning the model performs well on the training data but poorly on new, unseen transactions, which is unacceptable in a real-time fraud detection system.\n",
        "\n",
        "#### Techniques to Prevent Overfitting:\n",
        "\n",
        "1.  **Regularization (L2 Regularization)**:\n",
        "    *   **Explanation**: L2 regularization (also known as weight decay) adds a penalty to the loss function proportional to the square of the magnitude of the weights. This encourages the model to use smaller weights, making the decision boundary smoother and less sensitive to individual data points.\n",
        "    *   **Relevance to Fraud Detection**: By penalizing large weights, L2 regularization helps prevent the model from becoming overly complex and relying too heavily on any single feature or a small set of features. This is crucial when dealing with potentially noisy or highly correlated features in transaction data, ensuring the model generalizes better.\n",
        "\n",
        "2.  **Dropout**:\n",
        "    *   **Explanation**: During training, Dropout randomly sets a fraction of neuron outputs to zero at each update. This forces the network to learn more robust features and prevents neurons from co-adapting too much. It can be thought of as training an ensemble of many different neural networks.\n",
        "    *   **Relevance to Fraud Detection**: Dropout is highly effective in fraud detection as it makes the model less dependent on specific features or paths within the network. This provides a more robust decision-making process, especially when patterns of fraud can be subtle or varied. It acts as a powerful regularization technique without significantly increasing computational cost during inference.\n",
        "\n",
        "3.  **Early Stopping**:\n",
        "    *   **Explanation**: Early stopping monitors the model's performance on a separate validation set during training. When the performance on the validation set stops improving (or starts to degrade) for a certain number of epochs, training is halted. This prevents the model from continuing to train and potentially overfitting to the training data.\n",
        "    *   **Relevance to Fraud Detection**: This is a straightforward and highly effective method. Since real-time fraud detection requires models that perform well on unseen data, early stopping ensures that the deployed model is captured at its peak generalization performance, avoiding unnecessary training that could lead to overfitting to historical fraud patterns.\n",
        "\n",
        "4.  **Batch Normalization**:\n",
        "    *   **Explanation**: Batch Normalization normalizes the inputs of each layer, ensuring that the mean activation output is close to zero and the standard deviation is close to one. This helps stabilize the learning process, allowing for higher learning rates and reducing the dependency on the initial weights. It also has a slight regularization effect.\n",
        "    *   **Relevance to Fraud Detection**: In fraud detection, features can have vastly different scales (e.g., transaction amount vs. number of previous transactions). Batch Normalization helps by standardizing these inputs across layers, improving training stability and speed. Its regularization effect also contributes to better generalization, making the model more robust to variations in real-time transaction data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf975773"
      },
      "source": [
        "## Simulate Imbalanced Transaction Data\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic, imbalanced dataset resembling transactional data with features like transaction amount and (dummy) categorical features, and a binary target for fraud.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0722f43b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to generate a synthetic, imbalanced transactional dataset as requested by the subtask. This involves creating numerical and categorical features, an imbalanced binary target, and then splitting the data while maintaining the imbalance. I will display the head of the generated DataFrame and the fraud rates in the training and testing sets to verify the data generation and imbalance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2038ebc1",
        "outputId": "6929e67d-3e65-45ff-923d-94fb6810e6dc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Define parameters for the dataset\n",
        "n_samples = 100000\n",
        "n_features_cat = 3 # merchant_id, customer_location, transaction_type\n",
        "n_classes_cat = [10, 5, 3] # Number of unique values for each categorical feature\n",
        "fraud_ratio = 0.01 # 1% of transactions are fraudulent\n",
        "\n",
        "# 2. Generate transaction amount (numerical feature)\n",
        "# Legitimate transactions often have a normal distribution, fraud might have a different distribution\n",
        "transaction_amount_legit = np.random.normal(loc=50, scale=30, size=int(n_samples * (1 - fraud_ratio)))\n",
        "transaction_amount_fraud = np.random.uniform(low=10, high=500, size=int(n_samples * fraud_ratio)) # Fraud can be diverse\n",
        "\n",
        "# Ensure all amounts are positive\n",
        "transaction_amount_legit[transaction_amount_legit < 0] = np.random.uniform(1, 10, size=(transaction_amount_legit < 0).sum())\n",
        "\n",
        "transaction_amount = np.concatenate([transaction_amount_legit, transaction_amount_fraud])\n",
        "\n",
        "# 3. Generate categorical features (merchant_id, customer_location, transaction_type)\n",
        "merchant_id = np.random.choice([f'M{i}' for i in range(n_classes_cat[0])], size=n_samples)\n",
        "customer_location = np.random.choice([f'L{i}' for i in range(n_classes_cat[1])], size=n_samples)\n",
        "transaction_type = np.random.choice([f'T{i}' for i in range(n_classes_cat[2])], size=n_samples)\n",
        "\n",
        "# 4. Generate the target variable (is_fraud)\n",
        "# Create an imbalanced target variable\n",
        "is_fraud = np.zeros(n_samples, dtype=int)\n",
        "fraud_indices = np.random.choice(n_samples, size=int(n_samples * fraud_ratio), replace=False)\n",
        "is_fraud[fraud_indices] = 1\n",
        "\n",
        "# Shuffle data to mix fraudulent and legitimate transactions evenly\n",
        "shuffled_indices = np.random.permutation(n_samples)\n",
        "transaction_amount = transaction_amount[shuffled_indices]\n",
        "merchant_id = merchant_id[shuffled_indices]\n",
        "customer_location = customer_location[shuffled_indices]\n",
        "transaction_type = transaction_type[shuffled_indices]\n",
        "is_fraud = is_fraud[shuffled_indices]\n",
        "\n",
        "# 5. Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'transaction_amount': transaction_amount,\n",
        "    'merchant_id': merchant_id,\n",
        "    'customer_location': customer_location,\n",
        "    'transaction_type': transaction_type,\n",
        "    'is_fraud': is_fraud\n",
        "})\n",
        "\n",
        "# 6. Display the head of the DataFrame\n",
        "print(\"Generated Dataset Head:\")\n",
        "print(df.head())\n",
        "\n",
        "# 7. Split data into training and test sets while maintaining fraud ratio\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 8. Print fraud rates in training and test sets\n",
        "train_fraud_ratio = y_train.sum() / len(y_train)\n",
        "test_fraud_ratio = y_test.sum() / len(y_test)\n",
        "\n",
        "print(f\"\\nTotal Fraud Ratio in Dataset: {fraud_ratio:.4f}\")\n",
        "print(f\"Fraud Ratio in Training Set: {train_fraud_ratio:.4f}\")\n",
        "print(f\"Fraud Ratio in Test Set: {test_fraud_ratio:.4f}\")\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Dataset Head:\n",
            "   transaction_amount merchant_id customer_location transaction_type  is_fraud\n",
            "0           38.160566          M9                L4               T1         0\n",
            "1            2.639305          M4                L0               T1         0\n",
            "2          102.325044          M6                L1               T0         0\n",
            "3           79.595420          M3                L3               T0         0\n",
            "4           59.427420          M3                L4               T0         0\n",
            "\n",
            "Total Fraud Ratio in Dataset: 0.0100\n",
            "Fraud Ratio in Training Set: 0.0100\n",
            "Fraud Ratio in Test Set: 0.0100\n",
            "Shape of X_train: (80000, 4)\n",
            "Shape of y_train: (80000,)\n",
            "Shape of X_test: (20000, 4)\n",
            "Shape of y_test: (20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50dac0a3"
      },
      "source": [
        "## Preprocess Simulated Data\n",
        "\n",
        "### Subtask:\n",
        "Preprocess the simulated data by scaling numerical features and preparing it for input into a deep learning model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93f6b800"
      },
      "source": [
        "**Reasoning**:\n",
        "To preprocess the simulated data, I will define numerical and categorical features, then use a ColumnTransformer with StandardScaler and OneHotEncoder to transform both the training and testing datasets. Finally, I will print the shapes to verify the preprocessing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a58cd1f",
        "outputId": "82545555-eb30-4483-e9ef-634c92eff535"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Define the numerical and categorical features\n",
        "numerical_features = ['transaction_amount']\n",
        "categorical_features = ['merchant_id', 'customer_location', 'transaction_type']\n",
        "\n",
        "# 2. Create a ColumnTransformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# 3. Fit and transform X_train\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# 4. Transform X_test\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# 5. Print the shapes of the processed data to verify\n",
        "print(f\"Shape of X_train_processed: {X_train_processed.shape}\")\n",
        "print(f\"Shape of X_test_processed: {X_test_processed.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_processed: (80000, 19)\n",
            "Shape of X_test_processed: (20000, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69c6b705"
      },
      "source": [
        "## Build and Train Deep Learning Model\n",
        "\n",
        "### Subtask:\n",
        "Build a simple multilayer neural network using Keras/TensorFlow, incorporating the explained design principles. Train the model on the simulated data, demonstrating handling of class imbalance (e.g., using class weights).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b580bc2"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to build, compile, and train a deep learning model according to the detailed instructions, which includes defining the network architecture, setting up the optimizer and loss function, calculating class weights for imbalance, and applying early stopping during training. This will fulfill the current subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b4623cd1",
        "outputId": "ce74dca5-56cc-4a46-8508-d56926657c08"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Determine the input shape\n",
        "input_shape = (X_train_processed.shape[1],)\n",
        "print(f\"Input shape for the model: {input_shape}\")\n",
        "\n",
        "# 2. Define a Keras Sequential model\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam', # Adam optimizer\n",
        "    loss='binary_crossentropy', # Binary Cross-Entropy loss\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
        ")\n",
        "\n",
        "# 4. Print the model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# 5. Calculate class weights for y_train\n",
        "total_samples = len(y_train)\n",
        "num_fraud = y_train.sum()\n",
        "num_legit = total_samples - num_fraud\n",
        "\n",
        "weight_for_0 = (1 / num_legit) * (total_samples / 2.0)\n",
        "weight_for_1 = (1 / num_fraud) * (total_samples / 2.0)\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "# 6. Print the calculated class weights\n",
        "print(f\"\\nCalculated Class Weights: {class_weight}\")\n",
        "\n",
        "# 7. Define an EarlyStopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10, # Number of epochs with no improvement after which training will be stopped.\n",
        "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored quantity.\n",
        ")\n",
        "\n",
        "# 8. Train the model\n",
        "print(\"\\nStarting model training with class weights and early stopping...\")\n",
        "history = model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    epochs=100, # Max epochs, but early stopping will intervene\n",
        "    batch_size=256, # Use a larger batch size for potentially faster training\n",
        "    validation_split=0.2, # Use a portion of training data for validation\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape for the model: (19,)\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,825\u001b[0m (54.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,825</span> (54.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,377\u001b[0m (52.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,377</span> (52.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculated Class Weights: {0: np.float64(0.5050505050505051), 1: np.float64(50.0)}\n",
            "\n",
            "Starting model training with class weights and early stopping...\n",
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.4902 - auc: 0.4711 - loss: 1.0383 - precision: 0.0090 - recall: 0.4624 - val_accuracy: 0.2191 - val_auc: 0.5023 - val_loss: 0.9345 - val_precision: 0.0104 - val_recall: 0.8037\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4975 - auc: 0.5381 - loss: 0.9070 - precision: 0.0111 - recall: 0.5488 - val_accuracy: 0.4785 - val_auc: 0.5137 - val_loss: 0.8606 - val_precision: 0.0106 - val_recall: 0.5460\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5178 - auc: 0.5212 - loss: 0.8785 - precision: 0.0106 - recall: 0.5186 - val_accuracy: 0.5785 - val_auc: 0.4891 - val_loss: 0.8181 - val_precision: 0.0097 - val_recall: 0.3988\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5278 - auc: 0.5288 - loss: 0.8558 - precision: 0.0102 - recall: 0.4971 - val_accuracy: 0.5676 - val_auc: 0.5034 - val_loss: 0.8146 - val_precision: 0.0111 - val_recall: 0.4724\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5315 - auc: 0.5404 - loss: 0.8442 - precision: 0.0112 - recall: 0.5266 - val_accuracy: 0.5204 - val_auc: 0.4902 - val_loss: 0.8193 - val_precision: 0.0097 - val_recall: 0.4540\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5305 - auc: 0.5256 - loss: 0.8237 - precision: 0.0099 - recall: 0.4809 - val_accuracy: 0.4780 - val_auc: 0.4847 - val_loss: 0.8305 - val_precision: 0.0098 - val_recall: 0.5031\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5336 - auc: 0.5942 - loss: 0.7970 - precision: 0.0123 - recall: 0.6006 - val_accuracy: 0.5794 - val_auc: 0.4824 - val_loss: 0.8017 - val_precision: 0.0100 - val_recall: 0.4110\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5546 - auc: 0.5731 - loss: 0.7825 - precision: 0.0113 - recall: 0.5422 - val_accuracy: 0.5714 - val_auc: 0.4914 - val_loss: 0.7998 - val_precision: 0.0100 - val_recall: 0.4172\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5294 - auc: 0.5725 - loss: 0.8000 - precision: 0.0122 - recall: 0.5872 - val_accuracy: 0.5577 - val_auc: 0.5125 - val_loss: 0.7927 - val_precision: 0.0114 - val_recall: 0.4969\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5505 - auc: 0.5640 - loss: 0.7715 - precision: 0.0111 - recall: 0.5339 - val_accuracy: 0.6209 - val_auc: 0.5122 - val_loss: 0.7733 - val_precision: 0.0119 - val_recall: 0.4417\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5366 - auc: 0.5604 - loss: 0.7950 - precision: 0.0117 - recall: 0.5354 - val_accuracy: 0.5705 - val_auc: 0.5095 - val_loss: 0.7755 - val_precision: 0.0106 - val_recall: 0.4479\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5275 - auc: 0.5465 - loss: 0.7921 - precision: 0.0109 - recall: 0.5011 - val_accuracy: 0.5231 - val_auc: 0.4954 - val_loss: 0.7706 - val_precision: 0.0100 - val_recall: 0.4663\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5436 - auc: 0.5793 - loss: 0.7571 - precision: 0.0118 - recall: 0.5643 - val_accuracy: 0.5577 - val_auc: 0.5093 - val_loss: 0.7620 - val_precision: 0.0109 - val_recall: 0.4724\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5465 - auc: 0.5942 - loss: 0.7618 - precision: 0.0131 - recall: 0.5954 - val_accuracy: 0.5829 - val_auc: 0.5105 - val_loss: 0.7517 - val_precision: 0.0108 - val_recall: 0.4417\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5618 - auc: 0.5825 - loss: 0.7257 - precision: 0.0119 - recall: 0.5783 - val_accuracy: 0.5377 - val_auc: 0.4998 - val_loss: 0.7568 - val_precision: 0.0113 - val_recall: 0.5153\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5376 - auc: 0.5872 - loss: 0.7313 - precision: 0.0121 - recall: 0.6014 - val_accuracy: 0.5614 - val_auc: 0.5046 - val_loss: 0.7452 - val_precision: 0.0101 - val_recall: 0.4356\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5228 - auc: 0.5814 - loss: 0.7620 - precision: 0.0131 - recall: 0.6030 - val_accuracy: 0.5487 - val_auc: 0.5080 - val_loss: 0.7434 - val_precision: 0.0103 - val_recall: 0.4540\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5378 - auc: 0.6058 - loss: 0.7339 - precision: 0.0128 - recall: 0.5962 - val_accuracy: 0.5474 - val_auc: 0.5139 - val_loss: 0.7376 - val_precision: 0.0105 - val_recall: 0.4663\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5441 - auc: 0.6139 - loss: 0.7221 - precision: 0.0134 - recall: 0.6262 - val_accuracy: 0.5346 - val_auc: 0.5184 - val_loss: 0.7300 - val_precision: 0.0109 - val_recall: 0.4969\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5366 - auc: 0.6036 - loss: 0.7244 - precision: 0.0124 - recall: 0.5823 - val_accuracy: 0.4938 - val_auc: 0.5073 - val_loss: 0.7394 - val_precision: 0.0104 - val_recall: 0.5153\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5341 - auc: 0.6121 - loss: 0.7037 - precision: 0.0130 - recall: 0.6437 - val_accuracy: 0.4844 - val_auc: 0.4927 - val_loss: 0.7461 - val_precision: 0.0107 - val_recall: 0.5399\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5361 - auc: 0.6053 - loss: 0.7216 - precision: 0.0131 - recall: 0.6119 - val_accuracy: 0.5421 - val_auc: 0.5082 - val_loss: 0.7175 - val_precision: 0.0107 - val_recall: 0.4785\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5205 - auc: 0.6038 - loss: 0.7261 - precision: 0.0133 - recall: 0.6292 - val_accuracy: 0.5671 - val_auc: 0.5357 - val_loss: 0.7179 - val_precision: 0.0118 - val_recall: 0.5031\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5417 - auc: 0.6215 - loss: 0.6963 - precision: 0.0137 - recall: 0.6620 - val_accuracy: 0.5576 - val_auc: 0.5394 - val_loss: 0.7138 - val_precision: 0.0119 - val_recall: 0.5153\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5124 - auc: 0.5895 - loss: 0.7480 - precision: 0.0136 - recall: 0.6192 - val_accuracy: 0.5444 - val_auc: 0.5329 - val_loss: 0.7098 - val_precision: 0.0123 - val_recall: 0.5521\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5250 - auc: 0.6033 - loss: 0.7098 - precision: 0.0126 - recall: 0.6115 - val_accuracy: 0.5253 - val_auc: 0.5061 - val_loss: 0.7121 - val_precision: 0.0098 - val_recall: 0.4540\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5305 - auc: 0.5982 - loss: 0.7089 - precision: 0.0126 - recall: 0.6016 - val_accuracy: 0.5679 - val_auc: 0.5216 - val_loss: 0.7043 - val_precision: 0.0110 - val_recall: 0.4663\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5269 - auc: 0.6051 - loss: 0.6973 - precision: 0.0126 - recall: 0.6188 - val_accuracy: 0.4898 - val_auc: 0.5219 - val_loss: 0.7164 - val_precision: 0.0106 - val_recall: 0.5337\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4938 - auc: 0.6231 - loss: 0.7176 - precision: 0.0147 - recall: 0.7049 - val_accuracy: 0.5751 - val_auc: 0.5078 - val_loss: 0.7040 - val_precision: 0.0095 - val_recall: 0.3926\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5562 - auc: 0.5956 - loss: 0.7159 - precision: 0.0124 - recall: 0.5450 - val_accuracy: 0.5519 - val_auc: 0.5192 - val_loss: 0.6968 - val_precision: 0.0113 - val_recall: 0.4969\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5268 - auc: 0.6111 - loss: 0.7172 - precision: 0.0141 - recall: 0.6467 - val_accuracy: 0.4907 - val_auc: 0.5409 - val_loss: 0.7245 - val_precision: 0.0115 - val_recall: 0.5767\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5056 - auc: 0.6129 - loss: 0.7548 - precision: 0.0151 - recall: 0.6551 - val_accuracy: 0.5769 - val_auc: 0.5261 - val_loss: 0.6855 - val_precision: 0.0111 - val_recall: 0.4601\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5633 - auc: 0.6040 - loss: 0.6969 - precision: 0.0131 - recall: 0.5883 - val_accuracy: 0.4899 - val_auc: 0.5229 - val_loss: 0.7090 - val_precision: 0.0103 - val_recall: 0.5153\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5246 - auc: 0.6328 - loss: 0.6776 - precision: 0.0130 - recall: 0.6616 - val_accuracy: 0.4473 - val_auc: 0.5181 - val_loss: 0.7284 - val_precision: 0.0102 - val_recall: 0.5521\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5106 - auc: 0.6454 - loss: 0.7045 - precision: 0.0150 - recall: 0.7081 - val_accuracy: 0.4891 - val_auc: 0.5217 - val_loss: 0.7106 - val_precision: 0.0107 - val_recall: 0.5399\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5057 - auc: 0.6408 - loss: 0.6908 - precision: 0.0143 - recall: 0.7106 - val_accuracy: 0.5578 - val_auc: 0.5130 - val_loss: 0.6883 - val_precision: 0.0106 - val_recall: 0.4601\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5258 - auc: 0.6368 - loss: 0.7053 - precision: 0.0148 - recall: 0.6801 - val_accuracy: 0.4781 - val_auc: 0.4963 - val_loss: 0.7013 - val_precision: 0.0104 - val_recall: 0.5337\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5149 - auc: 0.6104 - loss: 0.6908 - precision: 0.0130 - recall: 0.6461 - val_accuracy: 0.5033 - val_auc: 0.5245 - val_loss: 0.7024 - val_precision: 0.0114 - val_recall: 0.5583\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5057 - auc: 0.6167 - loss: 0.7073 - precision: 0.0134 - recall: 0.6473 - val_accuracy: 0.5217 - val_auc: 0.5147 - val_loss: 0.6984 - val_precision: 0.0114 - val_recall: 0.5337\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5145 - auc: 0.6258 - loss: 0.6992 - precision: 0.0140 - recall: 0.6720 - val_accuracy: 0.5475 - val_auc: 0.5115 - val_loss: 0.6988 - val_precision: 0.0102 - val_recall: 0.4540\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5411 - auc: 0.6155 - loss: 0.6831 - precision: 0.0129 - recall: 0.6236 - val_accuracy: 0.4812 - val_auc: 0.5147 - val_loss: 0.7121 - val_precision: 0.0107 - val_recall: 0.5460\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4873 - auc: 0.6244 - loss: 0.7154 - precision: 0.0136 - recall: 0.6552 - val_accuracy: 0.5108 - val_auc: 0.5365 - val_loss: 0.6978 - val_precision: 0.0116 - val_recall: 0.5583\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb6a709e"
      },
      "source": [
        "# Task\n",
        "I will now evaluate the trained model on the test dataset (`X_test_processed`, `y_test`). I will print the test loss, accuracy, precision, recall, and ROC AUC. I will then generate predicted probabilities for the test set and display a comprehensive classification report. Finally, I will plot the Precision-Recall Curve to visualize the trade-off between precision and recall, which is crucial for imbalanced datasets like fraud detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b530b9af"
      },
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model on the test dataset (`X_test_processed`, `y_test`). Print the test loss, accuracy, precision, recall, and ROC AUC. Generate predicted probabilities for the test set and display a comprehensive classification report. Finally, plot the Precision-Recall Curve to visualize the trade-off between precision and recall, which is crucial for imbalanced datasets like fraud detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fbeb4ec"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the trained model on the test set, generate predictions, and visualize the Precision-Recall curve as specified in the subtask, I will use a code block to perform these operations using the `model` and preprocessed test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "b456b289",
        "outputId": "b8dc1466-2f75-47ae-b05a-19b535058811"
      },
      "source": [
        "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Evaluate the trained model on the test dataset\n",
        "loss, accuracy, precision, recall, auc_score = model.evaluate(X_test_processed, y_test, verbose=0)\n",
        "\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test ROC AUC: {auc_score:.4f}\")\n",
        "\n",
        "# 2. Generate predicted probabilities for the test set\n",
        "y_pred_proba = model.predict(X_test_processed).ravel()\n",
        "\n",
        "# 3. Calculate the Precision-Recall Curve and identify optimal threshold\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + np.finfo(float).eps) # Add epsilon to prevent division by zero\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nOptimal Threshold (maximizing F1-score): {optimal_threshold:.4f}\")\n",
        "\n",
        "# 4. Convert predicted probabilities to binary predictions using the optimal threshold\n",
        "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# 5. Print a comprehensive classification report\n",
        "print(\"\\nClassification Report (with optimal threshold):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 6. Plot the Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recalls, precisions, label=f'Precision-Recall curve (Area = {auc(recalls, precisions):.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 0.6845\n",
            "Test Accuracy: 0.5743\n",
            "Test Precision: 0.0096\n",
            "Test Recall: 0.4050\n",
            "Test ROC AUC: 0.5042\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
            "\n",
            "Optimal Threshold (maximizing F1-score): 0.6243\n",
            "\n",
            "Classification Report (with optimal threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98     19800\n",
            "           1       0.02      0.06      0.03       200\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.51      0.52      0.51     20000\n",
            "weighted avg       0.98      0.97      0.97     20000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1739de3"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the real-time data science workflow, including the Python code, its output, and the interpretation of the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7a9ca9c"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The model achieved a Test Loss of 0.6845, a Test Accuracy of 0.5743, a Test Precision of 0.0096, a Test Recall of 0.4050, and a Test ROC AUC of 0.5042.\n",
        "*   An optimal threshold of 0.6243 was identified for maximizing the F1-score, which is crucial for balancing precision and recall in imbalanced datasets.\n",
        "*   Using the optimal threshold, the classification report revealed:\n",
        "    *   For class 0 (non-fraud): Precision was 0.99, Recall was 0.98, and F1-score was 0.98.\n",
        "    *   For class 1 (fraud): Precision was 0.02, Recall was 0.06, and F1-score was 0.03.\n",
        "    *   The overall accuracy with this threshold was 0.97.\n",
        "*   The Area Under the Precision-Recall Curve (AUPRC) was calculated to be 0.02, indicating poor performance in distinguishing the positive class (fraud).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The very low precision and recall for the fraud class (class 1), despite a high overall accuracy, indicate that the model is struggling to correctly identify fraudulent transactions. The high overall accuracy is likely driven by the majority class (non-fraud).\n",
        "*   Given the low AUPRC and poor performance on the minority class, further efforts should focus on techniques to address class imbalance (e.g., oversampling, undersampling, using different loss functions, or exploring anomaly detection algorithms) and potentially feature engineering to improve the model's ability to differentiate fraudulent activities.\n"
      ]
    }
  ]
}